
@article{BlackburnComputationalsemantics2003,
  title = {Computational Semantics},
  journal = {Theoria: An International Journal for Theory, History and Foundations of Science},
  author = {Blackburn, Patrick and Bos, Johan},
  year = {2003},
  pages = {27--45},
  file = {/home/arildm/Zotero/storage/CJ9APB7P/BlackburnBos2003Theoria.pdf}
}

@article{ChatzikyriakidisTypeTheoryNatural2017,
  title = {Type {{Theory}} for {{Natural Language Semantics}}},
  author = {Chatzikyriakidis, Stergios and Cooper, Robin},
  year = {2017},
  keywords = {TTR,type theory},
  file = {/home/arildm/Zotero/storage/EJ6HP6GP/Chatzikyriakidis Cooper 2017 type-theory-natural.pdf}
}

@article{CooperRecordsRecordTypes2005,
  title = {Records and {{Record Types}} in {{Semantic Theory}}},
  volume = {15},
  issn = {0955-792X, 1465-363X},
  doi = {10.1093/logcom/exi004},
  language = {en},
  number = {2},
  journal = {Journal of Logic and Computation},
  author = {Cooper, R.},
  month = apr,
  year = {2005},
  keywords = {TTR},
  pages = {99-112},
  file = {/home/arildm/Zotero/storage/2FQHY3UG/Cooper 2005 Records_and_Record_Types_in_Semantic_Theory.pdf}
}

@article{CooperTypetheorysemantics2012,
  title = {Type Theory and Semantics in Flux},
  volume = {14},
  journal = {Handbook of the Philosophy of Science},
  author = {Cooper, Robin},
  year = {2012},
  keywords = {TTR,type theory},
  pages = {271--323},
  file = {/home/arildm/Zotero/storage/98QG5I2W/Cooper 2012 Type theory and semantics in flux.pdf}
}

@inproceedings{DobnikModellinglanguageaction2012,
  title = {Modelling Language, Action, and Perception in Type Theory with Records},
  booktitle = {International {{Workshop}} on {{Constraint Solving}} and {{Language Processing}}},
  publisher = {{Springer}},
  author = {Dobnik, Simon and Cooper, Robin and Larsson, Staffan},
  year = {2012},
  keywords = {TTR},
  pages = {70--91},
  file = {/home/arildm/Zotero/storage/FD4Z4XP3/Dobnik Cooper Larsson 2013 perceptual-ttr-post-proceedings-published-81140070.pdf}
}

@article{FernandoSituationsstrings2006,
  title = {Situations as Strings},
  volume = {165},
  journal = {Electronic Notes in Theoretical Computer Science},
  author = {Fernando, Tim},
  year = {2006},
  pages = {23--36},
  file = {/home/arildm/Zotero/storage/A3CLSDPV/Fernando 2006 Situations as strings.pdf}
}

@article{lspc,
  title = {Interfacing Language, Spatial Perception and Cognition in {{Type Theory}} with {{Records}}},
  volume = {5},
  number = {2},
  journal = {Journal of Language Modelling},
  author = {Dobnik, Simon and Cooper, Robin},
  year = {2017},
  keywords = {TTR,spatial relations},
  pages = {273--301},
  file = {/home/arildm/Zotero/storage/3SUGE6PL/lspc.pdf}
}

@book{martinlof84,
  title = {Intuitionistic Type Theory},
  volume = {9},
  publisher = {{Bibliopolis Napoli}},
  author = {Martin-L{\"o}f, Per and Sambin, Giovanni},
  year = {1984},
  keywords = {type theory},
  file = {/home/arildm/Zotero/storage/ZJRGURBB/Martin-Löf 1984 Intuitionistic type theory.pdf}
}

@article{CooperTypetheorylanguage2016,
  title = {Type Theory and Language: From Perception to Linguistic Communication},
  shorttitle = {Type Theory and Language},
  journal = {Draft of book chapters available from https://sites. google. com/site/typetheorywithrecords/drafts},
  author = {Cooper, Robin},
  year = {2016},
  keywords = {TTR},
  file = {/home/arildm/Zotero/storage/KWNW8W58/ttl161130.pdf}
}

@inproceedings{Larssonformalviewcorrective2009,
  title = {Towards a Formal View of Corrective Feedback},
  booktitle = {Proceedings of the {{EACL}} 2009 {{Workshop}} on {{Cognitive Aspects}} of {{Computational Language Acquisition}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Larsson, Staffan and Cooper, Robin},
  year = {2009},
  keywords = {TTR,dialogue},
  pages = {1--9},
  file = {/home/arildm/Zotero/storage/QUQ5MXF6/Larsson and Cooper - 2009 - Towards a Formal View of Corrective Feedback.pdf}
}

@misc{CooperSemanticsactionperception2017,
  title = {Semantics, Action and Perception - an Overview of {{TTR}}},
  author = {Cooper, Robin},
  year = {2017},
  keywords = {TTR},
  file = {/home/arildm/Zotero/storage/DYAYM47Y/eslp cooper ttr-lect-slides17.pdf}
}

@incollection{DybjerIntuitionisticTypeTheory2016,
  edition = {Winter 2016},
  title = {Intuitionistic {{Type Theory}}},
  abstract = {Intuitionistic type theory (also constructive type theory orMartin-L{\"o}f type theory) is a formal logical system and philosophicalfoundation for constructive mathematics. It is afull-scale system which aims to play a similar role for constructivemathematics as Zermelo-Fraenkel Set Theory does forclassical mathematics. It is based on the propositions-as-typesprinciple and clarifies the Brouwer-Heyting-Kolmogorov interpretationof intuitionistic logic. It extends this interpretation to the moregeneral setting of intuitionistic type theory and thus provides ageneral conception not only of what a constructive proof is, but alsoof what a constructive mathematical object is. The main idea is thatmathematical concepts such as elements, sets and functions areexplained in terms of concepts from programming such as datastructures, data types and programs. This article describes the formalsystem of intuitionistic type theory and its semantic foundations., In this entry, we first give an overview of the most importantaspects of intuitionistic type theory\textemdash{}a kind of ``extendedabstract''. It is meant for a reader who is already somewhatfamiliar with the theory. Section 2 on the other hand, is meant for areader who is new to intuitionistic type theory but familiar withtraditional logic, including propositional and predicate logic,arithmetic, and set theory. Here we informally introduce severalaspects which distinguishes intuitionistic type theory from thesetraditional theories. In Section 3 we present a basic version of thetheory, close to Martin-L{\"o}f's first published version from1972. The reader who was intrigued by the informality of Section 2will now see in detail how the theory is built up. Section 4 thenpresents a number of important extensions of the basic theory. Inparticular, it emphasizes the central role of inductive (andinductive-recursive) definitions. Section 5 introduces the underlyingphilosophical ideas including the theory of meaning developed byMartin-L{\"o}f. While Section 5 is about philosophy and foundations,Section 6 gives an overview of mathematical models of the theory. InSection 7 finally, we describe several important variations of thecore Martin-L{\"o}f ``intensional'' theory described inSection 3 and 4.},
  booktitle = {The {{Stanford Encyclopedia}} of {{Philosophy}}},
  publisher = {{Metaphysics Research Lab, Stanford University}},
  author = {Dybjer, Peter and Palmgren, Erik},
  editor = {Zalta, Edward N.},
  year = {2016},
  keywords = {type theory}
}

@article{DBLP:journals/corr/HeZRS15,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1512.03385},
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  volume = {abs/1512.03385},
  journal = {CoRR},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2015},
  biburl = {http://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{DBLP:journals/corr/Graves13,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1308.0850},
  title = {Generating {{Sequences With Recurrent Neural Networks}}},
  volume = {abs/1308.0850},
  journal = {CoRR},
  author = {Graves, Alex},
  year = {2013},
  biburl = {http://dblp.org/rec/bib/journals/corr/Graves13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{Hochreiter:1997:LSM:1246443.1246450,
  title = {Long {{Short}}-{{Term Memory}}},
  volume = {9},
  issn = {0899-7667},
  doi = {10.1162/neco.1997.9.8.1735},
  number = {8},
  journal = {Neural Comput.},
  author = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  month = nov,
  year = {1997},
  pages = {1735-1780},
  publisher = {{MIT Press}},
  location = {Cambridge, MA, USA},
  issue_date = {November 15, 1997},
  numpages = {46},
  acmid = {1246450}
}

@article{DBLP:journals/corr/MalinowskiRF15,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1505.01121},
  title = {Ask {{Your Neurons}}: {{A Neural}}-Based {{Approach}} to {{Answering Questions}} about {{Images}}},
  volume = {abs/1505.01121},
  journal = {CoRR},
  author = {Malinowski, Mateusz and Rohrbach, Marcus and Fritz, Mario},
  year = {2015},
  biburl = {http://dblp.org/rec/bib/journals/corr/MalinowskiRF15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{imagenet_cvpr09,
  title = {{{ImageNet}}: {{A Large}}-{{Scale Hierarchical Image Database}}},
  booktitle = {{{CVPR09}}},
  author = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
  year = {2009},
  bibsource = {http://www.image-net.org/papers/imagenet<sub>c</sub>vpr09.bib}
}

@article{Detectron2018,
  title = {Detectron},
  author = {Girshick, Ross and Radosavovic, Ilija and Gkioxari, Georgia and Doll{\'a}r, Piotr and He, Kaiming},
  year = {2018}
}

@misc{pyttr,
  title = {{{PyTTR}}},
  author = {Cooper, Robin},
  year = {2017},
  keywords = {TTR}
}

@article{RantaTypeTheoryUniversal2006,
  title = {Type {{Theory}} and {{Universal Grammar}}},
  copyright = {Tous droits r{\'e}serv{\'e}s},
  issn = {1281-2463},
  doi = {10.4000/philosophiascientiae.415},
  abstract = {The paper takes a look at the history of the idea of universal grammar and compares it with multilingual grammars, as formalized in the Grammatical Framework, GF. The constructivist idea of formalizing math$\-$ematics piece by piece, in a weak logical framework, rather than trying to reduce everything to one single strong theory, is the model that guides the development of grammars in GF.},
  language = {en},
  number = {CS 6},
  journal = {Philosophia Scienti{\ae}. Travaux d'histoire et de philosophie des sciences},
  author = {Ranta, Aarne},
  month = sep,
  year = {2006},
  pages = {115-131},
  file = {/home/arildm/Zotero/storage/AUFCFYVC/Ranta - 2006 - Type Theory and Universal Grammar.pdf;/home/arildm/Zotero/storage/MFG7YLYP/415.html}
}

@article{AndreasLearningComposeNeural2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1601.01705},
  primaryClass = {cs},
  title = {Learning to {{Compose Neural Networks}} for {{Question Answering}}},
  abstract = {We describe a question answering model that applies to both images and structured knowledge bases. The model uses natural language strings to automatically assemble neural networks from a collection of composable modules. Parameters for these modules are learned jointly with network-assembly parameters via reinforcement learning, with only (world, question, answer) triples as supervision. Our approach, which we term a dynamic neural model network, achieves state-of-the-art results on benchmark datasets in both visual and structured domains.},
  journal = {arXiv:1601.01705 [cs]},
  author = {Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
  month = jan,
  year = {2016},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Neural and Evolutionary Computing},
  file = {/home/arildm/Zotero/storage/W5Q4VZDY/Andreas et al. - 2016 - Learning to Compose Neural Networks for Question A.pdf;/home/arildm/Zotero/storage/A3UIGGIU/1601.html}
}

@article{RedmonYouOnlyLook2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1506.02640},
  primaryClass = {cs},
  title = {You {{Only Look Once}}: {{Unified}}, {{Real}}-{{Time Object Detection}}},
  shorttitle = {You {{Only Look Once}}},
  abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is far less likely to predict false detections where nothing exists. Finally, YOLO learns very general representations of objects. It outperforms all other detection methods, including DPM and R-CNN, by a wide margin when generalizing from natural images to artwork on both the Picasso Dataset and the People-Art Dataset.},
  journal = {arXiv:1506.02640 [cs]},
  author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  month = jun,
  year = {2015},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/arildm/Zotero/storage/2WVYT8AG/Redmon et al. - 2015 - You Only Look Once Unified, Real-Time Object Dete.pdf;/home/arildm/Zotero/storage/XUNRDBS7/1506.html}
}

@article{yolo,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1612.08242},
  primaryClass = {cs},
  title = {{{YOLO9000}}: {{Better}}, {{Faster}}, {{Stronger}}},
  shorttitle = {{{YOLO9000}}},
  abstract = {We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that don't have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. But YOLO can detect more than just 200 classes; it predicts detections for more than 9000 different object categories. And it still runs in real-time.},
  journal = {arXiv:1612.08242 [cs]},
  author = {Redmon, Joseph and Farhadi, Ali},
  month = dec,
  year = {2016},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/arildm/Zotero/storage/75R4TWJL/Redmon and Farhadi - 2016 - YOLO9000 Better, Faster, Stronger.pdf;/home/arildm/Zotero/storage/BARLE6W4/1612.html}
}

@article{RegierGroundingspatiallanguage2001a,
  title = {Grounding Spatial Language in Perception: {{An}} Empirical and Computational Investigation},
  volume = {130},
  copyright = {\textcopyright{} 2001, American Psychological Association},
  issn = {0096-3445},
  shorttitle = {Grounding Spatial Language in Perception},
  doi = {http://dx.doi.org.ezproxy.ub.gu.se/10.1037/0096-3445.130.2.273},
  abstract = {The present paper grounds the linguistic categorization of space in aspects of visual perception; specifically, the structure of projective spatial terms such as above are grounded in the process of attention and in vector-sum coding of overall direction. This is formalized in the attentional vector-sum (AVS) model. This computational model accurately predicts linguistic acceptability judgments for spatial terms, under a variety of spatial configurations. In 7 experiments, the predictions of the AVS model are tested against those of 3 competing models. The results support the AVS model and disconfirm its competitors. The authors conclude that the structure of linguistic spatial categories can be partially explained in terms of independently motivated perceptual processes.},
  language = {English},
  number = {2},
  journal = {Journal of Experimental Psychology: General},
  author = {Regier, Terry and Carlson, Laura A.},
  month = jun,
  year = {2001},
  keywords = {Orientation; Pattern Recognition; Visual; Semantics; Space Perception; Verbal Learning;,Attention,Classification (Cognitive Process) (major),Judgment,Linguistics (major),Mathematical Modeling (major),Spatial Perception (major),Visual Perception (major),Words (Phonetic Units)},
  pages = {273-298},
  file = {/home/arildm/Zotero/storage/WISAXKBR/Regier and Carlson - 2001 - Grounding spatial language in perception An empir.pdf}
}

@misc{LoganComputationalAnalysisApprehension1996,
  title = {A {{Computational Analysis}} of the {{Apprehension}} of {{Spatial Relations}}},
  abstract = {Basic, deictic, \& intrinsic spatial relations distinguished in the literature motivate the proposal that apprehension of spatial relations requires (1) spatial indexing to instantiate basic relations, (2) reference frame computation to adjust parameters of the representation, (3) spatial template alignment to specify scope of acceptability of a given relation, \& (4) assessment of goodness of fit of spatial templates. These representations \& processes may be combined in various orders to perform relation judgments, cuing tasks, \& verification tasks. Evidence from previous psychological studies corroborates spatial indexing \& reference frame computation. Four experiments provide new evidence of the computation of goodness of fit between position of the located object \& a spatial template representing the relation that is centered on \& aligned with the reference object. In a production task, Ss (N = 68 undergraduates) indicated regions of space corresponding to areas of greatest acceptability of 12 spatial relations. In a goodness rating task, Ss (N = 32) ranked areas of space as good, acceptable, \& bad examples of 10 spatial relations in sentences corresponding to pictures. Results showed consistent representations of each notion. In a similarity rating task, Ss (N = 101) evaluated equivalence of pairs from a set of 12 lexicalized spatial terms. Similarities posited for underlying conceptual templates account for resemblances in results of goodness \& similarity rating tasks. Finally, a spatial relation judgment task measured reaction times of Ss (N = 48) to stimuli that systematically varied the distance between reference \& located objects. Results showed that distance minimally affected times, thus supporting the idea that spatial templates applied in parallel, rather than serial visual routines, process spatial relationships. It is concluded that spatial templates are useful for description of many spatial relation meanings. 1 Table, 12 Figures, 39 References. L. Lucht},
  language = {eng},
  author = {Logan, Gordon and Sadler, Daniel},
  collaborator = {Logan, Gordon},
  month = jan,
  year = {1996},
  keywords = {4011,bookitem,Bookitem,Computational Linguistics (14100),Deixis (17750),Language Processing (43550),production /rating tasks,Production /Rating Tasks,Psycholinguistics; Theories and Models,Space (81600),spatial relations processing; computational analysis,Spatial Relations Processing; Computational Analysis},
  file = {/home/arildm/Zotero/storage/V3UFFU6V/Logan and Sadler - 1996 - A Computational Analysis of the Apprehension of Sp.pdf}
}

@unpublished{CooperAustinianTruthAttitudes,
  title = {Austinian {{Truth}}, {{Attitudes}} and {{Type Theory}} \$$\backslash$ast\$},
  author = {Cooper, Robin}
}

@article{RobinCooperAustiniantruthattitudes2005,
  title = {Austinian Truth, Attitudes and Type Theory},
  language = {eng},
  author = {{Robin Cooper}},
  year = {2005},
  keywords = {TTR,HUMANIORA och RELIGIONSVETENSKAP|Språkvetenskap|Lingvistikämnen|Datorlingvistik,HUMANITIES and RELIGION|Languages and linguistics|Linguistic subjects|Computational linguistics,NATURAL SCIENCES|Computer and Information Science|Language Technology (Computational Linguistics)|Computational linguistics,NATURVETENSKAP|Data- och informationsvetenskap|Språkteknologi (språkvetenskaplig databehandling)|Datorlingvistik},
  file = {/home/arildm/Downloads/Cooper 2005 Austinian.pdf}
}

@inproceedings{ttrspat,
  address = {Potsdam, Germany},
  title = {Spatial {{Descriptions}} in {{Type Theory}} with {{Records}}},
  booktitle = {Proceedings of {{IWCS}} 2013 {{Workshop}} on {{Computational Models}} of {{Spatial Language Interpretation}} and {{Generation}} ({{CoSLI}}-3)},
  publisher = {{Association for Computational Linguistics}},
  author = {Dobnik, Simon and Cooper, Robin},
  month = mar,
  year = {2013},
  keywords = {TTR},
  pages = {1--6},
  file = {/home/arildm/Zotero/storage/SXULHG3L/Dobnik and Cooper - 2013 - Spatial Descriptions in Type Theory with Records.pdf}
}

@inproceedings{Dobnik:2017ag,
  series = {CLASP Papers in Computational Linguistics},
  title = {Modular Mechanistic Networks: {{On}} Bridging Mechanistic and Phenomenological Models with Deep Neural Networks in Natural Language Processing},
  booktitle = {Proceedings of the {{Conference}} on {{Logic}} and {{Machine Learning}} in {{Natural Language}} ({{LaML}} 2017), {{Gothenburg}}, 12--13 {{June}} 2017},
  author = {Dobnik, Simon and Kelleher, John D.},
  pages = {1-11},
  file = {/home/arildm/Zotero/storage/52YJE6NF/mechanistic-phenomenological-models-in-nlp.pdf},
  crossref = {LaML-Proceeedings:2017}
}

@book{LaML-Proceeedings:2017,
  address = {Gothenburg, Sweden},
  title = {{{CLASP Papers}} in {{Computational Linguistics}}: {{Proceedings}} of the {{Conference}} on {{Logic}} and {{Machine Learning}} in {{Natural Language}} ({{LaML}} 2017), {{Gothenburg}}, 12 --13 {{June}}},
  volume = {1},
  publisher = {{CLASP, Centre for Language and Studies in Probability}},
  editor = {Dobnik, Simon and Lappin, Shalom},
  month = nov,
  year = {2017},
  file = {/home/arildm/Zotero/storage/63AK2K2T/Simon et al. - 2017 - CLASP Papers in Computational Linguistics.pdf;/home/arildm/Zotero/storage/CNCN6FDG/54911.html},
  organization = {Department of Philosophy, Linguistics and Theory of Science (FLOV), University of Gothenburg}
}

@article{RoySemioticschemasframework2005,
  title = {Semiotic Schemas: {{A}} Framework for Grounding Language in Action and Perception},
  volume = {167},
  issn = {0004-3702},
  shorttitle = {Semiotic Schemas},
  doi = {10.1016/j.artint.2005.04.007},
  abstract = {A theoretical framework for grounding language is introduced that provides a computational path from sensing and motor action to words and speech acts. The approach combines concepts from semiotics and schema theory to develop a holistic approach to linguistic meaning. Schemas serve as structured beliefs that are grounded in an agent's physical environment through a causal-predictive cycle of action and perception. Words and basic speech acts are interpreted in terms of grounded schemas. The framework reflects lessons learned from implementations of several language processing robots. It provides a basis for the analysis and design of situated, multimodal communication systems that straddle symbolic and non-symbolic realms.},
  language = {eng},
  number = {1},
  journal = {Artificial Intelligence},
  author = {Roy, Deb},
  year = {2005},
  keywords = {Action,Cross-Modal,Embodied,Grounding,Language,Meaning,Multimodal,Perception,Representation,Schemas,Semiotic,Situated},
  pages = {170--205},
  file = {/home/arildm/Zotero/storage/DA2BGULL/1-s2.0-S0004370205001037-main.pdf}
}

@inproceedings{PustejovskyPerceptualsemanticsconstruction1990,
  title = {Perceptual Semantics: The Construction of Meaning in Artificial Devices},
  shorttitle = {Perceptual Semantics},
  doi = {10.1109/ISIC.1990.128445},
  abstract = {The design of an artificial device that can acquire its own perceptually grounded meanings for internally represented control structure is discussed. A perceptual semantics, in which perceptual routines are mapped onto innate conceptual operators, is described. Entities and relations in the environment take on `meaning' for the device in three forms: the connotation, which is the internal encoding of an object within a syntactic discrimination lattice; the annotation, which is a procedural encoding of how connotations are translated into action/perception; and the denotation, which is the action associated with a procedure within the action-percept feedback loop. The author argues against model-theoretic interpretations for semantics of devices interacting within their environment, and in favor of pragmatically determined models of meaning},
  booktitle = {Proceedings. 5th {{IEEE International Symposium}} on {{Intelligent Control}} 1990},
  author = {Pustejovsky, J.},
  month = sep,
  year = {1990},
  keywords = {Grounding,action-percept feedback loop,adaptive control,annotation,artificial devices,Artificial intelligence,cognitive systems,Computer science,computer vision,conceptual representation,denotation,Encoding,feedback,Feedback loop,innate conceptual operators,Intelligent robots,Intelligent sensors,internal encoding,internally represented control structure,Lattices,learning systems,perceptual routines,perceptual semantics,perceptually grounded meanings,procedural encoding,Robot sensing systems,robot vision,robots,syntactic discrimination lattice,Testing},
  pages = {86-91 vol.1},
  file = {/home/arildm/Zotero/storage/7M4BCIIT/Pustejovsky - 1990 - Perceptual semantics the construction of meaning .pdf;/home/arildm/Zotero/storage/P692Y9RQ/128445.html}
}

@article{GuptaSurveyVisualQuestion2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1705.03865},
  primaryClass = {cs},
  title = {Survey of {{Visual Question Answering}}: {{Datasets}} and {{Techniques}}},
  shorttitle = {Survey of {{Visual Question Answering}}},
  abstract = {Visual question answering (or VQA) is a new and exciting problem that combines natural language processing and computer vision techniques. We present a survey of the various datasets and models that have been used to tackle this task. The first part of the survey details the various datasets for VQA and compares them along some common factors. The second part of this survey details the different approaches for VQA, classified into four types: non-deep learning models, deep learning models without attention, deep learning models with attention, and other models which do not fit into the first three. Finally, we compare the performances of these approaches and provide some directions for future work.},
  journal = {arXiv:1705.03865 [cs]},
  author = {Gupta, Akshay Kumar},
  month = may,
  year = {2017},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Artificial Intelligence},
  file = {/home/arildm/Zotero/storage/48GX3FA7/Gupta - 2017 - Survey of Visual Question Answering Datasets and .pdf;/home/arildm/Zotero/storage/IEZCNAWM/1705.html}
}

@article{CooperNegationdialogue2018,
  title = {Negation in Dialogue},
  abstract = {We consider the nature of negation in di-alogue as revealed by semantic phenomena such as negative dialogue particles, psycholin-guistic experimentation, and dialogue corpora. We examine alternative accounts of negation that can be used in TTR (Type Theory with Records), and conclude that an alternatives-based account which relates to the psycholog-ical notion of negation in simulation seman-tics is most appropriate. We show how this account relates to questions under discussion, dialogical relevance, and metalinguistic nega-tion.},
  author = {Cooper, Robin and Ginzburg, Jonathan},
  month = apr,
  year = {2018},
  file = {/home/arildm/Zotero/storage/W9MAYJGK/Negation_in_dialogue.pdf}
}

@article{Kampcalculusfirstorder1996,
  title = {A Calculus for First Order {{Discourse Representation Structures}}},
  volume = {5},
  issn = {0925-8531, 1572-9583},
  doi = {10.1007/BF00159343},
  abstract = {This paper presents a sound and complete proof system for the first order fragment of Discourse Representation Theory. Since the inferences that human language users draw from the verbal input they receive for the most transcend the capacities of such a system, it can be no more than a basis on which more powerful systems, which are capable of producing those inferences, may then be built. Nevertheless, even within the general setting of first order logic the structure of the ``formulas'' of DRS-languages, i.e. of the Discourse Representation Structures suggest for the components of such a system inference rules that differ somewhat from those usually found in proof systems for the first order predicate calculus and which are, we believe, more in keeping with inference patterns that are actually employed in common sense reasoning.This is why we have decided to publish the present exercise, in spite of the fact that it is not one for which a great deal of originality could be claimed. In fact, it could be argued that the problem addressed in this paper was solved when G{\"o}del first established the completeness of the system of Principia Mathematica for first order logic. For the DRS-languages we consider here are straightforwardly intertranslatable with standard formulations of the predicate calculus; in fact the translations are so straightforward that any sound and complete proof system for first order logic can be used as a sound and complete proof system for DRSs: simply translate the DRSs into formulas of predicate logic and then proceed as usual. As a matter of fact, this is how one has chosen to proceed in some implementations of DRT, which involve inferencing as well as semantic representation; an example is the Lex system developed jointly by IBM and the University of T{\"u}bingen (see in particular (Guenthner et al. 1986)).In the light of the close and simple connections between DRT and standard predicate logic, publication of what will be presented in this paper can be justified only in terms of the special mash we have tried to achieve between the general form and the particular rules of our proof system on the one hand and on the other the distinctive architecture of DRS-like semantic representation. Some additional justification is necessary, however, as there exist a number of other proof systems for first order DRT, some of which have pursued more or less the same aims that have motivated the system presented here. We are explicitly aware of those developed by (Koons 1988), (Saurer 1990), (Sedogbo and Eytan 1987), (Reinhart 1989), (Gabbay and Reyle 1994); perhaps there are others. (Sedogbo and Eytan 1987) is a tableau system, and (Reinhart 1989) and (Gabbay and Reyle 1994) are resolution based, goal directed. These systems may promise particular advantages when it comes to implementing inference engines operating on DRS-like premises. But they do not aim to conform to certain canons of actual inferencing by human interpreters of natural language; and indeed the proof procedures they propose depart quite drastically from what one could plausibly assume to go in the head of such an interpreter. Only (Koons 1988) and (Saurer 1990) are, like our system, inspired by the methods of natural deduction. But there are some differences in the choice of basic rules. In particular both (Koons 1988) and (Saurer 1990) have among their primitive rules the Rule of Reiteration, which permits the copying of a DRS condition from a DRS to any of its sub-DRSs. In our system this is a derived rule (see Section 4 below).We will develop our system in several stages. The necessary intuitions and the formal background are provided in Sections 1 and 2. (The formal definitions can be found also in the first two chapters of (Kamp and Reyle 1993). The first system we present is for a sublanguage of the one defined in Section 2, which differs from the full language in that it lacks identity and disjunction. The core of the paper consists of Section 3, where the proof system for this sublanguage is presented, and Section 5, which extends the system for the full language, including disjunctions (Section 5.1) and identity (Section 5.2) and then establishes soundness and completeness for the full system. Section 4 deals with certain derived inference principles.},
  language = {en},
  number = {3-4},
  journal = {Journal of Logic, Language and Information},
  author = {Kamp, Hans and Reyle, Uwe},
  month = oct,
  year = {1996},
  pages = {297-348},
  file = {/home/arildm/Zotero/storage/5D7W4D2U/Kamp and Reyle - 1996 - A calculus for first order Discourse Representatio.pdf;/home/arildm/Zotero/storage/YT33NP6W/BF00159343.html}
}

@incollection{GeurtsDiscourseRepresentationTheory2016,
  edition = {Spring 2016},
  title = {Discourse {{Representation Theory}}},
  abstract = {In the early 1980s, Discourse Representation Theory (DRT) wasintroduced by Hans Kamp as a theoretical framework for dealing withissues in the semantics and pragmatics of anaphora and tense (Kamp1981); a very similar theory was developed independently by Irene Heim(1982). The distinctive features of DRT, to be discussed below, arethat it is a mentalist and representationalist theory ofinterpretation, and that it is a theory of the interpretation not onlyof individual sentences but of discourse, as well. In these respectsDRT made a clear break with classical formal semantics, which duringthe 1970s had emanated from Montague's pioneering work (Thomason1974), but in other respects it continued the tradition, e.g., in itsuse of model-theoretical tools. In the meantime, DRT has come to serveas a framework for explaining a wide range of phenomena, but we willconfine our attention to fewer than a handful: anaphora, tense,presupposition, and propositional attitudes. For references to work onother topics, see the ``Further reading'' section.},
  booktitle = {The {{Stanford Encyclopedia}} of {{Philosophy}}},
  publisher = {{Metaphysics Research Lab, Stanford University}},
  author = {Geurts, Bart and Beaver, David I. and Maier, Emar},
  editor = {Zalta, Edward N.},
  year = {2016},
  keywords = {anaphora,compositionality,descriptions,indexicals,presupposition,semantics: dynamic},
  file = {/home/arildm/Zotero/storage/L6AH9LQL/discourse-representation-theory.html}
}

@book{CarlsonFunctionalFeaturesLanguage2004,
  title = {Functional {{Features}} in {{Language}} and {{Space}}},
  isbn = {978-0-19-926433-9},
  abstract = {There is much empirical evidence showing that factors other than the relative positions of objects in Euclidean space are important in the comprehension of a wide range of spatial prepositions in English and other languages. Yet thus far attempts at classifying what we will call extra-geometric constraints have not been forthcoming. In this chapter we survey the range of experimental evidence for extra-geometric constraints, and we provide the first attempt at a classification of these influences. We argue that extra-geometric influences are basically of two types: what we term dynamic-kinematic aspects of scenes, and knowledge of the functions of objects and how they usually interact with each other in particular situations. We review the evidence for each of these parameters across a range of types of preposition, and report some new data showing the influence of extrageometric variables on the comprehension of between. We conclude with a discussion of the implications the empirical data and resultant classification have for models of spatial language comprehension.},
  language = {en},
  publisher = {{Oxford University Press}},
  author = {Carlson, Laura and {van der Zee}, Emile},
  month = dec,
  year = {2004},
  doi = {10.1093/acprof:oso/9780199264339.001.0001}
}

@article{CoventryClassificationExtrageometricInfluences2004,
  title = {Towards a {{Classification}} of {{Extra}}-Geometric {{Influences}} on the {{Comprehension}} of {{Spatial Prepositions}}},
  doi = {10.1093/acprof:oso/9780199264339.003.0010},
  abstract = {There is much empirical evidence showing that factors other than the relative positions of objects in Euclidean space are important in the comprehension of a wide range of spatial prepositions in English and other languages. However, attempts at classifying so-called extra-geometric constraints have not been forthcoming. This chapter surveys experimental evidence for extra-geometric constraints, and provides the first attempt at classifying these influences. It argues that extra-geometric influences are basically of two types: dynamic-kinematic aspects of scenes, and knowledge of the functions of objects and how they usually interact with each other in particular situations. It reviews evidence for each of these parameters across a range of types of preposition, and reports some new data showing the influence of extra-geometric variables on the comprehension of between. The chapter concludes with a discussion of the implications the empirical data and resultant classification have for models of spatial language comprehensions. \textcopyright{} the several contributors, Laura Carlson and Emile van der Zee, 2005. All rights reserved.},
  author = {Coventry, Kenny and Garrod, Simon},
  month = dec,
  year = {2004},
  file = {/home/arildm/Zotero/storage/B58JEM2N/Carlson and van der Zee - 2004 - Functional Features in Language and Space.pdf}
}

@incollection{CoventrySpatialPrepositionsVague2005,
  address = {Berlin, Heidelberg},
  title = {Spatial {{Prepositions}} and {{Vague Quantifiers}}: {{Implementing}} the {{Functional Geometric Framework}}},
  volume = {3343},
  isbn = {978-3-540-25048-7 978-3-540-32255-9},
  shorttitle = {Spatial {{Prepositions}} and {{Vague Quantifiers}}},
  abstract = {There is much empirical evidence showing that factors other than the relative positions of objects in Euclidean space are important in the comprehension of a wide range of spatial prepositions in English and other languages. We first the overview the functional geometric framework (Coventry \& Garrod, 2004) which puts ``what'' and ``where'' information together to underpin the situation specific meaning of spatial terms. We then outline an implementation of this framework. The computational model for the processing of visual scenes and the identification of the appropriate spatial preposition consists of three main modules: (1) Vision Processing, (2) Elman Network, (3) Dual-Route Network. Mirroring data from experiments with human participants, we show that the model is both able to predict what will happen to objects in a scene, and use these judgements to influence the appropriateness of over/under/above/below to describe where objects are located in the scene. Extensions of the model to other prepositions and quantifiers are discussed.},
  language = {en},
  booktitle = {Spatial {{Cognition IV}}. {{Reasoning}}, {{Action}}, {{Interaction}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Coventry, Kenny R. and Cangelosi, Angelo and Rajapakse, Rohanna and Bacon, Alison and Newstead, Stephen and Joyce, Dan and Richards, Lynn V.},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Freksa, Christian and Knauff, Markus and Krieg-Br{\"u}ckner, Bernd and Nebel, Bernhard and Barkowsky, Thomas},
  year = {2005},
  pages = {98-110},
  file = {/home/arildm/Zotero/storage/862VDN3D/Coventry et al. - 2005 - Spatial Prepositions and Vague Quantifiers Implem.pdf},
  doi = {10.1007/978-3-540-32255-9_6}
}

@phdthesis{DobnikTeachingmobilerobots2009,
  title = {Teaching Mobile Robots to Use Spatial Words},
  school = {The Queen's College, University of Oxford},
  author = {Dobnik, Simon},
  year = {2009},
  file = {/home/arildm/Zotero/storage/NFA7MGRT/thesis.pdf}
}

@article{DiamantCognitiveimageprocessing2014,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1411.0054},
  primaryClass = {cs, q-bio},
  title = {Cognitive Image Processing: The Time Is Right to Recognize That the World Does Not Rest More on Turtles and Elephants},
  shorttitle = {Cognitive Image Processing},
  abstract = {Traditional image processing is a field of science and technology developed to facilitate human-centered image management. But today, when huge volumes of visual data inundate our surroundings (due to the explosive growth of image-capturing devices, proliferation of Internet communication means and video sharing services over the World Wide Web), human-centered handling of Big-data flows is impossible anymore. Therefore, it has to be replaced with a machine (computer) supported counterpart. Of course, such an artificial counterpart must be equipped with some cognitive abilities, usually characteristic for a human being. Indeed, in the past decade, a new computer design trend - Cognitive Computer development - is become visible. Cognitive image processing definitely will be one of its main duties. It must be specially mentioned that this trend is a particular case of a much more general movement - the transition from a "computational data-processing paradigm" to a "cognitive information-processing paradigm", which affects today many fields of science, technology, and engineering. This transition is a blessed novelty, but its success is hampered by the lack of a clear delimitation between the notion of data and the notion of information. Elaborating the case of cognitive image processing, the paper intends to clarify these important research issues.},
  journal = {arXiv:1411.0054 [cs, q-bio]},
  author = {Diamant, Emanuel},
  month = oct,
  year = {2014},
  keywords = {Computer Science - Computers and Society,Quantitative Biology - Neurons and Cognition},
  file = {/home/arildm/Zotero/storage/LMCE8WN8/Diamant - 2014 - Cognitive image processing the time is right to r.pdf;/home/arildm/Zotero/storage/NT2KDZSI/1411.html}
}

@misc{Howthingstyp,
  title = {{How to do things with typ\ldots{}}},
  language = {sv},
  howpublished = {http://earlymoderntown.gu.se/forskning/publikation/?languageId=100000\&disableRedirect=true\&returnUrl=http\%3A\%2F\%2Fearlymoderntown.gu.se\%2Fenglish\%2Fresearch\%2Fpublication\%2F\%3FlanguageId\%3D100001\%26publicationId\%3D203076\&publicationId=203076},
  journal = {G{\"o}teborgs universitet}
}

@incollection{CoquandTypeTheory2015,
  edition = {Summer 2015},
  title = {Type {{Theory}}},
  abstract = {The topic of type theory is fundamental both in logic and computerscience. We limit ourselves here to sketch some aspects that areimportant in logic. For the importance of types in computer science, werefer the reader for instance to Reynolds 1983 and 1985.},
  booktitle = {The {{Stanford Encyclopedia}} of {{Philosophy}}},
  publisher = {{Metaphysics Research Lab, Stanford University}},
  author = {Coquand, Thierry},
  editor = {Zalta, Edward N.},
  year = {2015},
  keywords = {category theory,Frege; Gottlob,Frege; Gottlob: theorem and foundations for arithmetic,logic: paraconsistent,mathematics: inconsistent,Peano; Giuseppe,Principia Mathematica,Russell; Bertrand,type theory: Church's type theory,type theory: intuitionistic}
}

@article{church40,
  title = {A {{Formulation}} of the {{Simple Theory}} of {{Types}}},
  volume = {5},
  issn = {0022-4812},
  doi = {10.2307/2266170},
  abstract = {The purpose of the present paper is to give a formulation of the simple theory of types which incorporates certain features of the calculus of $\lambda$-conversion. A complete incorporation of the calculus of $\lambda$-conversion into the theory of types is impossible if we require that $\lambda$x and juxtaposition shall retain their respective meanings as an abstraction operator and as denoting the application of function to argument. But the present partial incorporation has certain advantages from the point of view of type theory and is offered as being of interest on this basis (whatever may be thought of the finally satisfactory character of the theory of types as a foundation for logic and mathematics).For features of the formulation which are not immediately connected with the incorporation of $\lambda$-conversion, we are heavily indebted to Whitehead and Russell, Hilbert and Ackermann, Hilbert and Bernays, and to forerunners of these, as the reader familiar with the works in question will recognize.The class of type symbols is described by the rules that {\i} and o are each type symbols and that if $\alpha$ and $\beta$ are type symbols then ($\alpha\beta$) is a type symbol: it is the least class of symbols which contains the symbols {\i} and o and is closed under the operation of forming the symbol ($\alpha\beta$) from the symbols $\alpha$ and $\beta$.},
  language = {eng},
  number = {2},
  journal = {The Journal of Symbolic Logic},
  author = {Church, Alonzo},
  month = jun,
  year = {1940},
  keywords = {Philosophy ; Mathematics;},
  pages = {56--68},
  file = {/home/arildm/Zotero/storage/D762AY5V/Church - 1940 - A Formulation of the Simple Theory of Types.pdf}
}

@article{BarwiseSituationsAttitudes1981,
  title = {Situations and {{Attitudes}}},
  volume = {78},
  number = {11},
  journal = {Journal of Philosophy},
  author = {Barwise, Jon and Perry, John},
  year = {1981},
  pages = {668--691},
  file = {/home/arildm/Zotero/storage/5PKPFD2Y/Barwise and Perry - 1981 - Situations and Attitudes.pdf}
}

@article{H.ClarkSpacetimesemantics1973,
  title = {Space, Time, Semantics, and the Child.},
  abstract = {Discusses man's capabilities and limitations as an element in a closed loop control system under normal environmental conditions. Factors considered include the nature of manual control, modes of tracking, mathematical models of human operators, and characteristics of controls and displays in tracking tasks. (21/2 p ref) (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
  journal = {Cognitive development and the acquisition of language},
  author = {H. Clark, Herbert},
  month = jan,
  year = {1973},
  file = {/home/arildm/Zotero/storage/3GCZM5EK/H. Clark - 1973 - Space, time, semantics, and the child..pdf}
}

@article{HarnadSymbolGroundingProblem1990,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {cs/9906002},
  title = {The {{Symbol Grounding Problem}}},
  volume = {42},
  issn = {01672789},
  doi = {10.1016/0167-2789(90)90087-6},
  abstract = {How can the semantic interpretation of a formal symbol system be made intrinsic to the system, rather than just parasitic on the meanings in our heads? How can the meanings of the meaningless symbol tokens, manipulated solely on the basis of their (arbitrary) shapes, be grounded in anything but other meaningless symbols? The problem is analogous to trying to learn Chinese from a Chinese/Chinese dictionary alone. A candidate solution is sketched: Symbolic representations must be grounded bottom-up in nonsymbolic representations of two kinds: (1) "iconic representations," which are analogs of the proximal sensory projections of distal objects and events, and (2) "categorical representations," which are learned and innate feature-detectors that pick out the invariant features of object and event categories from their sensory projections. Elementary symbols are the names of these object and event categories, assigned on the basis of their (nonsymbolic) categorical representations. Higher-order (3) "symbolic representations," grounded in these elementary symbols, consist of symbol strings describing category membership relations (e.g., "An X is a Y that is Z").},
  number = {1-3},
  journal = {Physica D: Nonlinear Phenomena},
  author = {Harnad, Stevan},
  month = jun,
  year = {1990},
  keywords = {Computer Science - Artificial Intelligence,I.2.0},
  pages = {335-346},
  file = {/home/arildm/Zotero/storage/CKSAVE8F/Harnad - 1990 - The Symbol Grounding Problem.pdf;/home/arildm/Zotero/storage/I6ZWDRJS/9906002.html}
}

@article{LarssonFormalsemanticsperceptual2015,
  title = {Formal Semantics for Perceptual Classification},
  volume = {25},
  issn = {0955-792X},
  doi = {10.1093/logcom/ext059},
  abstract = {A formal semantics for low-level perceptual aspects of meaning is presented, tying these together with the logical-inferential aspects of meaning traditionally studied in formal semantics. The key idea is to model perceptual meanings as classifiers of perceptual input . Furthermore, we show how perceptual aspects of meaning can be updated as a result of observing language use in interaction, thereby enabling fine-grained semantic plasticity and semantic coordination. This requires a framework where intensions are (i) represented independently of extensions, and (ii) structured objects which can be modified as a result of learning. We use Type Theory with Records (TTR), a formal semantics framework that starts from the idea that information and meaning is founded on our ability to perceive and classify the world, i.e. to perceive objects and situations as being of types. As an example of our approach, we show how a simple classifier of spatial information based on the Perceptron can be cast in TTR.},
  number = {2},
  journal = {Journal of Logic and Computation},
  author = {Larsson, Staffan},
  year = {2015},
  keywords = {compositionality,dialogue,formal semantics,learning,perception,statistical classifiers,symbol grounding,Type theoretic semantics},
  pages = {335--369},
  file = {/home/arildm/Zotero/storage/JMZAEC47/Larsson - 2015 - Formal semantics for perceptual classification.pdf;/home/arildm/Zotero/storage/CIF49XCM/954129.html}
}

@inproceedings{LarssonDialoguesHaveContent2011,
  title = {Do {{Dialogues Have Content}}?},
  volume = {6736},
  isbn = {978-3-642-22221-4},
  abstract = {In this paper, the notion of ``the content of a dialogue'' is shown to be problematic in light of the phenomena of semantic coordination in dialogue, and the associated notion of semantic plasticity \textendash{} the ability of meanings to change as a result of language use. Specifically, it appears that any notion of content in dialogue based on classical modeltheoretical semantics will be insufficient for capturing semantic plasticity. An alternative formal semantics, type theory with records (TTR) is briefly introduced and is show to be better equipped to deal with semantic coordination and plasticity. However, it is also argued that any account of content in dialogue which takes semantic coordination seriously will also need to consider the problems it raises for some concepts central to traditional notions of meaning, namely inference and truth.},
  language = {eng},
  booktitle = {Sylvain {{Pogodalla And Jean}}-{{Philippe Prost}}, {{Eds}}: {{Proceedings Of Logical Aspects Of Computational Linguistics}} ({{Lacl}} 2011), {{Springer Lecture Notes In Computer Science}}.},
  author = {Larsson, Staffan},
  year = {2011},
  keywords = {Filosofi,General Language Studies And Linguistics,Human Computer Interaction,Jämförande Språkvetenskap Och Lingvistik,Language Technology (Computational Linguistics),Languages And Literature,Människa-Datorinteraktion (Interaktionsdesign),Philosophy,Språk Och Litteratur,Språkteknologi (Språkvetenskaplig Databehandling)},
  file = {/home/arildm/Zotero/storage/HZWDHQWF/Larsson - 2011 - Do Dialogues Have Content.pdf}
}


