
@article{BlackburnComputationalsemantics2003,
  title = {Computational Semantics},
  journal = {Theoria: An International Journal for Theory, History and Foundations of Science},
  author = {Blackburn, Patrick and Bos, Johan},
  year = {2003},
  pages = {27--45},
  file = {/home/arildm/Zotero/storage/CJ9APB7P/BlackburnBos2003Theoria.pdf}
}

@article{ChatzikyriakidisTypeTheoryNatural2017,
  title = {Type {{Theory}} for {{Natural Language Semantics}}},
  author = {Chatzikyriakidis, Stergios and Cooper, Robin},
  year = {2017},
  keywords = {TTR,type theory},
  file = {/home/arildm/Zotero/storage/EJ6HP6GP/Chatzikyriakidis Cooper 2017 type-theory-natural.pdf}
}

@article{CooperRecordsRecordTypes2005,
  title = {Records and {{Record Types}} in {{Semantic Theory}}},
  volume = {15},
  issn = {0955-792X, 1465-363X},
  doi = {10.1093/logcom/exi004},
  language = {en},
  number = {2},
  journal = {Journal of Logic and Computation},
  author = {Cooper, R.},
  month = apr,
  year = {2005},
  keywords = {TTR},
  pages = {99--112},
  file = {/home/arildm/Zotero/storage/2FQHY3UG/Cooper 2005 Records_and_Record_Types_in_Semantic_Theory.pdf}
}

@article{CooperTypetheorysemantics2012,
  title = {Type Theory and Semantics in Flux},
  volume = {14},
  journal = {Handbook of the Philosophy of Science},
  author = {Cooper, Robin},
  year = {2012},
  keywords = {TTR,type theory},
  pages = {271--323},
  file = {/home/arildm/Zotero/storage/98QG5I2W/Cooper 2012 Type theory and semantics in flux.pdf}
}

@inproceedings{DobnikModellinglanguageaction2012,
  title = {Modelling Language, Action, and Perception in Type Theory with Records},
  booktitle = {International {{Workshop}} on {{Constraint Solving}} and {{Language Processing}}},
  publisher = {{Springer}},
  author = {Dobnik, Simon and Cooper, Robin and Larsson, Staffan},
  year = {2012},
  keywords = {TTR},
  pages = {70--91},
  file = {/home/arildm/Zotero/storage/FD4Z4XP3/Dobnik Cooper Larsson 2013 perceptual-ttr-post-proceedings-published-81140070.pdf}
}

@article{FernandoSituationsstrings2006,
  title = {Situations as Strings},
  volume = {165},
  journal = {Electronic Notes in Theoretical Computer Science},
  author = {Fernando, Tim},
  year = {2006},
  pages = {23--36},
  file = {/home/arildm/Zotero/storage/A3CLSDPV/Fernando 2006 Situations as strings.pdf}
}

@article{DobnikInterfacinglanguagespatial2017,
  title = {Interfacing Language, Spatial Perception and Cognition in {{Type Theory}} with {{Records}}},
  volume = {5},
  number = {2},
  journal = {Journal of Language Modelling},
  author = {Dobnik, Simon and Cooper, Robin},
  year = {2017},
  keywords = {TTR,spatial relations},
  pages = {273--301},
  file = {/home/arildm/Zotero/storage/3SUGE6PL/lspc.pdf}
}

@book{Martin-LofIntuitionistictypetheory1984,
  title = {Intuitionistic Type Theory},
  volume = {9},
  publisher = {{Bibliopolis Napoli}},
  author = {Martin-L{\"o}f, Per and Sambin, Giovanni},
  year = {1984},
  keywords = {type theory},
  file = {/home/arildm/Zotero/storage/ZJRGURBB/Martin-LÃ¶f 1984 Intuitionistic type theory.pdf}
}

@article{CooperTypetheorylanguage2016,
  title = {Type Theory and Language: From Perception to Linguistic Communication},
  shorttitle = {Type Theory and Language},
  journal = {Draft of book chapters available from https://sites. google. com/site/typetheorywithrecords/drafts},
  author = {Cooper, Robin},
  year = {2016},
  keywords = {TTR},
  file = {/home/arildm/Zotero/storage/KWNW8W58/ttl161130.pdf}
}

@inproceedings{Larssonformalviewcorrective2009,
  title = {Towards a Formal View of Corrective Feedback},
  booktitle = {Proceedings of the {{EACL}} 2009 {{Workshop}} on {{Cognitive Aspects}} of {{Computational Language Acquisition}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Larsson, Staffan and Cooper, Robin},
  year = {2009},
  keywords = {TTR,dialogue},
  pages = {1--9},
  file = {/home/arildm/Zotero/storage/QUQ5MXF6/Larsson and Cooper - 2009 - Towards a Formal View of Corrective Feedback.pdf}
}

@book{SimonCLASPPapersComputational2017,
  title = {{{CLASP Papers}} in {{Computational Linguistics}}: {{Proceedings}} of the {{Conference}} on {{Logic}} and {{Machine Learning}} in {{Natural Language}} ({{LaML}} 2017), {{Gothenburg}}, 12\textendash{}13 {{June}} 2017},
  abstract = {The past two decades have seen impressive progress in a variety of areas of AI, particularly NLP, through the application of machine learning methods to a wide range of tasks. With the intensive use of deep learning methods in recent years this work has produced significant improvements in the coverage and accuracy of NLP systems in such domains as speech recognition, topic identification, semantic interpretation, and image description generation. While deep learning is opening up exciting new approaches to long standing, difficult problems in computational linguistics, it also raises important foundational questions. Specifically, we do not have a clear formal understanding of why multi-level recursive deep neural networks achieve the success in learning and classification that they are delivering. It is also not obvious whether they should displace more traditional, logically driven methods, or be combined with them. Finally, we need to explore the extent, if any, to which both logical models and machine learning methods offer insights into the cognitive foundations of natural language. The aim of the Conference on Logic and Machine Learning in Natural Language (LAML) was to initiate a dialogue between these two approaches, where they have traditionally remained separate and in competition.},
  language = {eng},
  editor = {Simon, Dobnik and Shalom, Lappin},
  month = nov,
  year = {2017},
  file = {/home/arildm/Zotero/storage/63AK2K2T/Simon et al. - 2017 - CLASP Papers in Computational Linguistics.pdf;/home/arildm/Zotero/storage/CNCN6FDG/54911.html}
}

@misc{CooperSemanticsactionperception2017,
  title = {Semantics, Action and Perception - an Overview of {{TTR}}},
  author = {Cooper, Robin},
  year = {2017},
  keywords = {TTR},
  file = {/home/arildm/Zotero/storage/DYAYM47Y/eslp cooper ttr-lect-slides17.pdf}
}

@incollection{DybjerIntuitionisticTypeTheory2016,
  edition = {Winter 2016},
  title = {Intuitionistic {{Type Theory}}},
  abstract = {Intuitionistic type theory (also constructive type theory orMartin-L{\"o}f type theory) is a formal logical system and philosophicalfoundation for constructive mathematics. It is afull-scale system which aims to play a similar role for constructivemathematics as Zermelo-Fraenkel Set Theory does forclassical mathematics. It is based on the propositions-as-typesprinciple and clarifies the Brouwer-Heyting-Kolmogorov interpretationof intuitionistic logic. It extends this interpretation to the moregeneral setting of intuitionistic type theory and thus provides ageneral conception not only of what a constructive proof is, but alsoof what a constructive mathematical object is. The main idea is thatmathematical concepts such as elements, sets and functions areexplained in terms of concepts from programming such as datastructures, data types and programs. This article describes the formalsystem of intuitionistic type theory and its semantic foundations., In this entry, we first give an overview of the most importantaspects of intuitionistic type theory\textemdash{}a kind of ``extendedabstract''. It is meant for a reader who is already somewhatfamiliar with the theory. Section 2 on the other hand, is meant for areader who is new to intuitionistic type theory but familiar withtraditional logic, including propositional and predicate logic,arithmetic, and set theory. Here we informally introduce severalaspects which distinguishes intuitionistic type theory from thesetraditional theories. In Section 3 we present a basic version of thetheory, close to Martin-L{\"o}f's first published version from1972. The reader who was intrigued by the informality of Section 2will now see in detail how the theory is built up. Section 4 thenpresents a number of important extensions of the basic theory. Inparticular, it emphasizes the central role of inductive (andinductive-recursive) definitions. Section 5 introduces the underlyingphilosophical ideas including the theory of meaning developed byMartin-L{\"o}f. While Section 5 is about philosophy and foundations,Section 6 gives an overview of mathematical models of the theory. InSection 7 finally, we describe several important variations of thecore Martin-L{\"o}f ``intensional'' theory described inSection 3 and 4.},
  booktitle = {The {{Stanford Encyclopedia}} of {{Philosophy}}},
  publisher = {{Metaphysics Research Lab, Stanford University}},
  author = {Dybjer, Peter and Palmgren, Erik},
  editor = {Zalta, Edward N.},
  year = {2016},
  keywords = {type theory}
}

@article{DBLP:journals/corr/MalinowskiRF15,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1505.01121},
  title = {Ask {{Your Neurons}}: {{A Neural}}-Based {{Approach}} to {{Answering Questions}} about {{Images}}},
  volume = {abs/1505.01121},
  journal = {CoRR},
  author = {Malinowski, Mateusz and Rohrbach, Marcus and Fritz, Mario},
  year = {2015},
  biburl = {http://dblp.org/rec/bib/journals/corr/MalinowskiRF15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{imagenet_cvpr09,
  title = {{{ImageNet}}: {{A Large}}-{{Scale Hierarchical Image Database}}},
  booktitle = {{{CVPR09}}},
  author = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
  year = {2009},
  bibsource = {http://www.image-net.org/papers/imagenet<sub>c</sub>vpr09.bib}
}

@article{Detectron2018,
  title = {Detectron},
  author = {Girshick, Ross and Radosavovic, Ilija and Gkioxari, Georgia and Doll{\'a}r, Piotr and He, Kaiming},
  year = {2018}
}

@misc{pyttr,
  title = {{{PyTTR}}},
  author = {Cooper, Robin},
  year = {2017}
}

@article{RantaTypeTheoryUniversal2006,
  title = {Type {{Theory}} and {{Universal Grammar}}},
  copyright = {Tous droits r{\'e}serv{\'e}s},
  issn = {1281-2463},
  doi = {10.4000/philosophiascientiae.415},
  abstract = {The paper takes a look at the history of the idea of universal grammar and compares it with multilingual grammars, as formalized in the Grammatical Framework, GF. The constructivist idea of formalizing math$\-$ematics piece by piece, in a weak logical framework, rather than trying to reduce everything to one single strong theory, is the model that guides the development of grammars in GF.},
  language = {en},
  number = {CS 6},
  journal = {Philosophia Scienti{\ae}. Travaux d'histoire et de philosophie des sciences},
  author = {Ranta, Aarne},
  month = sep,
  year = {2006},
  pages = {115--131},
  file = {/home/arildm/Zotero/storage/AUFCFYVC/Ranta - 2006 - Type Theory and Universal Grammar.pdf;/home/arildm/Zotero/storage/MFG7YLYP/415.html}
}

@article{AndreasLearningComposeNeural2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1601.01705},
  primaryClass = {cs},
  title = {Learning to {{Compose Neural Networks}} for {{Question Answering}}},
  abstract = {We describe a question answering model that applies to both images and structured knowledge bases. The model uses natural language strings to automatically assemble neural networks from a collection of composable modules. Parameters for these modules are learned jointly with network-assembly parameters via reinforcement learning, with only (world, question, answer) triples as supervision. Our approach, which we term a dynamic neural model network, achieves state-of-the-art results on benchmark datasets in both visual and structured domains.},
  journal = {arXiv:1601.01705 [cs]},
  author = {Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
  month = jan,
  year = {2016},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Neural and Evolutionary Computing},
  file = {/home/arildm/Zotero/storage/W5Q4VZDY/Andreas et al. - 2016 - Learning to Compose Neural Networks for Question A.pdf;/home/arildm/Zotero/storage/A3UIGGIU/1601.html}
}

@article{RedmonYouOnlyLook2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1506.02640},
  primaryClass = {cs},
  title = {You {{Only Look Once}}: {{Unified}}, {{Real}}-{{Time Object Detection}}},
  shorttitle = {You {{Only Look Once}}},
  abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is far less likely to predict false detections where nothing exists. Finally, YOLO learns very general representations of objects. It outperforms all other detection methods, including DPM and R-CNN, by a wide margin when generalizing from natural images to artwork on both the Picasso Dataset and the People-Art Dataset.},
  journal = {arXiv:1506.02640 [cs]},
  author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  month = jun,
  year = {2015},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/arildm/Zotero/storage/2WVYT8AG/Redmon et al. - 2015 - You Only Look Once Unified, Real-Time Object Dete.pdf;/home/arildm/Zotero/storage/XUNRDBS7/1506.html}
}

@article{RedmonYOLO9000BetterFaster2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1612.08242},
  primaryClass = {cs},
  title = {{{YOLO9000}}: {{Better}}, {{Faster}}, {{Stronger}}},
  shorttitle = {{{YOLO9000}}},
  abstract = {We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that don't have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. But YOLO can detect more than just 200 classes; it predicts detections for more than 9000 different object categories. And it still runs in real-time.},
  journal = {arXiv:1612.08242 [cs]},
  author = {Redmon, Joseph and Farhadi, Ali},
  month = dec,
  year = {2016},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/arildm/Zotero/storage/75R4TWJL/Redmon and Farhadi - 2016 - YOLO9000 Better, Faster, Stronger.pdf;/home/arildm/Zotero/storage/BARLE6W4/1612.html}
}

@article{RegierGroundingspatiallanguage2001a,
  title = {Grounding Spatial Language in Perception: {{An}} Empirical and Computational Investigation},
  volume = {130},
  copyright = {\textcopyright{} 2001, American Psychological Association},
  issn = {0096-3445},
  shorttitle = {Grounding Spatial Language in Perception},
  doi = {http://dx.doi.org.ezproxy.ub.gu.se/10.1037/0096-3445.130.2.273},
  abstract = {The present paper grounds the linguistic categorization of space in aspects of visual perception; specifically, the structure of projective spatial terms such as above are grounded in the process of attention and in vector-sum coding of overall direction. This is formalized in the attentional vector-sum (AVS) model. This computational model accurately predicts linguistic acceptability judgments for spatial terms, under a variety of spatial configurations. In 7 experiments, the predictions of the AVS model are tested against those of 3 competing models. The results support the AVS model and disconfirm its competitors. The authors conclude that the structure of linguistic spatial categories can be partially explained in terms of independently motivated perceptual processes.},
  language = {English},
  number = {2},
  journal = {Journal of Experimental Psychology: General},
  author = {Regier, Terry and Carlson, Laura A.},
  month = jun,
  year = {2001},
  keywords = {Orientation; Pattern Recognition; Visual; Semantics; Space Perception; Verbal Learning;,Attention,Classification (Cognitive Process) (major),Judgment,Linguistics (major),Mathematical Modeling (major),Spatial Perception (major),Visual Perception (major),Words (Phonetic Units)},
  pages = {273--298},
  file = {/home/arildm/Zotero/storage/WISAXKBR/Regier and Carlson - 2001 - Grounding spatial language in perception An empir.pdf}
}

@misc{LoganComputationalAnalysisApprehension1996,
  title = {A {{Computational Analysis}} of the {{Apprehension}} of {{Spatial Relations}}},
  abstract = {Basic, deictic, \& intrinsic spatial relations distinguished in the literature motivate the proposal that apprehension of spatial relations requires (1) spatial indexing to instantiate basic relations, (2) reference frame computation to adjust parameters of the representation, (3) spatial template alignment to specify scope of acceptability of a given relation, \& (4) assessment of goodness of fit of spatial templates. These representations \& processes may be combined in various orders to perform relation judgments, cuing tasks, \& verification tasks. Evidence from previous psychological studies corroborates spatial indexing \& reference frame computation. Four experiments provide new evidence of the computation of goodness of fit between position of the located object \& a spatial template representing the relation that is centered on \& aligned with the reference object. In a production task, Ss (N = 68 undergraduates) indicated regions of space corresponding to areas of greatest acceptability of 12 spatial relations. In a goodness rating task, Ss (N = 32) ranked areas of space as good, acceptable, \& bad examples of 10 spatial relations in sentences corresponding to pictures. Results showed consistent representations of each notion. In a similarity rating task, Ss (N = 101) evaluated equivalence of pairs from a set of 12 lexicalized spatial terms. Similarities posited for underlying conceptual templates account for resemblances in results of goodness \& similarity rating tasks. Finally, a spatial relation judgment task measured reaction times of Ss (N = 48) to stimuli that systematically varied the distance between reference \& located objects. Results showed that distance minimally affected times, thus supporting the idea that spatial templates applied in parallel, rather than serial visual routines, process spatial relationships. It is concluded that spatial templates are useful for description of many spatial relation meanings. 1 Table, 12 Figures, 39 References. L. Lucht},
  language = {eng},
  author = {Logan, Gordon and Sadler, Daniel},
  collaborator = {Logan, Gordon},
  month = jan,
  year = {1996},
  keywords = {4011,bookitem,Bookitem,Computational Linguistics (14100),Deixis (17750),Language Processing (43550),production /rating tasks,Production /Rating Tasks,Psycholinguistics; Theories and Models,Space (81600),spatial relations processing; computational analysis,Spatial Relations Processing; Computational Analysis},
  file = {/home/arildm/Zotero/storage/V3UFFU6V/Logan and Sadler - 1996 - A Computational Analysis of the Apprehension of Sp.pdf}
}

@unpublished{CooperAustinianTruthAttitudes,
  title = {Austinian {{Truth}}, {{Attitudes}} and {{Type Theory}} \$$\backslash$ast\$},
  author = {Cooper, Robin}
}

@article{RobinCooperAustiniantruthattitudes2005,
  title = {Austinian Truth, Attitudes and Type Theory},
  language = {eng},
  author = {{Robin Cooper}},
  year = {2005},
  keywords = {HUMANIORA och RELIGIONSVETENSKAP|SprÃ¥kvetenskap|LingvistikÃ¤mnen|Datorlingvistik,HUMANITIES and RELIGION|Languages and linguistics|Linguistic subjects|Computational linguistics,NATURAL SCIENCES|Computer and Information Science|Language Technology (Computational Linguistics)|Computational linguistics,NATURVETENSKAP|Data- och informationsvetenskap|SprÃ¥kteknologi (sprÃ¥kvetenskaplig databehandling)|Datorlingvistik},
  file = {/home/arildm/Downloads/Cooper 2005 Austinian.pdf}
}


