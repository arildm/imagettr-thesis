
@article{BlackburnComputationalsemantics2003,
  title = {Computational Semantics},
  journal = {Theoria: An International Journal for Theory, History and Foundations of Science},
  author = {Blackburn, Patrick and Bos, Johan},
  year = {2003},
  pages = {27--45},
  file = {/home/arildm/Zotero/storage/CJ9APB7P/BlackburnBos2003Theoria.pdf}
}

@article{ChatzikyriakidisTypeTheoryNatural2017,
  title = {Type {{Theory}} for {{Natural Language Semantics}}},
  author = {Chatzikyriakidis, Stergios and Cooper, Robin},
  year = {2017},
  keywords = {TTR,type theory},
  file = {/home/arildm/Zotero/storage/EJ6HP6GP/Chatzikyriakidis Cooper 2017 type-theory-natural.pdf}
}

@article{CooperRecordsRecordTypes2005,
  title = {Records and {{Record Types}} in {{Semantic Theory}}},
  volume = {15},
  issn = {0955-792X, 1465-363X},
  doi = {10.1093/logcom/exi004},
  language = {en},
  number = {2},
  journal = {Journal of Logic and Computation},
  author = {Cooper, R.},
  month = apr,
  year = {2005},
  keywords = {TTR},
  pages = {99--112},
  file = {/home/arildm/Zotero/storage/2FQHY3UG/Cooper 2005 Records_and_Record_Types_in_Semantic_Theory.pdf}
}

@article{CooperTypetheorysemantics2012,
  title = {Type Theory and Semantics in Flux},
  volume = {14},
  journal = {Handbook of the Philosophy of Science},
  author = {Cooper, Robin},
  year = {2012},
  keywords = {TTR,type theory},
  pages = {271--323},
  file = {/home/arildm/Zotero/storage/98QG5I2W/Cooper 2012 Type theory and semantics in flux.pdf}
}

@inproceedings{DobnikModellinglanguageaction2012,
  title = {Modelling Language, Action, and Perception in Type Theory with Records},
  booktitle = {International {{Workshop}} on {{Constraint Solving}} and {{Language Processing}}},
  publisher = {{Springer}},
  author = {Dobnik, Simon and Cooper, Robin and Larsson, Staffan},
  year = {2012},
  keywords = {TTR},
  pages = {70--91},
  file = {/home/arildm/Zotero/storage/FD4Z4XP3/Dobnik Cooper Larsson 2013 perceptual-ttr-post-proceedings-published-81140070.pdf}
}

@article{FernandoSituationsstrings2006,
  title = {Situations as Strings},
  volume = {165},
  journal = {Electronic Notes in Theoretical Computer Science},
  author = {Fernando, Tim},
  year = {2006},
  pages = {23--36},
  file = {/home/arildm/Zotero/storage/A3CLSDPV/Fernando 2006 Situations as strings.pdf}
}

@article{DobnikInterfacinglanguagespatial2017,
  title = {Interfacing Language, Spatial Perception and Cognition in {{Type Theory}} with {{Records}}},
  volume = {5},
  number = {2},
  journal = {Journal of Language Modelling},
  author = {Dobnik, Simon and Cooper, Robin},
  year = {2017},
  keywords = {TTR,spatial relations},
  pages = {273--301},
  file = {/home/arildm/Zotero/storage/3SUGE6PL/lspc.pdf}
}

@book{Martin-LofIntuitionistictypetheory1984,
  title = {Intuitionistic Type Theory},
  volume = {9},
  publisher = {{Bibliopolis Napoli}},
  author = {Martin-L{\"o}f, Per and Sambin, Giovanni},
  year = {1984},
  keywords = {type theory},
  file = {/home/arildm/Zotero/storage/ZJRGURBB/Martin-LÃ¶f 1984 Intuitionistic type theory.pdf}
}

@article{CooperTypetheorylanguage2016,
  title = {Type Theory and Language: From Perception to Linguistic Communication},
  shorttitle = {Type Theory and Language},
  journal = {Draft of book chapters available from https://sites. google. com/site/typetheorywithrecords/drafts},
  author = {Cooper, Robin},
  year = {2016},
  keywords = {TTR},
  file = {/home/arildm/Zotero/storage/KWNW8W58/ttl161130.pdf}
}

@inproceedings{Larssonformalviewcorrective2009,
  title = {Towards a Formal View of Corrective Feedback},
  booktitle = {Proceedings of the {{EACL}} 2009 {{Workshop}} on {{Cognitive Aspects}} of {{Computational Language Acquisition}}},
  publisher = {{Association for Computational Linguistics}},
  author = {Larsson, Staffan and Cooper, Robin},
  year = {2009},
  keywords = {TTR,dialogue},
  pages = {1--9},
  file = {/home/arildm/Zotero/storage/QUQ5MXF6/Larsson and Cooper - 2009 - Towards a Formal View of Corrective Feedback.pdf}
}

@misc{CooperSemanticsactionperception2017,
  title = {Semantics, Action and Perception - an Overview of {{TTR}}},
  author = {Cooper, Robin},
  year = {2017},
  keywords = {TTR},
  file = {/home/arildm/Zotero/storage/DYAYM47Y/eslp cooper ttr-lect-slides17.pdf}
}

@incollection{DybjerIntuitionisticTypeTheory2016,
  edition = {Winter 2016},
  title = {Intuitionistic {{Type Theory}}},
  abstract = {Intuitionistic type theory (also constructive type theory orMartin-L{\"o}f type theory) is a formal logical system and philosophicalfoundation for constructive mathematics. It is afull-scale system which aims to play a similar role for constructivemathematics as Zermelo-Fraenkel Set Theory does forclassical mathematics. It is based on the propositions-as-typesprinciple and clarifies the Brouwer-Heyting-Kolmogorov interpretationof intuitionistic logic. It extends this interpretation to the moregeneral setting of intuitionistic type theory and thus provides ageneral conception not only of what a constructive proof is, but alsoof what a constructive mathematical object is. The main idea is thatmathematical concepts such as elements, sets and functions areexplained in terms of concepts from programming such as datastructures, data types and programs. This article describes the formalsystem of intuitionistic type theory and its semantic foundations., In this entry, we first give an overview of the most importantaspects of intuitionistic type theory\textemdash{}a kind of ``extendedabstract''. It is meant for a reader who is already somewhatfamiliar with the theory. Section 2 on the other hand, is meant for areader who is new to intuitionistic type theory but familiar withtraditional logic, including propositional and predicate logic,arithmetic, and set theory. Here we informally introduce severalaspects which distinguishes intuitionistic type theory from thesetraditional theories. In Section 3 we present a basic version of thetheory, close to Martin-L{\"o}f's first published version from1972. The reader who was intrigued by the informality of Section 2will now see in detail how the theory is built up. Section 4 thenpresents a number of important extensions of the basic theory. Inparticular, it emphasizes the central role of inductive (andinductive-recursive) definitions. Section 5 introduces the underlyingphilosophical ideas including the theory of meaning developed byMartin-L{\"o}f. While Section 5 is about philosophy and foundations,Section 6 gives an overview of mathematical models of the theory. InSection 7 finally, we describe several important variations of thecore Martin-L{\"o}f ``intensional'' theory described inSection 3 and 4.},
  booktitle = {The {{Stanford Encyclopedia}} of {{Philosophy}}},
  publisher = {{Metaphysics Research Lab, Stanford University}},
  author = {Dybjer, Peter and Palmgren, Erik},
  editor = {Zalta, Edward N.},
  year = {2016},
  keywords = {type theory}
}

@article{DBLP:journals/corr/HeZRS15,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1512.03385},
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  volume = {abs/1512.03385},
  journal = {CoRR},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2015},
  biburl = {http://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{DBLP:journals/corr/Graves13,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1308.0850},
  title = {Generating {{Sequences With Recurrent Neural Networks}}},
  volume = {abs/1308.0850},
  journal = {CoRR},
  author = {Graves, Alex},
  year = {2013},
  biburl = {http://dblp.org/rec/bib/journals/corr/Graves13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{Hochreiter:1997:LSM:1246443.1246450,
  title = {Long {{Short}}-{{Term Memory}}},
  volume = {9},
  issn = {0899-7667},
  doi = {10.1162/neco.1997.9.8.1735},
  number = {8},
  journal = {Neural Comput.},
  author = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  month = nov,
  year = {1997},
  pages = {1735--1780},
  publisher = {{MIT Press}},
  location = {Cambridge, MA, USA},
  issue_date = {November 15, 1997},
  numpages = {46},
  acmid = {1246450}
}

@article{DBLP:journals/corr/MalinowskiRF15,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1505.01121},
  title = {Ask {{Your Neurons}}: {{A Neural}}-Based {{Approach}} to {{Answering Questions}} about {{Images}}},
  volume = {abs/1505.01121},
  journal = {CoRR},
  author = {Malinowski, Mateusz and Rohrbach, Marcus and Fritz, Mario},
  year = {2015},
  biburl = {http://dblp.org/rec/bib/journals/corr/MalinowskiRF15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{imagenet_cvpr09,
  title = {{{ImageNet}}: {{A Large}}-{{Scale Hierarchical Image Database}}},
  booktitle = {{{CVPR09}}},
  author = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
  year = {2009},
  bibsource = {http://www.image-net.org/papers/imagenet<sub>c</sub>vpr09.bib}
}

@article{Detectron2018,
  title = {Detectron},
  author = {Girshick, Ross and Radosavovic, Ilija and Gkioxari, Georgia and Doll{\'a}r, Piotr and He, Kaiming},
  year = {2018}
}

@misc{pyttr,
  title = {{{PyTTR}}},
  author = {Cooper, Robin},
  year = {2017}
}

@article{RantaTypeTheoryUniversal2006,
  title = {Type {{Theory}} and {{Universal Grammar}}},
  copyright = {Tous droits r{\'e}serv{\'e}s},
  issn = {1281-2463},
  doi = {10.4000/philosophiascientiae.415},
  abstract = {The paper takes a look at the history of the idea of universal grammar and compares it with multilingual grammars, as formalized in the Grammatical Framework, GF. The constructivist idea of formalizing math$\-$ematics piece by piece, in a weak logical framework, rather than trying to reduce everything to one single strong theory, is the model that guides the development of grammars in GF.},
  language = {en},
  number = {CS 6},
  journal = {Philosophia Scienti{\ae}. Travaux d'histoire et de philosophie des sciences},
  author = {Ranta, Aarne},
  month = sep,
  year = {2006},
  pages = {115--131},
  file = {/home/arildm/Zotero/storage/AUFCFYVC/Ranta - 2006 - Type Theory and Universal Grammar.pdf;/home/arildm/Zotero/storage/MFG7YLYP/415.html}
}

@article{AndreasLearningComposeNeural2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1601.01705},
  primaryClass = {cs},
  title = {Learning to {{Compose Neural Networks}} for {{Question Answering}}},
  abstract = {We describe a question answering model that applies to both images and structured knowledge bases. The model uses natural language strings to automatically assemble neural networks from a collection of composable modules. Parameters for these modules are learned jointly with network-assembly parameters via reinforcement learning, with only (world, question, answer) triples as supervision. Our approach, which we term a dynamic neural model network, achieves state-of-the-art results on benchmark datasets in both visual and structured domains.},
  journal = {arXiv:1601.01705 [cs]},
  author = {Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
  month = jan,
  year = {2016},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Neural and Evolutionary Computing},
  file = {/home/arildm/Zotero/storage/W5Q4VZDY/Andreas et al. - 2016 - Learning to Compose Neural Networks for Question A.pdf;/home/arildm/Zotero/storage/A3UIGGIU/1601.html}
}

@article{CocchiarellaReviewSituationsAttitudes1986,
  title = {Review of {{Situations}} and {{Attitudes}}},
  volume = {51},
  issn = {0022-4812},
  doi = {10.2307/2274074},
  number = {2},
  journal = {The Journal of Symbolic Logic},
  author = {Cocchiarella, Nino B.},
  collaborator = {Barwise, Jon and Perry, John},
  year = {1986},
  pages = {470--472}
}

@article{RedmonYouOnlyLook2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1506.02640},
  primaryClass = {cs},
  title = {You {{Only Look Once}}: {{Unified}}, {{Real}}-{{Time Object Detection}}},
  shorttitle = {You {{Only Look Once}}},
  abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is far less likely to predict false detections where nothing exists. Finally, YOLO learns very general representations of objects. It outperforms all other detection methods, including DPM and R-CNN, by a wide margin when generalizing from natural images to artwork on both the Picasso Dataset and the People-Art Dataset.},
  journal = {arXiv:1506.02640 [cs]},
  author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  month = jun,
  year = {2015},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/arildm/Zotero/storage/2WVYT8AG/Redmon et al. - 2015 - You Only Look Once Unified, Real-Time Object Dete.pdf;/home/arildm/Zotero/storage/XUNRDBS7/1506.html}
}

@article{RedmonYOLO9000BetterFaster2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1612.08242},
  primaryClass = {cs},
  title = {{{YOLO9000}}: {{Better}}, {{Faster}}, {{Stronger}}},
  shorttitle = {{{YOLO9000}}},
  abstract = {We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that don't have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. But YOLO can detect more than just 200 classes; it predicts detections for more than 9000 different object categories. And it still runs in real-time.},
  journal = {arXiv:1612.08242 [cs]},
  author = {Redmon, Joseph and Farhadi, Ali},
  month = dec,
  year = {2016},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/arildm/Zotero/storage/75R4TWJL/Redmon and Farhadi - 2016 - YOLO9000 Better, Faster, Stronger.pdf;/home/arildm/Zotero/storage/BARLE6W4/1612.html}
}

@article{RedmonYOLO9000BetterFaster2016a,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1612.08242},
  primaryClass = {cs},
  title = {{{YOLO9000}}: {{Better}}, {{Faster}}, {{Stronger}}},
  shorttitle = {{{YOLO9000}}},
  abstract = {We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that don't have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. But YOLO can detect more than just 200 classes; it predicts detections for more than 9000 different object categories. And it still runs in real-time.},
  journal = {arXiv:1612.08242 [cs]},
  author = {Redmon, Joseph and Farhadi, Ali},
  month = dec,
  year = {2016},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/arildm/Zotero/storage/45NTGG8C/Redmon and Farhadi - 2016 - YOLO9000 Better, Faster, Stronger.pdf;/home/arildm/Zotero/storage/GBSZUB8J/1612.html}
}

@article{RegierGroundingspatiallanguage2001,
  title = {Grounding Spatial Language in Perception: An Empirical and Computational Investigation},
  volume = {130},
  issn = {0096-3445},
  shorttitle = {Grounding Spatial Language in Perception},
  abstract = {The present paper grounds the linguistic cdategorization of space in aspects of visual perception; specifically, the structure of projective spatial terms such as above are grounded in the process of attention and in vector-sum coding of overall direction. This is formalized in the attentional vector-sum (AVS) model. This computational model accurately predicts linguistic acceptability judgments for spatial terms, under a variety of spatial configurations. In 7 experiments, the predictions of the AVS model are tested against those of 3 competing models. The results support the AVS model and disconfirm its competitors. The authors conclude that the structure of linguistic spatial categories can be partially explained in terms of independently motivated perceptual processes.},
  language = {eng},
  number = {2},
  journal = {Journal of Experimental Psychology. General},
  author = {Regier, T. and Carlson, L. A.},
  month = jun,
  year = {2001},
  keywords = {Adult,Discrimination Learning,Female,Humans,Male,Orientation,Pattern Recognition; Visual,Psycholinguistics,Semantics,Space Perception,Verbal Learning},
  pages = {273--298},
  pmid = {11409104}
}

@article{RegierGroundingspatiallanguage2001a,
  title = {Grounding Spatial Language in Perception: {{An}} Empirical and Computational Investigation},
  volume = {130},
  copyright = {\textcopyright{} 2001, American Psychological Association},
  issn = {0096-3445},
  shorttitle = {Grounding Spatial Language in Perception},
  doi = {http://dx.doi.org.ezproxy.ub.gu.se/10.1037/0096-3445.130.2.273},
  abstract = {The present paper grounds the linguistic categorization of space in aspects of visual perception; specifically, the structure of projective spatial terms such as above are grounded in the process of attention and in vector-sum coding of overall direction. This is formalized in the attentional vector-sum (AVS) model. This computational model accurately predicts linguistic acceptability judgments for spatial terms, under a variety of spatial configurations. In 7 experiments, the predictions of the AVS model are tested against those of 3 competing models. The results support the AVS model and disconfirm its competitors. The authors conclude that the structure of linguistic spatial categories can be partially explained in terms of independently motivated perceptual processes.},
  language = {English},
  number = {2},
  journal = {Journal of Experimental Psychology: General},
  author = {Regier, Terry and Carlson, Laura A.},
  month = jun,
  year = {2001},
  keywords = {Orientation; Pattern Recognition; Visual; Semantics; Space Perception; Verbal Learning;,Attention,Classification (Cognitive Process) (major),Judgment,Linguistics (major),Mathematical Modeling (major),Spatial Perception (major),Visual Perception (major),Words (Phonetic Units)},
  pages = {273--298},
  file = {/home/arildm/Zotero/storage/WISAXKBR/Regier and Carlson - 2001 - Grounding spatial language in perception An empir.pdf}
}

@misc{LoganComputationalAnalysisApprehension1996,
  title = {A {{Computational Analysis}} of the {{Apprehension}} of {{Spatial Relations}}},
  abstract = {Basic, deictic, \& intrinsic spatial relations distinguished in the literature motivate the proposal that apprehension of spatial relations requires (1) spatial indexing to instantiate basic relations, (2) reference frame computation to adjust parameters of the representation, (3) spatial template alignment to specify scope of acceptability of a given relation, \& (4) assessment of goodness of fit of spatial templates. These representations \& processes may be combined in various orders to perform relation judgments, cuing tasks, \& verification tasks. Evidence from previous psychological studies corroborates spatial indexing \& reference frame computation. Four experiments provide new evidence of the computation of goodness of fit between position of the located object \& a spatial template representing the relation that is centered on \& aligned with the reference object. In a production task, Ss (N = 68 undergraduates) indicated regions of space corresponding to areas of greatest acceptability of 12 spatial relations. In a goodness rating task, Ss (N = 32) ranked areas of space as good, acceptable, \& bad examples of 10 spatial relations in sentences corresponding to pictures. Results showed consistent representations of each notion. In a similarity rating task, Ss (N = 101) evaluated equivalence of pairs from a set of 12 lexicalized spatial terms. Similarities posited for underlying conceptual templates account for resemblances in results of goodness \& similarity rating tasks. Finally, a spatial relation judgment task measured reaction times of Ss (N = 48) to stimuli that systematically varied the distance between reference \& located objects. Results showed that distance minimally affected times, thus supporting the idea that spatial templates applied in parallel, rather than serial visual routines, process spatial relationships. It is concluded that spatial templates are useful for description of many spatial relation meanings. 1 Table, 12 Figures, 39 References. L. Lucht},
  language = {eng},
  author = {Logan, Gordon and Sadler, Daniel},
  collaborator = {Logan, Gordon},
  month = jan,
  year = {1996},
  keywords = {4011,bookitem,Bookitem,Computational Linguistics (14100),Deixis (17750),Language Processing (43550),production /rating tasks,Production /Rating Tasks,Psycholinguistics; Theories and Models,Space (81600),spatial relations processing; computational analysis,Spatial Relations Processing; Computational Analysis},
  file = {/home/arildm/Zotero/storage/V3UFFU6V/Logan and Sadler - 1996 - A Computational Analysis of the Apprehension of Sp.pdf}
}

@unpublished{CooperAustinianTruthAttitudes,
  title = {Austinian {{Truth}}, {{Attitudes}} and {{Type Theory}} \$$\backslash$ast\$},
  author = {Cooper, Robin}
}

@article{RobinCooperAustiniantruthattitudes2005,
  title = {Austinian Truth, Attitudes and Type Theory},
  language = {eng},
  author = {{Robin Cooper}},
  year = {2005},
  keywords = {HUMANIORA och RELIGIONSVETENSKAP|SprÃ¥kvetenskap|LingvistikÃ¤mnen|Datorlingvistik,HUMANITIES and RELIGION|Languages and linguistics|Linguistic subjects|Computational linguistics,NATURAL SCIENCES|Computer and Information Science|Language Technology (Computational Linguistics)|Computational linguistics,NATURVETENSKAP|Data- och informationsvetenskap|SprÃ¥kteknologi (sprÃ¥kvetenskaplig databehandling)|Datorlingvistik},
  file = {/home/arildm/Downloads/Cooper 2005 Austinian.pdf}
}

@inproceedings{DobnikSpatialDescriptionsType2013,
  address = {Potsdam, Germany},
  title = {Spatial {{Descriptions}} in {{Type Theory}} with {{Records}}},
  booktitle = {Proceedings of {{IWCS}} 2013 {{Workshop}} on {{Computational Models}} of {{Spatial Language Interpretation}} and {{Generation}} ({{CoSLI}}-3)},
  publisher = {{Association for Computational Linguistics}},
  author = {Dobnik, Simon and Cooper, Robin},
  month = mar,
  year = {2013},
  pages = {1--6},
  file = {/home/arildm/Zotero/storage/SXULHG3L/Dobnik and Cooper - 2013 - Spatial Descriptions in Type Theory with Records.pdf}
}

@inproceedings{Dobnik:2017ag,
  series = {CLASP Papers in Computational Linguistics},
  title = {Modular Mechanistic Networks: {{On}} Bridging Mechanistic and Phenomenological Models with Deep Neural Networks in Natural Language Processing},
  booktitle = {Proceedings of the {{Conference}} on {{Logic}} and {{Machine Learning}} in {{Natural Language}} ({{LaML}} 2017), {{Gothenburg}}, 12--13 {{June}} 2017},
  author = {Dobnik, Simon and Kelleher, John D.},
  pages = {1--11},
  file = {/home/arildm/Zotero/storage/52YJE6NF/mechanistic-phenomenological-models-in-nlp.pdf},
  crossref = {LaML-Proceeedings:2017}
}

@book{LaML-Proceeedings:2017,
  address = {Gothenburg, Sweden},
  title = {{{CLASP Papers}} in {{Computational Linguistics}}: {{Proceedings}} of the {{Conference}} on {{Logic}} and {{Machine Learning}} in {{Natural Language}} ({{LaML}} 2017), {{Gothenburg}}, 12 --13 {{June}}},
  volume = {1},
  publisher = {{CLASP, Centre for Language and Studies in Probability}},
  editor = {Dobnik, Simon and Lappin, Shalom},
  month = nov,
  year = {2017},
  file = {/home/arildm/Zotero/storage/63AK2K2T/Simon et al. - 2017 - CLASP Papers in Computational Linguistics.pdf;/home/arildm/Zotero/storage/CNCN6FDG/54911.html},
  organization = {Department of Philosophy, Linguistics and Theory of Science (FLOV), University of Gothenburg}
}

@article{RoySemioticschemasframework2005,
  title = {Semiotic Schemas: {{A}} Framework for Grounding Language in Action and Perception},
  volume = {167},
  issn = {0004-3702},
  shorttitle = {Semiotic Schemas},
  doi = {10.1016/j.artint.2005.04.007},
  abstract = {A theoretical framework for grounding language is introduced that provides a computational path from sensing and motor action to words and speech acts. The approach combines concepts from semiotics and schema theory to develop a holistic approach to linguistic meaning. Schemas serve as structured beliefs that are grounded in an agent's physical environment through a causal-predictive cycle of action and perception. Words and basic speech acts are interpreted in terms of grounded schemas. The framework reflects lessons learned from implementations of several language processing robots. It provides a basis for the analysis and design of situated, multimodal communication systems that straddle symbolic and non-symbolic realms.},
  language = {eng},
  number = {1},
  journal = {Artificial Intelligence},
  author = {Roy, Deb},
  year = {2005},
  keywords = {Action,Cross-Modal,Embodied,Grounding,Language,Meaning,Multimodal,Perception,Representation,Schemas,Semiotic,Situated},
  pages = {170--205},
  file = {/home/arildm/Zotero/storage/DA2BGULL/1-s2.0-S0004370205001037-main.pdf}
}

@inproceedings{PustejovskyPerceptualsemanticsconstruction1990,
  title = {Perceptual Semantics: The Construction of Meaning in Artificial Devices},
  shorttitle = {Perceptual Semantics},
  doi = {10.1109/ISIC.1990.128445},
  abstract = {The design of an artificial device that can acquire its own perceptually grounded meanings for internally represented control structure is discussed. A perceptual semantics, in which perceptual routines are mapped onto innate conceptual operators, is described. Entities and relations in the environment take on `meaning' for the device in three forms: the connotation, which is the internal encoding of an object within a syntactic discrimination lattice; the annotation, which is a procedural encoding of how connotations are translated into action/perception; and the denotation, which is the action associated with a procedure within the action-percept feedback loop. The author argues against model-theoretic interpretations for semantics of devices interacting within their environment, and in favor of pragmatically determined models of meaning},
  booktitle = {Proceedings. 5th {{IEEE International Symposium}} on {{Intelligent Control}} 1990},
  author = {Pustejovsky, J.},
  month = sep,
  year = {1990},
  keywords = {action-percept feedback loop,adaptive control,annotation,artificial devices,Artificial intelligence,cognitive systems,Computer science,computer vision,conceptual representation,denotation,Encoding,feedback,Feedback loop,Grounding,innate conceptual operators,Intelligent robots,Intelligent sensors,internal encoding,internally represented control structure,Lattices,learning systems,perceptual routines,perceptual semantics,perceptually grounded meanings,procedural encoding,Robot sensing systems,robot vision,robots,syntactic discrimination lattice,Testing},
  pages = {86--91 vol.1},
  file = {/home/arildm/Zotero/storage/7M4BCIIT/Pustejovsky - 1990 - Perceptual semantics the construction of meaning .pdf;/home/arildm/Zotero/storage/P692Y9RQ/128445.html}
}

@article{GuptaSurveyVisualQuestion2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1705.03865},
  primaryClass = {cs},
  title = {Survey of {{Visual Question Answering}}: {{Datasets}} and {{Techniques}}},
  shorttitle = {Survey of {{Visual Question Answering}}},
  abstract = {Visual question answering (or VQA) is a new and exciting problem that combines natural language processing and computer vision techniques. We present a survey of the various datasets and models that have been used to tackle this task. The first part of the survey details the various datasets for VQA and compares them along some common factors. The second part of this survey details the different approaches for VQA, classified into four types: non-deep learning models, deep learning models without attention, deep learning models with attention, and other models which do not fit into the first three. Finally, we compare the performances of these approaches and provide some directions for future work.},
  journal = {arXiv:1705.03865 [cs]},
  author = {Gupta, Akshay Kumar},
  month = may,
  year = {2017},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/arildm/Zotero/storage/48GX3FA7/Gupta - 2017 - Survey of Visual Question Answering Datasets and .pdf;/home/arildm/Zotero/storage/IEZCNAWM/1705.html}
}

@article{CooperNegationdialogue2018,
  title = {Negation in Dialogue},
  abstract = {We consider the nature of negation in di-alogue as revealed by semantic phenomena such as negative dialogue particles, psycholin-guistic experimentation, and dialogue corpora. We examine alternative accounts of negation that can be used in TTR (Type Theory with Records), and conclude that an alternatives-based account which relates to the psycholog-ical notion of negation in simulation seman-tics is most appropriate. We show how this account relates to questions under discussion, dialogical relevance, and metalinguistic nega-tion.},
  author = {Cooper, Robin and Ginzburg, Jonathan},
  month = apr,
  year = {2018},
  file = {/home/arildm/Zotero/storage/W9MAYJGK/Negation_in_dialogue.pdf}
}


