\section{Results}
\label{sec:results}

%In this section, the model is defined.
%First formally, in \gls{ttr}.
%Then, parts of the Python source is presented, including PyTTR usage.




\subsection{Subtype relabeling}

This model uses TTR record types to model situations.
The two main situations in action are the perceived \textit{scene} and the statement expressed in a natural-language \textit{question}.
In this project, the language is restricted to polar (yes/no) questions.
Such a question has a corresponding declarative statement:
The question ``Can you see them?'' corresponds to the statement ``You can see them''.
Responding to such a question entails checking if the scene type is a \textit{subtype} of the question type.
[SOURCE?]

[TODO check \cite{RooyPolarQuestions2003}, (sources of) \cite{AloniQuantificationConceptualCovers2001}]

In TTR, however, subtype checking is not enough.
The fields in a record type are labeled, and they will not necessarily be the same in the scene type and the question type.
This prompts for a more advanced variant of subtype checking, allowing \textit{relabeling}.

\begin{definition}[Relabel-subtype]
A record type $S$ is a \textbf{relabel-subtype} of the record type $Q$ if there is a relabeling $\eta$ of $S$, $S_\eta$, such that $S_\eta \sqsubseteq Q$.
\end{definition}

The number of relabelings in one record type, to the labels of another, can be quite large:
If $S$ has 20 fields and $Q$ has five, then there are $\dfrac{20!}{(20-5)!} = 1\,860\,480$ relabelings of Q (the number of 5-permutations of 20).
It is practically impossible to perform all relabelings and check whether subtypeness holds.
An alternative algorithm is presented below for the purpose of this project.
Fast computation is enabled by making a few assumptions about the input record types.

\paragraph{Prerequisites}

\begin{itemize}
\item Any dependent fields depend only on basic (non-dependent) fields (basic or singleton type)
\item No nested record types (this could be solved using flattening but it's not needed in this scope)
\end{itemize}

\paragraph{Algorithm}

\begin{enumerate}
\item For each basic-field relabeling of Q:
    \begin{enumerate}
    \item For each complex field in Q:
        \begin{enumerate}
        \item Find a subtype field in S and remember it
        \item If no subtype field was found, skip to next basic-field relabeling
        \end{enumerate}
    \item A subtype S field was found for all complex Q fields; return the relabeling
    \end{enumerate}
\item Return nothing
\end{enumerate}

Now only the basic fields are included when considering relabelings of Q.
If $S$ has eight basic fields and $Q$ has two, there are only $\dfrac{8!}{(8-2)!} = 56$ relabelings.
For each relabeling, the remaining fields are subtype-checked in a nested loop with early exit.

[what is this in terms of big-O?]

A Python implementation is given in \autoref{lst:find_subtype_relabeling}.

\begin{lstlisting}[label={lst:find_subtype_relabeling}, caption=The \texttt{find\_subtype\_relabeling} function]
from itertools import permutations, combinations

def my_subtype_of(sub, sup):
    """Is T a subtype of U? Accept dependent rectype fields (= (fun, args) tuples) with simplistic equality test."""
    try:
        return sub.subtype_of(sup)
    except AttributeError:
        return isinstance(sub, tuple) and isinstance(sup, tuple) and show(sub) == show(sup)

def find_subtype_relabeling(S, Q):
    '''Could record type S be a sub type of record type Q if relabeling in Q is allowed?'''
    # For each relabeling of basic-type fields
    for sls in permutations(basic_fields(S), len(basic_fields(Q))):
        # Try the basic-fields relabeling of Q
        rlb_basic = dict(zip(basic_fields(Q), sls))
        Q2 = rectype_relabels(Q, rlb_basic)
        
        # For each Q field, find a S field that is a subtype
        rlb_dep = dict()
        for ql in nonbasic_fields(Q2):
            for sl in nonbasic_fields(S):
                # The new labels must be unique.
                if sl in rlb_dep.values(): continue
                if my_subtype_of(S.field(sl), Q2.field(ql)):
                    rlb_dep[ql] = sl
                    break
            if ql not in rlb_dep:
                break

        # Successful if all non-basic fields match.
        if len(rlb_dep) == len(nonbasic_fields(Q2)):
            return dict(**rlb_basic, **rlb_dep)
    return None
\end{lstlisting}




\subsection{\Acrshort{ttr} model}
\label{ssec:ttrmodel}

The types in the \gls{ttr} model are largely based on \cite{lspc}, but the $Segment$ type is new, the individuation function is improved and the $RelClf$ mechanism is more concretely defined.
The $Agent$ type is also new.

Three basic types exist in the model.

\begin{description}
\item [$Ind$] A single individual object, such as the reader or the Eiffel Tower.
\item [$Int$] An integer, such as 415.
\item [$Image$] A 2-dimensional digital image. It serves as an identifier to a set of extracted information, and its file type and actual data is not important in this thesis.
\end{description}

A $Segment$ is a record type describing a rectangular bounding box within an (implicit) image (\autoref{eq:seg}).
Its fields contain the center coordinates of the box ($cx$ and $cy$) and the width ($w$) and height ($h$) of the box.
$Ppty$ is the type of functions that can be applied to an individual and return a type (\autoref{eq:ppty}).
In our account the resulting type will be restricted to a ptype that is dependent on the individual, thus describing a property of it.

\begin{equation}\label{eq:seg}
Segment = \left[\begin{array}{rcl}
\text{cx} &:& Int\\
\text{cy} &:& Int\\
\text{w} &:& Int\\
\text{h} &:& Int
\end{array}\right]\end{equation}

\begin{equation}\label{eq:ppty}
Ppty = (Ind \rightarrow Type)\end{equation}

%[PTy?]

A perceptual object is a record of the record type $Obj$ (\autoref{eq:obj}).
It contains a bounding box (the `seg' field) and a property (`pfun').
An example record is given in \autoref{eq:objrec}.
%$Obj$ records are the result of performing \textit{object detection}.
%This fact is expressed in TTR as the function type $ObjDetector$ (\autoref{eq:objdetector}).
An object detector is a function from an image to a set of such perceptual objects, as captured by the $ObjDetector$ function type (\autoref{eq:objdetector}).

%[differences/similarites LSPC and others]

\begin{equation}\label{eq:obj}
Obj = \left[\begin{array}{rcl}
\text{seg} &:& Segment\\
\text{pfun} &:& Ppty \\
\end{array}\right]\end{equation}

\begin{equation}\label{eq:objrec}
obj =
\left[\begin{array}{rcl}
\text{seg} &=& \left[\begin{array}{rcl}
\text{cx} &=& 138\\
\text{w} &=& 276\\
\text{cy} &=& 654\\
\text{h} &=& 809
\end{array}\right]\\
\text{pfun} &=& \lambda v:Ind\ .\ \text{person}(v)\\
\end{array}\right] : Obj\end{equation}

\begin{equation}\label{eq:objdetector}
ObjDetector = ( Image \rightarrow [Obj] )
\end{equation}



\subsubsection{Individuation}

The perceptual object couples a property with a location, but it does not explicitly say anything about any individual object.
In \cite{lspc}, the step from the perceptual to the \textit{conceptual} domain is made by generating a record type that corresponds to a situation, namely the situation that a certain individual has a certain property and is at a certain location.
This situation record type is known as an \textit{individuated object}, and is a subtype of $IndObj$ (\autoref{eq:indobj}).
Here, $x$ is an individual and $loc$ is a location.
$cl$ specifies that $loc$ is the location of $x$, and the purpose of $cp$ is to declare a property of $x$.
$PTy$ is defined as a supertype of all ptypes (\autoref{eq:pty}).

\begin{equation}\label{eq:indobj}
IndObj = \left[\begin{array}{rcl}
\text{x} &:& Ind \\
\text{loc} &:& Segment \\
\text{cp} &:& PTy \\
\text{cl} &:& \text{location}(\text{x}, \text{loc}) \\
\end{array}\right]
\end{equation}

\begin{equation}\label{eq:pty}
PTy : Type
\end{equation}

A function for generating an $IndObj$ subtype from an $Obj$ record is known from \cite{lspc} as an \textit{individuation function}.
It is typed as $IndFun$ (\autoref{eq:indfun}).

\begin{equation}\label{eq:indfun}
IndFun = ( Obj \rightarrow RecType )
\end{equation}

The record type resulting from applying an $IndFun$ function will be a subtype of $IndObj$.
Furthermore, the $x$ and $loc$ fields will be specified using manifest fields.
The $x$ field is specified as a newly instantiated $Ind$ object, $a_n$ (where $n$ is a number such that the new instatiation is unique).
The $loc$ field is specified as the value of $seg$ in the $Obj$ record.

%For the $x$ field, we create a new individual object $a_{new} : Ind$.
%For the ptype fields $cp$ and $cl$, we also create new objects $e_{new} : r.\text{pfun}(\text{x})$ and $e_{new} : \text{location}(\text{x}, \text{loc})$.

The individuation function is defined, as explained above, in \autoref{eq:indfundef}, with an example application in \autoref{eq:indfunrec}.
The output record type describes a situation where an individual identified as $a_0$ is classified as a person and is occupying a $276 \times 809$-sized rectangle with its center at $(138, 654)$.

\begin{equation}\label{eq:indfundef}
f_{IndFun} = \lambda r : Obj\ . \left[\begin{array}{lcl}
    \text{x} = a_n &:& Ind \\
    \text{cp} &:& r.\text{pfun}(\text{x}) \\
    \text{cl} &:& \text{location}(\text{x}, \text{loc}) \\
    \text{loc} = r.\text{seg} &:& Segment\\
\end{array}\right]
\end{equation}

\begin{equation}\label{eq:indfunrec}
f_{IndFun}(
\left[\begin{array}{rcl}
\text{seg} &=& \left[\begin{array}{rcl}
\text{cx} &=& 138\\
\text{w} &=& 276\\
\text{cy} &=& 654\\
\text{h} &=& 809
\end{array}\right]\\
\text{pfun} &=& \lambda v:Ind\ .\ \text{person}(v)\\
\end{array}\right]
) =
\left[\begin{array}{lcl}
    \text{x} = a_0 &:& Ind \\
    \text{cp} &:& \text{person}(\text{x}) \\
    \text{cl} &:& \text{location}(\text{x}, \text{loc}) \\
    \text{loc} = \left[\begin{array}{rcl}
		\text{cx} &=& 138\\
		\text{w} &=& 276\\
		\text{cy} &=& 654\\
		\text{h} &=& 809
		\end{array}\right] &:& Segment\\
\end{array}\right]
\end{equation}



\subsubsection{Spatial relations}

Relations may hold between pairs of individuated objects.
How do we detect and model a certain relation between such a pair?

Since we are interested in the spatial relation between a \textit{reference object} and a \textit{located object}, we will be constructing tuple-like records of the type $LocTup$ defined in \autoref{eq:loctup}.
Records of this type contain instantiations (records) of two $IndObj$ record types.
In \autoref{eq:clf}, a classifier is modeled as a function from such a record to a new record type which should describe the relation.

\begin{equation}\label{eq:loctup}
LocTup = \left[\begin{array}{rcl}
    \text{lo} &:& IndObj \\
    \text{refo} &:& IndObj \\
    \end{array}\right]
\end{equation}

\begin{equation}\label{eq:clf}
RelClf = ( LocTup \rightarrow RecType )
\end{equation}

For instance, a classifier for ``left'' might look like in \autoref{eq:leftclfdef}, where $\kappa_{left}$ is a non-TTR, boolean function.
Of course, the requirement that the individual $r.\text{lo}.\text{x}$ is actually located at $r.\text{lo}.\text{loc}$ (and same for $r.\text{refo}$) is implicit from the typing as $IndObj$, where the field $\text{cl} : \text{location}(\text{x}, \text{loc})$ is necessarily present.

\begin{equation}\label{eq:leftclfdef}
\lambda r : LocTup \ .\ 
\begin{cases}
\left[\begin{array}{rcl}
    \text{cr} &:& \text{left}(r.\text{lo}.\text{x}, r.\text{refo}.\text{x}) \\
\end{array}\right],
& \text{if } \kappa_{left}(r.\text{lo}.\text{loc}, r.\text{refo}.\text{loc}) \\
[], & \text{otherwise}
\end{cases}
\end{equation}



\subsubsection{Combining beliefs}

The hitherto generated types are considered our beliefs.
As described in \autoref{ssec:languagevqa}, we can answer to a polar question if we \textit{combine} the beliefs to a scene type and check whether it is a subtype of the question type, $S \sqsubseteq Q$.
How is this combining carried out?
A direct application of the \textit{merge} operation is not suitable for this, as we have labels reocurring in multiple record types.
Instead, all record types are relabeled with new, unique labels, before being merged.

\label{def:cfmerge}
If $T_1$ and $T_2$ are record types, then the \textbf{conflict-free merge} $T_1 \underset{u}{\wedge} T_2$ is a merge of the record types relabeled such that they do not share any labels.

If the belief types are $T_1, T_2, ..., T_n$, they are combined to $T_1 \underset{u}{\wedge} T_2 \underset{u}{\wedge} ... \underset{u}{\wedge} T_n$.



\subsubsection{Agent}
\label{sec:agent}

We are now connecting the perceptual-conceptual pieces described above, by building an agent.
It receives information on classified and located objects of an image, and apprehends their basic status and spatial relations.
It also receives the result of parsing a natural-language utterance.
The information is in \gls{ttr} form, which finally allows the agent to connect the two modes.
This provides a means to answer to natural-language questions about the image.

\begin{equation}\label{eq:agent}
Agent = \left[\begin{array}{rcl}
    \text{objdetector} &:& ObjDetector \\
    \text{indfun} &:& IndFun \\
    \text{relclfs} &:& [RelClf] \\
    \text{state} &:& AgentState \\
    \end{array}\right]
\end{equation}

\begin{equation}\label{eq:state}
AgentState = \left[\begin{array}{rcl}
    \text{img} &:& Image \\
    \text{perc} &:& [Obj] \\
    \text{bel} &:& [RecType] \\
    \text{utt} &:& RecType \\
    \end{array}\right]
\end{equation}

The fields `objdetector', `indfun' and `relclfs' of $Agent$ are to be statically defined for a specific agent.
While running, the agent will modify the $AgentState$ record in `state'.
For an agent $ag : Agent$, the perception and question-answering procedure is carried out as follows.

\paragraph{Visual perception}

\begin{enumerate}
\item Visual input in the form of an image is received and assigned to $ag.\text{state}.\text{img}$.
\item $ag.\text{objdetector}$ is invoked on $ag.\text{state.img}$ and creates a collection of records that are assigned to $ag.\text{state}.\text{perc}$.
\item $ag.\text{indfun}$ is, in turn, invoked on each record in $ag.\text{state.perc}$ and resulting record types are added to $ag.\text{state.bel}$.
\item Now, each function in $ag.\text{relclfs}$ are applied:
	\begin{enumerate}
	\item The fields of the domain record type of the function is considered its arguments.
	\item Each combination of $ag.\text{state.bel}$ record types that matches the argument types is considered for input.
	\item The input record types are combined to match the domain record type of the function, and the type is instantiated.
	\item The function is applied to the created record, and the resulting record type is added to $ag.\text{state.bel}$
	\end{enumerate}
	For example, the \textit{left} classifier in \autoref{eq:leftclfdef} is applied to each pair of $IndObj$ after combining them into a $LocTup$ and instantiating it.
    Note that the $IndObj$ have manifest fields which carry on to the $LocTup$ type, so it is more specific than just instantiating $LocTup$ itself.
\end{enumerate}



\paragraph{Language}

\begin{enumerate}
\item Any language input is parsed and the resulting record type assigned to $ag.\text{state.utt}$.
\item The record types in $ag.\text{state.bel}$ are combined. If the resulting record type is a relabel-subtype of $ag.\text{state.utt}$, the answer YES is emitted; otherwise NO.
\end{enumerate}



An example state of an agent $ag$ is shown in \autoref{eq:ag}.

\begin{landscape}
\begin{equation}\label{eq:ag}
\renewcommand{\arraystretch}{1.2}
ag = \left[\begin{array}{rcl}
    \text{objdetector} &=& \mathtt{yolo\_detector} \\
    \text{indfun} &=& \mathtt{indfun} \\
    \text{relclfs} &=& [Clf_{left}, Clf_{right}, Clf_{above}, Clf_{below}] \\
    \text{state} &=& \left[\begin{array}{rcl}
		\text{img} &=& \mathtt{dogride.jpg} \\
		\text{perc} &=& [
			\left[\begin{array}{rcl}
				\text{seg} &=& \left[\begin{array}{rcl}
					\text{w} &=& 197\\
					\text{cx} &=& 452\\
					\text{h} &=& 351\\
					\text{cy} &=& 261
					\end{array}\right]\\
				\text{pfun} &=& \lambda a:Ind\ .\ \text{person}(a)
				\end{array}\right],
			\left[\begin{array}{rcl}
				\text{seg} &=& \left[\begin{array}{rcl}
					\text{w} &=& 422\\
					\text{cx} &=& 435\\
					\text{h} &=& 242\\
					\text{cy} &=& 355
					\end{array}\right]\\
				\text{pfun} &=& \lambda a:Ind\ .\ \text{bicycle}(a)
				\end{array}\right],
			...
			] \\
		\text{bel} &=& \begin{array}{l} [
			\left[\begin{array}{rcl}
				\text{x} = a_0 &:& Ind\\
				\text{cp} &:& \text{person}(x)\\
				\text{cl} &:& \text{location}(x, loc)\\
				\text{loc} = \left[\begin{array}{rcl}
					\text{w} &=& 197\\
					\text{cx} &=& 452\\
					\text{h} &=& 351\\
					\text{cy} &=& 261
					\end{array}\right]
					&:& Segment \\
				\end{array}\right],
			{}{} \left[\begin{array}{rcl}
				\text{cr} &:& \text{above}(a_{0}, a_{1})
				\end{array}\right],
			... ]
			\end{array} \\
		\text{utt} &=& \left[\begin{array}{rcl}
			\text{x} &:& Ind\\
			\text{y} &:& Ind\\
			\text{c}_\text{0} &:& \text{dog}(x)\\
			\text{c}_\text{1} &:& \text{bicycle}(y)\\
			\text{c}_\text{2} &:& \text{left}(x, y)\\
			\end{array}\right] \\
		\end{array}\right] \\
    \end{array}\right]
\end{equation}
\end{landscape}



\subsection{Python implementation}
\label{ssec:python}

This section presents significant parts of the Python implementation of the model described above.
The full code, including visualization and more comments, is published as a Jupyter Notebook at \url{https://github.com/arildm/imagettr}.



\subsubsection{PyTTR definitions}

\begin{lstlisting}[label={lst:pyttrbasic}, caption=TTR type definitions]
Ind = BType('Ind')

Int = BType('Int')
Int.learn_witness_condition(lambda x: isinstance(x, int))

Image = BType('Image')
Image.learn_witness_condition(lambda x: isinstance(x, PIL.Image.Image))

Segment = RecType({'cx': Int, 'cy': Int, 'w': Int, 'h': Int})
Ppty = FunType(Ind, Ty)
Obj = RecType({'seg': Segment, 'pfun': Ppty})
Objs = ListType(Obj)
ObjDetector = FunType(Image, Objs)
ObjDetector.witness_cache.append(yolo_detector)

PTy = Type('PTy')
PTy.learn_witness_condition(lambda p: isinstance(p, HypObj) \
    and forsome(p.types, lambda t: isinstance(t, PType)))

IndObj = RecType({
    'x' : Ind,
    'loc' : Segment,
    'cp' : PTy,
    'cl' : create_fun('location', 'ab').app('x').app('loc'),
})
IndFun = FunType(Obj, RecTy)

LocTup = RecType({'lo': IndObj, 'refo': IndObj})
ClfRes = RecType({'cr': PTy})
RelClf = FunType(LocTup, ClfRes)
\end{lstlisting}



\subsubsection{Outside PyTTR}

\paragraph{Individuation function}

The PyTTR implementation of \gls{ttr} functions does not support usage of the argument within the function body.
The individuation function was therefore implemented in Python.
To keep the connection to \gls{ttr} tight, the argument and the result are checked against their \gls{ttr} types.

\begin{lstlisting}[label={lst:indfun},caption={Individuation function}]
def indfun(r):
    if not Obj.query(r):
        raise ValueError()
    cp = r.pfun.app('x')
    cl = create_fun('location', 'ab').app('x').app('loc')
    indobj = RecType({
        'x': SingletonType(Ind, Ind.create()),
        'cp': SingletonType(cp, cp.create()),
        'loc': SingletonType(Segment, r.seg),
        'cl': SingletonType(cl, cl.create()),
    })
    if not unsingleton(indobj).subtype_of(IndObj):
        raise ValueError()
    return indobj
IndFun.witness_cache.append(indfun)
\end{lstlisting}

\paragraph{Spatial relation classification}

In \autoref{lst:relclf}, each pair of $IndObj$ types is tested for each spatial relation classifier.
A classifier is a tuple of a predicate identifier (e.g. {\tt left}) and a function from two $Segment$s to a boolean value.
The return values of {\tt get\_relclfs} are functions of the same kind as the example in \autoref{eq:leftclfdef}.

\begin{lstlisting}[label=lst:relclf, caption=Spatial relation classifiers]
def get_relclfs():
    for pred, f in location_relation_classifiers.items():
        def relclf(r):
            if f(r.lo.loc, r.refo.loc):
                c = create_fun(pred, 'ab').app(r.lo.x).app(r.refo.x)
                return RecType({'cr': SingletonType(c, c.create())})
            return RecType()
        RelClf.witness_cache.append(relclf)
        yield relclf

def find_all_rels(indobjs):
    """Find all relations between IndObj records."""
    for relclf in get_relclfs():
        for loT, refoT in product(indobjs, indobjs):
            loctup = Rec({'lo': loT.create(), 'refo': refoT.create()})
            yield relclf(loctup)
\end{lstlisting}

\paragraph{YOLO}

In \autoref{lst:yolo}, YOLO object detection is invoked on an image, and the result is converted to PyTTR records.

\begin{lstlisting}[label=lst:yolo, caption=YOLO usage]
def yolo_detector(i):
    """Creates IndObj records for YOLO results."""
    for o in yolo(i):
        o = yolo_reformat(o)
        yield Rec({
            'seg': Rec(o['loc']),
            'pfun': create_fun(o['label'].replace(' ', '_')),
        })
\end{lstlisting}



\subsubsection{Extensions to PyTTR}

The combining of beliefs and the subtype relabeling require TTR operations that are not defined in PyTTR.

\paragraph{Combining beliefs}

The conflict-free merge operation defined in \autoref{def:cfmerge} is implemented in \autoref{lst:mergeunconflict}.
For example, if $T_1 = T_2 = [x:Ind]$, then $\mathtt{merge\_unconflict}(T_1, T_2)$ evaluates to $\left[\begin{array}{rcl} x_0&:&Ind \\ x_1&:&Ind \end{array}\right]$ (or a similar record type with different subscript indices).

\begin{lstlisting}[label={lst:mergeunconflict},caption={merge\_unconflict}]
def unique_labels(T):
    """Relabel a RecType so each field label is unique over all RecTypes."""
    for l, v in T.comps.__dict__.items():
        if '_' not in l:
            T.Relabel(l, gensym(l))
    return T

def merge_unconflict(T1, T2):
    """Merge two RecTypes after making sure they do not share any field labels."""
    T1c = unique_labels(copy_rectype(T1))
    T2c = unique_labels(copy_rectype(T2))
    return T1c.merge(T2c)
\end{lstlisting}

With dependent types, it is customary in \gls{ttr} literature to include the dependum as a field and use the field label in the dependent type.
In our implementation, spatial classifiers return record types where dependums are instead specified as individuals directly.
The function in \autoref{lst:useindfieldlabels} helps when those record types are combined with others.

\begin{lstlisting}[label={lst:useindfieldlabels},caption={use\_ind\_field\_labels}]
def use_ind_field_labels(T):
    """c:foo(a) becomes c:foo(x) if x=a:Ind is present."""
    T = copy_rectype(T)
    for l, v in T.comps.__dict__.items():
        if isinstance(v, SingletonType) and v.comps.base_type == Ind:
            a = v.comps.obj
            T.Relabel(a, l)
            # Undo the relabeling of the Ind field itself.
            T.comps.__dict__[l] = SingletonType(Ind, a)
    return T
\end{lstlisting}

\autoref{lst:combine} defines the function for combining record types in the fashion required: conflict-free merging and subsequent dependum re-referencing.

\begin{lstlisting}[label={lst:combine},caption={combine}]
def combine_beliefs(bel):
    """Combine a list of belief record types into one."""
    return unsingleton(use_ind_field_labels(reduce(merge_unconflict, bel, RecType())))
\end{lstlisting}

\paragraph{Subtype-relabeling}

The condition described in \autoref{ssec:languagevqa} necessitated the ability to find a relabeling $\eta$ that would fulfill a subtype relation $S \sqsubseteq Q_\eta$.
A simple approach to finding such a relabeling is to list every possible combination and one-by-one perform relabeling and check subtypeness.
However, that is computationally very expensive, and not very interesting even if speed is not a priority.

Another quicker approach is to not perform the relabeling in all steps.
Subtypeness can instead be checked field-wise:
For every field $\langle\ell_Q, T_Q\rangle$ in $Q$, if there is a field $\langle\ell_S, T_S\rangle$ in $S$ such that $T_S \sqsubseteq T_Q$, then let $\eta(\ell_Q) = \ell_S$.
If $\eta$ covers all fields in $Q$, then it follows that $S \sqsubseteq Q_\eta$.

However, we need to mind the types that are dependent on other fields.
For example, $\text{dog}(\text{x}) \cancel{\sqsubseteq} \text{dog}(\text{y})$ even if both $\text{x}:Ind$ and $\text{y}:Ind$ are fields in the respective record types.
To remedy this, the simple approach mentioned above is carried out as a first step, but for basic-type fields only.
Then, for every basic-field relabeling, the second approach is carried out.
In the example case, some of the basic-type relabelings will then have relabeled $\text{y}$ to $\text{x}$ so that the field-wise check becomes $\text{dog}(\text{x}) \sqsubseteq \text{dog}(\text{x})$.

\begin{lstlisting}[label=lst:subtyperlb, caption=Subtype-relabeling.]
from itertools import permutations, combinations

def find_subtype_relabeling(T, U):
    '''Could record type T be a sub type of record type U if relabeling in T is allowed?'''
    # Find possible relabelings for basic-type fields
    basic_label_permutations = set(ps[:len(basic_fields(U))] for ps in permutations(basic_fields(T)))
    
    for tks in basic_label_permutations:
        # Copy U and try a basic-fields relabeling
        U2 = copy_rectype(U)
        rlb = dict(zip(basic_fields(U), tks))
        rectype_relabels(U2, rlb)
        
        # For each U field, find a T field that is a subtype
        match = dict()
        for uk in nonbasic_fields(U2):
            for tk in nonbasic_fields(T):
                if T.comps.__dict__[tk].subtype_of(U2.comps.__dict__[uk]):
                    match[uk] = tk
                    break
            if uk not in match:
                break

        # Successful if all non-basic fields match.
        if len(match) == len(nonbasic_fields(U2)):
            return dict(**rlb, **match)
    return None
\end{lstlisting}



\subsubsection{Language parsing}

Parsing to PyTTR cannot be done directly.
The output of NLTK feature grammars is either strings or \gls{fol} expressions.
For the need of variable substitution, we choose the latter.
The resulting \gls{fol} conjunction expression is then translated to PyTTR ptypes, and $Ind$ fields are created from the arguments of the predicates.

\begin{lstlisting}[label=lst:grammar, caption=Basic parsing of natural language into PyTTR object]
import nltk

grammar = nltk.grammar.FeatureGrammar.fromstring(r'''
%start S
S[SEM=<?s(x) & ?vp(x, y)>] -> NP[SEM=?s] VP[SEM=?vp]
S[SEM=?q] -> QS[SEM=?q]
QS[SEM=<?s(x) & ?vp(x, y)>] -> 'is' 'there' NP[SEM=?s] PP[SEM=?vp]
NP[SEM=<?det(?n)>] -> Det[SEM=?det] N[SEM=?n]
Det[SEM=<\P a.P(a)>] -> 'a' | 'an'
N[SEM=<dog>] -> 'dog'
N[SEM=<car>] -> 'car'
N[SEM=<person>] -> 'person'
N[SEM=<bicycle>] -> 'bicycle'
N[SEM=<backpack>] -> 'backpack'
VP[SEM=?pp] -> 'is' PP[SEM=?pp]
PP[SEM=<\a b.(?prep(a, b) & ?o(b))>] -> Prep[SEM=?prep] NP[SEM=?o]
Prep[SEM=<left>] -> 'to' 'the' 'left' 'of'
Prep[SEM=<right>] -> 'to' 'the' 'right' 'of'
Prep[SEM=<above>] -> 'above'
Prep[SEM=<under>] -> 'under'
''')
parser = nltk.FeatureChartParser(grammar)

def fopc_to_pyttr(expr, T=RecType()):
    """Turns a FOPC object into a RecType."""
    from nltk.sem.logic import ApplicationExpression, AndExpression
    if isinstance(expr, ApplicationExpression):
        pred, args = expr.uncurry()
        T.addfield(gensym('c'), mkptype(str(pred), vars=[str(a) for a in args]))
        for x in args:
            if str(x) not in T.comps.__dict__:
                T.addfield(str(x), Ind)
    if isinstance(expr, AndExpression):
        fopc_to_pyttr(expr.first, T)
        fopc_to_pyttr(expr.second, T)
    return T

def eng_to_pyttr(text):
    trees = parser.parse(text.lower().strip('.?!').split())
    sem = nltk.sem.root_semrep(list(trees)[0])
    T = fopc_to_pyttr(sem)
    return T
\end{lstlisting}



\subsubsection{Agent}
\label{sec:implagent}

% @TODO Typing of Python functions yolo_detector and indfun: now manipulating witness_cache but then LambdaFun?

The agent is a record of the type $Agent$.
Manipulation of the record is performed by Python functions \texttt{agent\_see} and \texttt{agent\_hear}.
They correspond to the algorithms for visual perception and language, described in \autoref{sec:agent}



\subsection{Evaluation}

The evaluation results are presented in \autoref{tab:eval}.
Where the answer is incorrect, this is explained by different reasons.
In 1.2, the car is classified as \textit{truck} and our model does not have any inference system for determining that if something is a truck then it is also a car.
In 2.1 and 4.1, some of the objects are not successfully detected by the object detection system.
In 3.1, the simplistic account of spatial relations conflicts with that of our intuition.
Sure enough, there is at least one snowboard whose center coordinates is higher on the $y$ axis than that of at least one person.

\begin{table}
\begin{tabular}{cl}
  
	\includegraphics[width=0.3\textwidth]{vqa1.jpg} &
	\begin{tabular}{llll}
		1.1 & Is there an aeroplane? & Yes & Correct \\
		1.2 & Is there a person to the right of a car? & No & Incorrect
		\end{tabular} \\
		
	\includegraphics[width=0.3\textwidth]{vqa2.jpg} &
	\begin{tabular}{llll}
		2.1 & Is there a tent? & No & Incorrect \\
		2.2 & Is there a kite above a person? & Yes & Correct
		\end{tabular} \\
		
	\includegraphics[width=0.3\textwidth]{vqa3.jpg} &
	\begin{tabular}{llll}
		3.1 & Is there a snowboard above a person? & Yes & Incorrect \\
		3.2 & Is there a snowboard below a person? & Yes & Correct
		\end{tabular} \\
		
	\includegraphics[width=0.3\textwidth]{vqa4.jpg} &
	\begin{tabular}{llll}
		4.1 & Is there a giraffe below a tree? & No & Incorrect
		\end{tabular} \\
		
  	\end{tabular}
\caption{Evaluation results.}
\label{tab:eval}
\end{table}
