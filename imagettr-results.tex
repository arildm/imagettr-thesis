\section{Results}
\label{sec:results}

The results of this project consists primarily of a \gls{ttr} model, which connects language to visual perception in a basic \gls{vqa} setting and uses \gls{ttr} throughout (\autoref{sec:ttrmodel}).
There are also a few significant sub-problems, which are not entirely within the TTR model but tightly connected to it.
These have been solved as algorithms implemented in Python.
They are: efficiently combining multiple belief record types into one (\autoref{sec:combine}), basic translation from first-order logic to \gls{ttr} (\autoref{sec:parsing}) and finally a subtype relation insensitive to labels, $\subtrlb$ (\autoref{sec:subtyperelabeling}).



\subsection{\Acrshort{ttr} model}
\label{sec:ttrmodel}

The types in the \gls{ttr} model are largely based on \cite{lspc}, but the $Segment$ type is new, the individuation function is improved and the $RelClf$ mechanism is more concretely defined.
The $Agent$ type is also new.

Five basic types exist in the model.

\begin{description}
\item [$Ind$] A single individual object, such as the reader or the Eiffel Tower.
\item [$Int$] An integer, such as 415.
\item [$Image$] A 2-dimensional digital image. It serves as an identifier to a set of extracted information, and its file type and actual data is not important in this thesis.
\item [$String$] A piece of plain text of arbitrary length.
\item [$Nothing$] Has a single, empty value as its only witness.
\end{description}

A $Segment$ is a record type describing a rectangular bounding box within an (implicit) image (\autoref{eq:seg}).
Its fields contain the center coordinates of the box (`cx' and `cy') and the width (`w') and height (`h') of the box.
$Ppty$ is the type of functions that can be applied to an individual and return a type (\autoref{eq:ppty}).
In our account the resulting type will be restricted to a ptype that is dependent on the individual, thus describing a property of it.

\begin{equation}\label{eq:seg}
Segment = \left[\begin{array}{rcl}
\text{cx} &:& Int\\
\text{cy} &:& Int\\
\text{w} &:& Int\\
\text{h} &:& Int
\end{array}\right]\end{equation}

\begin{equation}\label{eq:ppty}
Ppty = (Ind \rightarrow Type)\end{equation}

%[PTy?]



\subsubsection{Object detection}

A \textit{perceptual object} is a record of the record type $Obj$ (\autoref{eq:obj}).
It contains a bounding box (the `seg' field) and a property (`pfun').
An example record is given in \autoref{eq:objrec}.
%$Obj$ records are the result of performing \textit{object detection}.
%This fact is expressed in TTR as the function type $ObjDetector$ (\autoref{eq:objdetector}).
An object detector is a function from an image to a set of such perceptual objects, as captured by the $ObjDetector$ function type (\autoref{eq:objdetector}).

%[differences/similarites LSPC and others]

\begin{equation}\label{eq:obj}
Obj = \left[\begin{array}{rcl}
\text{seg} &:& Segment\\
\text{pfun} &:& Ppty \\
\end{array}\right]\end{equation}

\begin{equation}\label{eq:objrec}
obj =
\left[\begin{array}{rcl}
\text{seg} &=& \left[\begin{array}{rcl}
\text{cx} &=& 435\\
\text{w} &=& 422\\
\text{cy} &=& 355\\
\text{h} &=& 242
\end{array}\right]\\
\text{pfun} &=& \lambda v:Ind\ .\ \text{bicycle}(v)\\
\end{array}\right] : Obj\end{equation}

\begin{equation}\label{eq:objdetector}
ObjDetector = ( Image \rightarrow [Obj] )
\end{equation}



\subsubsection{Individuation}

The perceptual object couples a property with a location, but it does not explicitly say anything about any individual object.
In \cite{lspc}, the step from the perceptual to the \textit{conceptual} domain is made by generating a record type that corresponds to a situation, namely the situation that a certain individual has a certain property and is at a certain location.
This situation record type is known as an \textit{individuated object}, and is a subtype of $IndObj$ (\autoref{eq:indobj}).
Here, $x$ is an individual and $loc$ is a bounding box.
$cl$ specifies that $loc$ is the location of $x$, and the purpose of $cp$ is to declare a property of $x$.
$PTy$ is defined as a supertype of all ptypes (\autoref{eq:pty}).

[TODO What to do about PTy? Does it make sense? Skip it? Make use of it more?]

\begin{equation}\label{eq:indobj}
IndObj = \left[\begin{array}{rcl}
\text{x} &:& Ind \\
\text{loc} &:& Segment \\
\text{cp} &:& PTy \\
\text{cl} &:& \text{location}(\text{x}, \text{loc}) \\
\end{array}\right]
\end{equation}

\begin{equation}\label{eq:pty}
PTy : Type
\end{equation}

A function for generating an $IndObj$ subtype from an $Obj$ record is known from \cite{lspc} as an \textit{individuation function}.
It is typed as $IndFun$ (\autoref{eq:indfun}).

\begin{equation}\label{eq:indfun}
IndFun = ( Obj \rightarrow RecType )
\end{equation}

The individuation function is defined as $f_{IndFun}$ in \autoref{eq:indfundef}.
The record type resulting from applying $f_{IndFun}$ is a subtype of $IndObj$, where the `x' and `loc' fields are specified using manifest fields.
The `x' field is specified as a newly instantiated $Ind$ object, $a_n$ (where $n$ is a number such that the new instatiation is unique).
The `loc' field is specified as the value of `seg' in the $Obj$ record.

%For the $x$ field, we create a new individual object $a_{new} : Ind$.
%For the ptype fields $cp$ and $cl$, we also create new objects $e_{new} : r.\text{pfun}(\text{x})$ and $e_{new} : \text{location}(\text{x}, \text{loc})$.

An example application of $f_{IndFun}$ is shown in \autoref{eq:indfunrec}.
The output record type describes a situation where an individual identified as $a_0$ is classified as a bicycle and is occupying a $422 \times 242$-sized rectangle with its center at $(435, 355)$.

\begin{equation}\label{eq:indfundef}
f_{IndFun} = \lambda r : Obj\ . \left[\begin{array}{rcl}
    \text{x} = a_n &:& Ind \\
    \text{cp} &:& r.\text{pfun}(\text{x}) \\
    \text{cl} &:& \text{location}(\text{x}, \text{loc}) \\
    \text{loc} = r.\text{seg} &:& Segment\\
\end{array}\right]
\end{equation}

\begin{equation}\label{eq:indfunrec}
f_{IndFun}(
\left[\begin{array}{rcl}
\text{seg} &=& \left[\begin{array}{rcl}
\text{cx} &=& 435\\
\text{w} &=& 422\\
\text{cy} &=& 355\\
\text{h} &=& 242
\end{array}\right]\\
\text{pfun} &=& \lambda v:Ind\ .\ \text{bicycle}(v)\\
\end{array}\right]
) =
\left[\begin{array}{rcl}
    \text{x} = a_0 &:& Ind \\
    \text{cp} &:& \text{bicycle}(\text{x}) \\
    \text{cl} &:& \text{location}(\text{x}, \text{loc}) \\
    \text{loc} = \left[\begin{array}{rcl}
        \text{cx} &=& 435\\
        \text{w} &=& 422\\
        \text{cy} &=& 355\\
        \text{h} &=& 242
		\end{array}\right] &:& Segment\\
\end{array}\right]
\end{equation}



\subsubsection{Spatial relation classification}

Relations may hold between pairs of individuated objects.
How do we detect and model a certain relation between such a pair?

Since we are interested in the spatial relation between a \textit{reference object} and a \textit{located object}, we will be constructing tuple-like records of the type $LocTup$ defined in \autoref{eq:loctup}.
Records of this type contain instantiations (records) of two $IndObj$ record types.
In \autoref{eq:clf}, a classifier is modeled as a function from such a record to a new record type which should describe the relation.

\begin{equation}\label{eq:loctup}
LocTup = \left[\begin{array}{rcl}
    \text{lo} &:& IndObj \\
    \text{refo} &:& IndObj \\
    \end{array}\right]
\end{equation}

\begin{equation}\label{eq:clf}
RelClf = ( LocTup \rightarrow RecType )
\end{equation}

For instance, a classifier for ``left'' might look like in \autoref{eq:leftclfdef}, where $\kappa_{left}$ is a non-TTR, boolean function.
Of course, the requirement that the individual $r.\text{lo}.\text{x}$ is actually located at $r.\text{lo}.\text{loc}$ (and same for $r.\text{refo}$) is implicit from the typing as $IndObj$, where a field typed as $\text{location}(\text{x}, \text{loc})$ is necessarily present.

\begin{equation}\label{eq:leftclfdef}
\lambda r : LocTup \ .\ 
\begin{cases}
\left[\begin{array}{rcl}
    \text{x} &:& r.\text{lo}.\text{x} \\
    \text{y} &:& r.\text{refo}.\text{x} \\
    \text{cr} &:& \text{left}(\text{x}, \text{y}) \\
\end{array}\right],
& \text{if } \kappa_{left}(r.\text{lo}.\text{loc}, r.\text{refo}.\text{loc}) \\
[], & \text{otherwise}
\end{cases}
\end{equation}



%%%%%%%%
\begin{comment}
\subsubsection{Combining beliefs}

The hitherto generated types are considered our beliefs.
As described in \autoref{sec:languagevqa}, we can answer to a polar question if we \textit{combine} the beliefs to a scene type and check whether it is a subtype of the question type, $S \sqsubseteq Q$.
How is this combining carried out?
A direct application of the \textit{merge} operation is not suitable for this, as we have labels reocurring in multiple record types.
Instead, all record types are relabeled with new, unique labels, before being merged.

\label{def:cfmerge}
If $T_1$ and $T_2$ are record types, then the \textbf{conflict-free merge} $T_1 \underset{u}{\wedge} T_2$ is a merge of the record types relabeled such that they do not share any labels.

If the belief types are $T_1, T_2, ..., T_n$, they are combined to $T_1 \underset{u}{\wedge} T_2 \underset{u}{\wedge} ... \underset{u}{\wedge} T_n$.
\end{comment}
%%%%%%%%



\subsubsection{Beliefs}

The set of individuated objects, added to the set of relation classification results, forms a set of beliefs.
Each of these types is a situation held to be true, by virtue of resulting from perception mechanisms.
They can be \textit{combined} into one \textit{scene} record type which describes the full scene.
The method of such combination is not trivial, and is discussed in \autoref{sec:combine}.



\subsubsection{Language}
\label{sec:ttrlanguage}

%The connection between visual perception and language happens by means of using the same representation (TTR) for both modes.
%The representation of the former mode has been discussed above.
%Digitally encoded visual data is input to the model, which uses an external object detector to extract information which forms the base of further acts of perception.
%
%For the language side, this model does not concern itself with parsing.
%Instead, the parsing of natural language is expected to occur outside the model.
%The resulting TTR representation 

% How do we go from language to TTR?
In order to add the  connection to language, any natural-language utterance must be parsed into \gls{ttr}.
As discussed in \autoref{sec:languagevqa}, TTR-based natural-language parsing has not yet been implemented as a ready-to-use library.
Therefore, parsing must be done externally to the TTR model.
This is described in \autoref{sec:parsing}.
%Any utterance is input to the model only as a TTR record type.
% What will the parsing result look like in TTR?
Equation~\ref{eq:question} models the question ``Is there a lamp above a table?''.

\begin{equation}\label{eq:question}
\left[\begin{array}{rcl}
    \text{x} &:& Ind \\
    \text{y} &:& Ind \\
    \text{c}_\text{x} &:& \text{lamp}(\text{x}) \\
    \text{c}_\text{y} &:& \text{table}(\text{y}) \\
    \text{c}_\text{r} &:& \text{above}(\text{x}, \text{y}) \\
    \end{array}\right]
\end{equation}

% How do we use the question TTR type?
% TODO In terms of DIALOGUE ACTS?
As mentioned in \autoref{sec:languagevqa}, answering the question corresponds to checking whether $S \sqsubseteq Q$.
An important problem, however, stems from the fact that TTR record types are labeled.
In general, fields in the scene type and question type will not share labels in a way that enables simple subtype checking to be useful.
The remedy to this is an alternative subtype relation $\subtrlb$ which is insensitive to labels.
This new relation is discussed in \autoref{sec:subtyperelabeling}.



\subsubsection{Agent}
\label{sec:agent}

The perceptual-conceptual pieces described above are now connected in an \textit{agent} record type (\autoref{eq:agent} and \autoref{eq:state}) with associated manipulation algorithms.
Upon receiving an image, it will carry out object detection, individuation and spatial relation classification, in order to form its beliefs.
It may also receive a parsed natural-language utterance, which will then be validated against the beliefs.
%The information is in \gls{ttr} form, which finally allows the agent to connect the two modes.
A construction like this provides a means to answer to natural-language questions about the image.

\begin{equation}\label{eq:agent}
Agent = \left[\begin{array}{rcl}
    \text{objdetector} &:& ObjDetector \\
    \text{indfun} &:& IndFun \\
    \text{relclfs} &:& [RelClf] \\
    \text{state} &:& AgentState \\
    \end{array}\right]
\end{equation}

\begin{equation}\label{eq:state}
AgentState = \left[\begin{array}{rcl}
    \text{img} &:& Image \vee Nothing \\
    \text{perc} &:& [Obj] \\
    \text{bel} &:& [RecType] \\
    \text{utt} &:& String \vee Nothing \\
    \text{que} &:& RecType \\
    \end{array}\right]
\end{equation}

The fields `objdetector', `indfun' and `relclfs' of $Agent$ are to be statically defined for a specific agent.
While running, the agent will modify the $AgentState$ record in `state'.
For an agent $ag : Agent$, the perception and question-answering procedure is carried out as follows.

\paragraph{Visual perception}

\begin{enumerate}
\item Visual input in the form of an image is received and assigned to $ag.\text{state}.\text{img}$.
\item $ag.\text{objdetector}$ is invoked on $ag.\text{state.img}$ and creates a collection of perceptual object records that are assigned to $ag.\text{state}.\text{perc}$.
\item $ag.\text{indfun}$ is, in turn, invoked on each record in $ag.\text{state.perc}$ and resulting individuated object record types are added to $ag.\text{state.bel}$.
\item Now, each function in $ag.\text{relclfs}$ is applied to each pair of record types in $ag.\text{state.bel}$:
	\begin{enumerate}
	%\item The fields of the domain record type of the function is considered its arguments.
	%\item Each combination of $ag.\text{state.bel}$ record types that matches the argument types is considered for input.
	%\item The input record types are combined to match the domain record type of the function, and the type is instantiated.
    \item For each pair $T_1$ and $T_2$ in $ag.\text{state.bel}$, a $LocTup$ record type is constructed as $[\text{lo}: T_1, \text{refo}: T_2]$. Note that this will be specified to certain individuals and segments, and is thus more informative than the plain $LocTup$ type.
    \item The specified $LocTup$ type is instantiated to a record.
	\item Each function in $ag.\text{relclfs}$ is applied to the created record, and the record type resulting from each application is added to $ag.\text{state.bel}$ unless it is empty ($[]$).
	\end{enumerate}
	For example, the \textit{left} classifier in \autoref{eq:leftclfdef} is applied to each pair of $IndObj$ after combining them into a $LocTup$ and instantiating it.
    Note that the $IndObj$ have manifest fields which carry on to the $LocTup$ type, so it is more specific than just instantiating $LocTup$ itself.
\end{enumerate}



\paragraph{Language}

\begin{enumerate}
\item Any language input utterance is assigned to $ag.\text{state.utt}$.
\item The utterance is parsed and the resulting record type ($Q$) assigned to $ag.\text{state.que}$.
\item The record types in $ag.\text{state.bel}$ are combined ($S$). If the resulting record type is a relabel-subtype of $ag.\text{state.que}$, $S \subtrlb Q$ the answer ``Yes'' is emitted; otherwise ``No''.
\end{enumerate}



An example state of an agent $ag$ is shown in \autoref{eq:ag}.

\begin{landscape}
\begin{equation}\label{eq:ag}
%\arraycolsep=1pt
\def\arraystretch{1.2}
ag =
\left[\begin{array}{rcl}
    \text{objdetector} &=& \mathtt{yolo\_detector} \\
    \text{indfun} &=& \mathtt{indfun} \\
    \text{relclfs} &=& [Clf_{left}, Clf_{right}, Clf_{above}, Clf_{below}] \\
    \text{state} &=& \left[\begin{array}{rcl}
		\text{img} &=& \text{\tt <Image "dogride.jpg">} \\
		\text{perc} &=& [
			\left[\begin{array}{rcl}
				\text{seg} &=& \left[\begin{array}{rcl}
					\text{cx} &=& 452\\
					\text{w} &=& 197\\
					\text{cy} &=& 261 \\
					\text{h} &=& 351\\
					\end{array}\right]\\
				\text{pfun} &=& \lambda a:Ind\ .\ \text{person}(a)
				\end{array}\right],
			\left[\begin{array}{rcl}
				\text{seg} &=& \left[\begin{array}{rcl}
					\text{cx} &=& 435\\
					\text{w} &=& 422\\
					\text{cy} &=& 355 \\
					\text{h} &=& 242\\
					\end{array}\right]\\
				\text{pfun} &=& \lambda a:Ind\ .\ \text{bicycle}(a)
				\end{array}\right],
			... ] \\
		\text{bel} &=& [
			\left[\begin{array}{rcl}
				\text{x} = a_0 &:& Ind\\
				\text{cp} &:& \text{person}(x)\\
				\text{cl} &:& \text{location}(x, loc)\\
				\text{loc} = \left[\begin{array}{rcl}
					\text{cx} &=& 452\\
					\text{w} &=& 197\\
					\text{cy} &=& 261 \\
					\text{h} &=& 351\\
					\end{array}\right]
					&:& Segment \\
				\end{array}\right],
			{}{} \left[\begin{array}{rcl}
				\text{x} &:& Ind_{a_{0}} \\
				\text{y} &:& Ind_{a_{1}} \\
				\text{cr} &:& \text{above}(\text{x}, \text{y})
				\end{array}\right],
			... ] \\
        \text{utt} &=& \text{``Is there a dog to the left of a bicycle?''} \\
		\text{que} &=& \left[\begin{array}{rcl}
			\text{x} &:& Ind\\
			\text{y} &:& Ind\\
			\text{c}_\text{0} &:& \text{dog}(x)\\
			\text{c}_\text{1} &:& \text{bicycle}(y)\\
			\text{c}_\text{2} &:& \text{left}(x, y)\\
			\end{array}\right] \\
		\end{array}\right] \\
    \end{array}\right]
\end{equation}
\end{landscape}



\subsection{Combining situation types}
\label{sec:combine}

The beliefs of the agent are formed by a collection of record types.
These are \textit{combined} into one, in order to build the scene type $S$.

Consider the spatial relation classifiers, which create record types with the fields `x', `y', and `cr'.
One of these record types may be specified so that it declares that an individual $a_1$ is above another individual $a_2$ (\autoref{eq:combineterm1}).
Another record type may declare that $a_2$ is to the right of $a_1$ (\autoref{eq:combineterm2}).
The \textit{combination} of these beliefs, which declares both these relationships, is described by \autoref{eq:combination}.
To avoid conflict, some fields have been relabeled, prompting the expectation that combination results have no informative or predictable labels.

\begin{equation} \label{eq:combineterm1}
T_1 = \left[\begin{array}{rcl}
    \text{x} &:& Ind_{a_1} \\
    \text{y} &:& Ind_{a_2} \\
    \text{cr} &:& \text{above}(\text{x}, \text{y})
    \end{array}\right]
\end{equation}

\begin{equation} \label{eq:combineterm2}
T_2 = \left[\begin{array}{rcl}
    \text{x} &:& Ind_{a_2} \\
    \text{y} &:& Ind_{a_1} \\
    \text{cr} &:& \text{right}(\text{x}, \text{y})
    \end{array}\right]
\end{equation}

\begin{equation} \label{eq:combination}
\left[\begin{array}{rcl}
    \text{x} &:& Ind_{a_1} \\
    \text{y} &:& Ind_{a_2} \\
    \text{cr}_1 &:& \text{above}(\text{x}, \text{y}) \\
    \text{cr}_2 &:& \text{right}(\text{y}, \text{x})
    \end{array}\right]
\end{equation}

TTR features a \textit{merge} operation ($\ttrmerge$), but a merge will not have the result desired here.
Since the same labels occur in both belief types, a merge would result in \textit{meet types}, as seen in \autoref{eq:merge}, in a way which is not useful for this purpose.
The meet type of two different singleton types, $Ind_{a_1} \wedge Ind_{a_2}$, can only be true if the two individuals are the same, $a_1 = a_2$.
The constraint in the `cr' field then says that some individual is above and to the right of itself, which is meaningless and certainly not what we are trying to obtain.

\begin{equation} \label{eq:merge}
T_1  \ttrmerge T_2 =
\left[\begin{array}{rcl}
    \text{x} &:& Ind_{a_1} \wedge Ind_{a_2} \\
    \text{y} &:& Ind_{a_2} \wedge Ind_{a_1} \\
    \text{cr} &:& \text{above}(\text{x}, \text{y}) \wedge \text{right}(\text{x}, \text{y})
    \end{array}\right]
\end{equation}

\cite{CooperTypetheorylanguage2016} solves this by a method of nesting and flattening.
Each belief is added as the type of a new field `prev' in the next belief: $[\text{prev} : T_1] \ttrmerge T_2$.
The result is then flattened to avoid the nesting (\autoref{eq:combineprev}).
The field labeled `x' in $T_1$ is now labeled `prev.x' and does not conflict with the field labeled `x' from $T_2$.
% Duplicates?

\begin{equation} \label{eq:combineprev}
\left[\begin{array}{rcl}
    \text{prev.x} &:& Ind_{a_1} \\
    \text{prev.y} &:& Ind_{a_2} \\
    \text{prev.cr} &:& \text{above}(\text{prev.x}, \text{prev.y}) \\
    \text{x} &:& Ind_{a_2} \\
    \text{y} &:& Ind_{a_1} \\
    \text{cr} &:& \text{right}(\text{x}, \text{y})
    \end{array}\right]
\end{equation}

Another method is used in this project for the purpose of computational speed.
In this method, each belief record type is relabeled to only have unique labels, and then merged.
An example result is shown in \autoref{eq:combineunconflict}.
Generating unique labels is an operation outside TTR, making this method less purely TTR-powered.

\begin{equation} \label{eq:combineunconflict}
\left[\begin{array}{rcl}
    \text{x}_1 &:& Ind_{a_1} \\
    \text{y}_1 &:& Ind_{a_2} \\
    \text{cr}_1 &:& \text{above}(\text{x}_1, \text{y}_1) \\
    \text{x}_2 &:& Ind_{a_2} \\
    \text{y}_2 &:& Ind_{a_1} \\
    \text{cr}_2 &:& \text{right}(\text{x}_2, \text{y}_2)
    \end{array}\right]
\end{equation}

Both methods result in duplicate fields: there is no meaningful difference between the fields labeled `$\text{x}_1$' and `$\text{y}_2$' above, as both have the same type.
Removing duplicates does not only involve finding which fields have the same type as another field, but also relabeling them so that all dependent fields refer to the same basic field as appropriate.
%I.e. if `x_2' is relabeled to `y_1' and `y_2' to `x_1', then `c_2' must

[TODO why deduplication? Because relabel-subtype doesn't seem to work otherwise.]
[necessary to describe deduplication in detail?]

The \textit{combine} and \textit{dedupe} functions are defined in \autoref{lst:combine}.

In \texttt{combine}, a list of record types are reduced to one type by unique relabeling and merging.
The \texttt{unique\_labels} function makes use of \texttt{gensym} in the PyTTR library, which generates new, consecutively numbered labels such as \texttt{loc\_4} (typeset here as $\text{loc}_4$).
A label containing an underscore (`\_') is assumed to already be uniquely numbered.
Thus, labels without undescores are relabeled to new, numbered labels.

Finally, the \texttt{dedupe} function removes any duplicated field types by relabeling all occurrences of a field type with one of their labels. For example, in $[x:Ind_{a_1}, y:Ind_{a_1}]$, `y' is relabeled to `x'.
(Or possibly vice versa; the order of record type fields is unspecified.)
When all duplicates of some field type have been removed, recursion is used to avoid usage of old labels in the outer for-loop.

\begin{lstlisting}[label={lst:combine}, caption=The \texttt{combine} and \texttt{dedupe} functions.]
from functools import reduce

def unique_labels(T):
    """Relabel a RecType so each field label is unique over all RecTypes."""
    rlb = ((l, gensym(l)) for l in T.labels() if '_' not in l)
    return rectype_relabels(T, dict(rlb))

def dedupe(T):
    """Make a copy of a record type without duplicated field values."""
    for l,v in T.fields():
        # Are there more fields with the same value?
        l2s = [l2 for l2,v2 in T.fields() if l2 != l and show(v) == show(v2)]
        if len(l2s):
            # Relabel all these fields to the same label,
			# overwriting until one remains.
            for l2 in l2s:
                T.Relabel(l2, l)
            # Dependent fields have changed, so start over.
            return dedupe(T)
    # No more duplicates.
    return T

def combine(Ts):
    """Combine a list of belief record types into one."""
    f = lambda a, b: a.merge(unique_labels(b))
    return dedupe(reduce(f, Ts, RecType()))
\end{lstlisting}



\subsection{Parsing language to TTR}
\label{sec:parsing}
\glsreset{fol}

As mentioned in \autoref{sec:ttnlp}, pure TTR solutions to natural language parsing have been developed but not implemented.
Such an implementation is sufficiently complex and outside the scope of this thesis.
Furthermore, the language domain is limited for the purpose of this thesis, and a wide-coverage parsing solution is more than what is necessary.
Therefore, instead of implementing natural language parsing in \gls{ttr}, this project uses
another standard method to parse natural language to \gls{fol}.
The \gls{fol} expression is subsequently \textit{translated} to \gls{ttr} in a new algorithm.

\subsubsection{Parsing to \acrlong{fol}}

Parsing is done using a semantically augmented \gls{cfg}.
The rules in the grammar determine how an utterance is parsed into a syntax tree.
A determiner followed by a common noun form a noun phrase (NP $\rightarrow$ Det N), a sentence consists of a noun phrase and a verb phrase (S $\rightarrow$ NP VP), and so on.
A feature-based grammar extends the \gls{cfg} framework so that each constituent is associated with a feature structure.
This allows constituents to carry additional information which can be combined as defined in the grammar rules.

The semantic augmentation uses feature structures to associate each constituent with a \gls{fol} term possibly using lambda calculus.
For a simple example, a noun phrase may carry the term $t_{\text{NP}} = \lambda P \exists x P(x)$, and a verb phrase may carry $t_\text{VP} = \lambda z \ \text{sleep}(z)$.
A sentence rule may combine them as $t_\text{S} \rightarrow t_\text{VP}(t_\text{NP})$.
The result is $t_\text{S} = (\lambda P \exists x P(x)) (\lambda z \ \text{sleep}(z))$ which, after $\beta$-reduction, is equal to $t_\text{S} = \exists x \ \text{sleep}(x)$.
(Note that the actual rules for noun and verb phrases are slightly more complex.)

This project uses the semantically augmented \gls{cfg} framework available in NLTK \citep{nltk}.
A snippet of the grammar is given in \autoref{lst:grammar}.
The grammar can be used to generate the sample parse tree in \autoref{fig:tree}.
Above the word-tokenized sentence, every node in the tree represents a constituent.
Underneath the abbreviation, each constituent features first the expression given in the grammar specification (with some typographical modification), and second, the \gls{fol} term resulting from substitution and $\beta$-reduction.

\begin{lstlisting}[label={lst:grammar}, caption=A snippet of the FCFG grammar]
QS[SEM=<?np(?pp)>] -> 'is' 'there' NP[SEM=?np] PP[SEM=?pp]
QS[SEM=<?np(\P.true)>] -> 'is' 'there' NP[SEM=?np]

NP[SEM=<?det(?n)>] -> Det[SEM=?det] N[SEM=?n]
Det[SEM=<\P Q.exists x.(P(x) & Q(x))>] -> 'a' | 'an'

VP[SEM=?pp] -> 'is' PP[SEM=?pp]
PP[SEM=<\x.(?np(\y.?prep(x, y)))>] -> Prep[SEM=?prep] NP[SEM=?np]

Prep[SEM=<left>] -> 'to' 'the' 'left' 'of'

N[SEM=<dog>] -> 'dog'
N[SEM=<person>] -> 'person'
\end{lstlisting}

\begin{figure}[h]
\includegraphics[width=\textwidth]{tree}
\centering
\caption{Example syntactic-semantic parsing of an utterance into first-order logic.}
\label{fig:tree}
\end{figure}



\subsubsection{Translating \acrlong{fol} to \gls{ttr}}

The result of the \gls{cfg} parsing is a Python object that encodes the \gls{fol} expression.
A custom Python function \texttt{fol\_to\_pyttr}, given in \autoref{lst:foltopyttr}, traverses this object recursively and builds a PyTTR type.
For an ``Exists'' expression, an $Ind$ field is added to the type.
For an ``Application'' expression, a ptype field is added, copying the predicate and variable names.
An ``And'' expression simply triggers recursion into each of the two terms.
The constant `true' is added to allow simple existential questions like ``Is there an aeroplane?''
A wrapper function \texttt{eng\_to\_pyttr} combines simple word tokenization, \gls{cfg} parsing and \gls{fol}-to-\gls{ttr} translation.

\begin{lstlisting}[label=lst:foltopyttr, caption=Translation from \gls{fol} to \gls{ttr}.]
import nltk
from nltk.sem.logic import ApplicationExpression, AndExpression, ExistsExpression, ConstantExpression

def fol_to_pyttr(expr, T=RecType()):
    """Turns a FOL object into a RecType."""
    # Existential quantifier -> Ind field.
    if isinstance(expr, ExistsExpression):
        T.addfield(str(expr.variable), Ind)
        return fol_to_pyttr(expr.term, T)
    
    # Application -> ptype, e.g. left(x, y)
    if isinstance(expr, ApplicationExpression):
        pred, args = expr.uncurry()
        # Create a PType function, e.g. lambda x:Ind . dog(x)
        fun = create_fun(str(pred), 'abcd'[:len(args)])
        T.addfield(gensym('c'), (fun, [str(a) for a in args]))
        return T
    
    # For and-expressions, interpret each term.
    if isinstance(expr, AndExpression):
        fol_to_pyttr(expr.first, T)
        fol_to_pyttr(expr.second, T)
        return T
    
    # A constant function in the "is there an X" rule trivially gives "true".
    if isinstance(expr, ConstantExpression) and str(expr.variable) == 'true':
        return T
    
    raise ValueError('Unknown expression: ' + str(type(expr)) + ' ' + str(expr))

def eng_to_pyttr(text):
    # Tokenize.
    sent = text.lower().strip('.?!').split()
    # NLTK-parse to syntax tree.
    trees = parser.parse(sent)
    # Extract semantic representation for the tree.
    sem = nltk.sem.root_semrep(list(trees)[0])
    # Interpret to TTR record type.
    T = fol_to_pyttr(sem, RecType())
    return T
\end{lstlisting}



\subsection{The relabel-subtype relation}
\label{sec:subtyperelabeling}

Perceptual mechanisms and the combination of belief types have produced a scene type $S$.
Separately, natural language parsing has provided a question type $Q$.
Now, in order to answer the question, we are interested in whether $S \sqsubseteq Q$.

However, the fact that \gls{ttr} record types are labeled prevents direct usage of the subtype relation.
Field labels in the scene type will generally not agree with those in the question type.
This prompts for a more advanced variant of subtype checking, allowing \textit{relabeling}.

[TODO Why relabel supertype Q and not subtype S?]

\begin{definition}[Relabel-subtype]
A record type $S$ is a \textbf{relabel-subtype} of the record type $Q$, $S \subtrlb Q$, if there is a relabeling $\eta$ of $Q$ such that $S \sqsubseteq Q_\eta$.

%Such a relabeling $\eta$ is known as a \textbf{subtype relabeling} of $Q$.
% or rather supertype relabeling?
\end{definition}

The number of relabelings in one record type, to the labels of another, can be quite large:
If $S$ has 20 fields and $Q$ has five, then there are $\dfrac{20!}{(20-5)!} = 1\,860\,480$ relabelings of Q (the number of 5-permutations of 20).
It is practically impossible to perform all relabelings and check whether subtypeness holds.
An alternative algorithm is presented below for the purpose of this project, where fast computation is enabled by making a few assumptions about the input record types.



\begin{comment}
\paragraph{Subtype-relabeling}
Subtypeness can instead be checked field-wise:
For every field $\langle\ell_Q, T_Q\rangle$ in $Q$, if there is a field $\langle\ell_S, T_S\rangle$ in $S$ such that $T_S \sqsubseteq T_Q$, then let $\eta(\ell_Q) = \ell_S$.
If $\eta$ covers all fields in $Q$, then it follows that $S \sqsubseteq Q_\eta$.

However, we need to mind the types that are dependent on other fields.
For example, $\text{dog}(\text{x}) \cancel{\sqsubseteq} \text{dog}(\text{y})$ even if both $\text{x}:Ind$ and $\text{y}:Ind$ are fields in the respective record types.
To remedy this, the simple approach mentioned above is carried out as a first step, but for basic-type fields only.
Then, for every basic-field relabeling, the second approach is carried out.
In the example case, some of the basic-type relabelings will then have relabeled $\text{y}$ to $\text{x}$ so that the field-wise check becomes $\text{dog}(\text{x}) \sqsubseteq \text{dog}(\text{x})$.
\end{comment}


\subsubsection{Subtype relabeling algorithm}

This algorithm handles non-dependent (``basic'') and dependent fields separately.
When considering relabelings of $Q$, only the basic fields are included.
This drastically limits the number of relabelings to try:
If $S$ has eight basic fields and $Q$ has two, there are only $\dfrac{8!}{(8-2)!} = 56$ relabelings.
For each relabeling, the remaining (dependent) fields are subtype-checked individually.
This means checking
$\text{dog}(\text{x}) \sqsubseteq \text{dog}(\text{x})$ (true) instead of
$[\text{c}_1 : \text{dog}(\text{x})] \sqsubseteq [\text{c}_2 : \text{dog}(\text{x})]$ (false).
If there is some field in $Q_\eta$ that does not have a subtype field in $S$, then subtypeness cannot hold, and the rest of the complex fields are skipped in favor of trying the next basic-field relabeling.

% TODO what is this in terms of big-O?

%\paragraph{Prerequisites}
The algorithm imposes some prerequisites on the scene type $S$ and question type $Q$:

\begin{itemize}
\item Any dependent fields depend only on basic (non-dependent) fields.

For example, $\left[\begin{array}{rcl}
\text{x} &:& Ind \\
\text{c}_1 &:& \text{great}(\text{x}) \\
\text{c}_2 &:& \text{believe}(\text{x}, \text{c}_1)
\end{array}\right]$ is not allowed.

\item No nested record types.
(This restraint may be eliminated by using flattening, but it is not needed in this scope.)
\end{itemize}

%%%%%%%%
\begin{comment}
\paragraph{Algorithm}

\begin{enumerate}
\item For each basic-field relabeling of Q:
    \begin{enumerate}
    \item For each complex field in Q:
        \begin{enumerate}
        \item Find a subtype field in S and remember it
        \item If no subtype field was found, skip to next basic-field relabeling
        \end{enumerate}
    \item A subtype S field was found for all complex Q fields; return the relabeling
    \end{enumerate}
\item Return nothing
\end{enumerate}
\end{comment}
%%%%%%%%

A Python implementation is given in \autoref{lst:find_subtype_relabeling}.

\begin{lstlisting}[label={lst:find_subtype_relabeling}, caption=The \texttt{find\_subtype\_relabeling} function]
from itertools import permutations, combinations

def my_subtype_of(sub, sup):
    """Is T a subtype of U? Accept dependent rectype fields (= (fun, args) tuples) with simplistic equality test."""
    try:
        return sub.subtype_of(sup)
    except AttributeError:
        return isinstance(sub, tuple) and isinstance(sup, tuple) and show(sub) == show(sup)

def find_subtype_relabeling(S, Q):
    '''Could record type S be a sub type of record type Q if relabeling in Q is allowed?'''
    # For each relabeling of basic-type fields
    for sls in permutations(basic_fields(S), len(basic_fields(Q))):
        # Try the basic-fields relabeling of Q
        rlb_basic = dict(zip(basic_fields(Q), sls))
        Q2 = rectype_relabels(Q, rlb_basic)
        
        # For each Q field, find a S field that is a subtype
        rlb_dep = dict()
        for ql in nonbasic_fields(Q2):
            for sl in nonbasic_fields(S):
                # The new labels must be unique.
                if sl in rlb_dep.values(): continue
                if my_subtype_of(S.field(sl), Q2.field(ql)):
                    rlb_dep[ql] = sl
                    break
            if ql not in rlb_dep:
                break

        # Successful if all non-basic fields match.
        if len(rlb_dep) == len(nonbasic_fields(Q2)):
            return dict(**rlb_basic, **rlb_dep)
    return None
\end{lstlisting}



\subsection{Additions to PyTTR}

Some extensions to PyTTR were necessary for the implementation to be possible.
%In order to utilize PyTTR in the application, a few TTR operations had to be added.
%Additionally, a few functions which were TTR-related, but not obviously operations, were added.
Of these, some were added directly to the PyTTR library, because simpler version of the operations of functions were already there.
Others were defined in the custom application.
These were all small functions or additions.
They include:

\begin{description}
\item[Python-body functions] A \gls{ttr} function is modelled by the PyTTR \texttt{Fun} class, where the function body is made up by another PyTTR object. Application of the function is implemented as substituting the argument in the body object. Some operations here have required more advanced operations. A \texttt{LambdaFun} subclass of \texttt{Fun} was thus created to allow any Python code as its body.
\item[Copying a record type] This facilitated the creation of new record types based off an existing one, without altering the original.
\item[Relabeling multiple fields] PyTTR originally only contains a method for relabeling a single field.
\item[Relabel fix] When a relabeled field occurs in a sibling dependent field value, the dependent field value must be updated to use the new label. For instance, if `x' is relabeled to `y' in $\left[ \begin{array}{rcl}\text{x} &:& Ind \\ \text{c} &:& \text{p}(\text{x}) \end{array}\right]$, then $\text{p}(\text{x})$ must be updated to $\text{p}(\text{y})$.
\item[A fix for LazyObject] LazyObject is a class in the PyTTR library used for making references between fields. Prior to the fix, it could only be used for paths longer than one item, for instance $r.x$ but not $r$.
\item[Flatten for record types] The flatten operation was implemented for records but not for record types. Flatten was used together with merging in one version of the implementation, but was later replaced by another approach, using only merging.
\item[Latex output fixes] These did not contribute to the implementation itself, but to the writing of this thesis.
\end{description}
