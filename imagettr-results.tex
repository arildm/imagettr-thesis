\section{Results}
\label{sec:results}

In this section, the model is defined.
First formally, in \gls{ttr}.
Then in Python, using PyTTR but also with some passages of non-PyTTR Python code.
The implementation necessitated some extensions to PyTTR which are also presented.
[The vqa application is presented? sd] [the problem is that currently there is no vqa application...]



\subsection{\Gls{ttr} model}
\label{ssec:ttrmodel}

Three basic types exist in the model.

\begin{description}
\item [$Ind$] A single individual object (or person), such as the reader or the Eiffel Tower.
\item [$Int$] An integer, such as 415.
\item [$Image$] A 2-dimensional digital image. It serves as an identifier to a set of extracted information, and its file type and actual data is not important in this thesis.
\end{description}

A $Segment$ is a record type describing a rectangular bounding box within an (implicit) image (\autoref{eq:seg}).
Its fields contain the center coordinates of the box ($cx$ and $cy$) and the width ($w$) and height ($h$) of the box.
$Ppty$ is the type of functions that can be applied to an individual and return a type (\autoref{eq:ppty}).
In our account the resulting type will be restricted to a ptype that is dependent on the individual, thus describing a property of it.

\begin{equation}\label{eq:seg}
Segment = \left[\begin{array}{rcl}
\text{cx} &:& Int\\
\text{cy} &:& Int\\
\text{w} &:& Int\\
\text{h} &:& Int
\end{array}\right]\end{equation}

\begin{equation}\label{eq:ppty}
Ppty = (Ind \rightarrow Type)\end{equation}

[PTy?]

A perceptual object is a record of the type $Obj$ (\autoref{eq:obj}).
An example record is given in \autoref{eq:objrec}.
%$Obj$ records are the result of performing \textit{object detection}.
%This fact is expressed in TTR as the function type $ObjDetector$ (\autoref{eq:objdetector}).
An object detector is a function from an image to a set of perceptual objects, as captured by the $ObjDetector$ function type (\autoref{eq:objdetector}).

[differences/similarites LSPC and others]

\begin{equation}\label{eq:obj}
Obj = \left[\begin{array}{rcl}
\text{seg} &:& Segment\\
\text{pfun} &:& Ppty \\
\end{array}\right]\end{equation}

\begin{equation}\label{eq:objrec}
obj =
\left[\begin{array}{rcl}
\text{seg} &=& \left[\begin{array}{rcl}
\text{cx} &=& 138\\
\text{w} &=& 276\\
\text{cy} &=& 654\\
\text{h} &=& 809
\end{array}\right]\\
\text{pfun} &=& \lambda v:Ind\ .\ \text{person}(v)\\
\end{array}\right] : Obj\end{equation}

\begin{equation}\label{eq:objdetector}
ObjDetector = ( Image \rightarrow [Obj] )
\end{equation}



\subsubsection{Individuation}

The perceptual object couples a property with a location, but it does not explicitly say anything about any individual object.
In \cite{lspc}, the step from the perceptual to the \textit{conceptual} domain is made by generating a record type that corresponds to a situation, namely the situation that a certain individual has a certain property and is at a certain location.
This situation record type is known as an \textit{individuated object}, and is a subtype of $IndObj$ (\autoref{eq:indobj}).
Here, $x$ is an individual and $loc$ is a location.
$cl$ specifies that $loc$ is the location of $x$, and the purpose of $cp$ is to declare a property of $x$.
$PTy$ is defined as a supertype of all ptypes (\autoref{eq:pty}).

\begin{equation}\label{eq:indobj}
IndObj = \left[\begin{array}{rcl}
\text{x} &:& Ind \\
\text{loc} &:& Segment \\
\text{cp} &:& PTy \\
\text{cl} &:& \text{location}(\text{x}, \text{loc}) \\
\end{array}\right]
\end{equation}

\begin{equation}\label{eq:pty}
PTy : Type
\end{equation}

A function for generating an $IndObj$ subtype from an $Obj$ record is known from \cite{lspc} as an \textit{individuation function}.
It is typed as $IndFun$ (\autoref{eq:indfun}).

\begin{equation}\label{eq:indfun}
IndFun = ( Obj \rightarrow RecType )
\end{equation}

The record type resulting from applying an $IndFun$ function should be a subtype of $IndObj$.

For each record type returned by the individuation function, a record is simultaneously created.
The $loc$ value of this record is naturally identical to the $seg$ value of the $Obj$ input record.
Objects for the remaining fields need to be instantiated on the spot.
Object creation is notated here as $A_{new}$, where the symbol $A$ may vary for the sake of readability.
%For the $x$ field, we create a new individual object $a_{new} : Ind$.
%For the ptype fields $cp$ and $cl$, we also create new objects $e_{new} : r.\text{pfun}(\text{x})$ and $e_{new} : \text{location}(\text{x}, \text{loc})$.

The individuation function is defined in \autoref{eq:indfundef}, with an example application in \autoref{eq:indfunrec}.
The definition uses manifest fields to denote the \textit{fully specified} record type, or singleton record type.

\begin{equation}\label{eq:indfundef}
Individuate = \lambda r : Obj\ . \left[\begin{array}{lcl}
    \text{x} = a_{new} &:& Ind \\
    \text{cp} = e_{new_1} &:& r.\text{pfun}(\text{x}) \\
    \text{cl} = e_{new_2} &:& \text{location}(\text{x}, \text{loc}) \\
    \text{loc} = r.\text{seg} &:& Segment\\
\end{array}\right]
\end{equation}

\begin{equation}\label{eq:indfunrec}
Individuate(
\left[\begin{array}{rcl}
\text{seg} &=& \left[\begin{array}{rcl}
\text{cx} &=& 138\\
\text{w} &=& 276\\
\text{cy} &=& 654\\
\text{h} &=& 809
\end{array}\right]\\
\text{pfun} &=& \lambda v:Ind\ .\ \text{person}(v)\\
\end{array}\right]
) =
\left[\begin{array}{lcl}
    \text{x} = a_0 &:& Ind \\
    \text{cp} = e_0 &:& \text{person}(\text{x}) \\
    \text{cl} = e_1 &:& \text{location}(\text{x}, \text{loc}) \\
    \text{loc} = \left[\begin{array}{rcl}
\text{cx} &=& 138\\
\text{w} &=& 276\\
\text{cy} &=& 654\\
\text{h} &=& 809
\end{array}\right] &:& Segment\\
\end{array}\right]
\end{equation}



\subsubsection{Spatial relations}

Relations may hold between pairs of individuated objects.
How do we detect and model a certain relation between such a pair?

Since we are interested in the spatial relation between a \textit{reference object} and a \textit{located object}, we will be constructing tuple-like records of the type $LocTup$ defined in \autoref{eq:loctup}.
Records of this type contain instantiations (records) of two $IndObj$ record types.
In \autoref{eq:clf}, a classifier is modeled as a function from such a record to a new record type which should describe the relation.

\begin{equation}\label{eq:loctup}
LocTup = \left[\begin{array}{rcl}
    \text{lo} &:& IndObj \\
    \text{refo} &:& IndObj \\
    \end{array}\right]
\end{equation}

\begin{equation}\label{eq:clf}
ClfFun = ( LocTup \rightarrow RecType )
\end{equation}

For instance, a classifier for ``left'' might look like in \autoref{eq:leftclfdef}, where $\kappa_{left}$ is a non-TTR, boolean function.
Of course, the requirement that the individual $r.\text{lo}.\text{x}$ is actually located at $r.\text{lo}.\text{loc}$ (and same for $r.\text{refo}$) is implicit from the typing as $IndObj$, where the field $\text{cl} : \text{location}(\text{x}, \text{loc})$ is necessarily present.

\begin{equation}\label{eq:leftclfdef}
\lambda r : LocTup \ .\ 
\begin{cases}
\left[\begin{array}{rcl}
    \text{cr} &:& \text{left}(r.\text{lo}.\text{x}, r.\text{refo}.\text{x}) \\
\end{array}\right],
& \text{if } \kappa_{left}(r.\text{lo}.\text{loc}, r.\text{refo}.\text{loc}) \\
[], & \text{otherwise}
\end{cases}
\end{equation}



\subsubsection{Agent}

Now, the perceptual-conceptual pieces described above are combined.
We are building an agent who receives information on classified and located objects of an image, and apprehends their basic status and spatial relations.
It also receives the result of parsing a natural-language utterance.
The information is in \gls{ttr} form, which finally allows the agent to connect the two modes.
This provides a means to answer to natural-language questions about the image.

\begin{equation}\label{eq:agent}
Agent = \left[\begin{array}{rcl}
    \text{objdetector} &:& ObjDetector \\
    \text{indfun} &:& IndFun \\
    \text{appr} &:& [(Rec \rightarrow RecType)] \\
    \text{state} &:& AgentState \\
    \end{array}\right]
\end{equation}

\begin{equation}\label{eq:state}
AgentState = \left[\begin{array}{rcl}
    \text{img} &:& Image \\
    \text{perc} &:& [Obj] \\
    \text{bel} &:& [RecType] \\
    \text{utt} &:& RecType \\
    \end{array}\right]
\end{equation}

The fields $objdetector$, $indfun$ and $appr$ of $Agent$ are to be statically defined for a specific agent.
While running, the agent will modify the $AgentState$ record in $state$.

For an agent $agt : Agent$, the perception and question-answering procedure is carried out as follows.

\begin{enumerate}
\item Visual input in the form of an image is received and assigned to $agt.\text{state}.\text{img}$.
\item $objdetector$ is invoked on $agt.\text{state.img}$ and creates a collection of records that are assigned to $agt.\text{state}.\text{perc}$.
\item $indfun$ is, in turn, invoked on each record in $agt.\text{state.perc}$ and resulting record types are added to $agt.\text{state.bel}$.
\item Now, each function in $agt.\text{appr}$ are applied:
	\begin{enumerate}
	\item The fields of the domain record type of the function is considered its arguments.
	\item Each combination of $agt.\text{state.bel}$ record types that matches the argument types is considered for input.
	\item A record is instantiated for each input record type, and the records are combined into one that matches the domain record type of the function.
	\item Resulting record types are added to $agt.\text{state.bel}$
	\end{enumerate}
	For example, the \textit{left} classifier in \autoref{eq:leftclfdef} is applied to each pair of $IndObj$ after instantiating and combining records into a $LocTup$.
\item Any language input is parsed and the resulting record type assigned to $agt.\text{state.utt}$.
\item The record types in $agt.\text{state.bel}$ are combined. If the resulting record type is a relabel-subtype of $agt.\text{state.utt}$, the answer ``yes'' is emitted; otherwise ``no''.
\end{enumerate}

An example state of an agent $agt$ is shown in \autoref{eq:agt}.

\begin{landscape}
\begin{equation}\label{eq:agt}
\renewcommand{\arraystretch}{1.2}
agt = \left[\begin{array}{rcl}
    \text{objdetector} &=& \mathtt{yolo\_detector} \\
    \text{indfun} &=& \mathtt{individuate} \\
    \text{appr} &=& [Clf_{left}, Clf_{right}, Clf_{above}, Clf_{below}] \\
    \text{state} &=& \left[\begin{array}{rcl}
		\text{img} &=& \mathtt{dogride.jpg} \\
		\text{perc} &=& [
			\left[\begin{array}{rcl}
				\text{seg} &=& \left[\begin{array}{rcl}
					\text{w} &=& 197\\
					\text{cx} &=& 452\\
					\text{h} &=& 351\\
					\text{cy} &=& 261
					\end{array}\right]\\
				\text{pfun} &=& \lambda a:Ind\ .\ \text{person}(a)
				\end{array}\right],
			\left[\begin{array}{rcl}
				\text{seg} &=& \left[\begin{array}{rcl}
					\text{w} &=& 422\\
					\text{cx} &=& 435\\
					\text{h} &=& 242\\
					\text{cy} &=& 355
					\end{array}\right]\\
				\text{pfun} &=& \lambda a:Ind\ .\ \text{bicycle}(a)
				\end{array}\right],
			...
			] \\
		\text{bel} &=& \begin{array}{l} [
			\left[\begin{array}{rcl}
				\text{x} = a_0 &:& Ind\\
				\text{cp} = e_0 &:& \text{person}(x)\\
				\text{cl} = e_{1} &:& \text{location}(x, loc)\\
				\text{loc} = \left[\begin{array}{rcl}
					\text{w} &=& 197\\
					\text{cx} &=& 452\\
					\text{h} &=& 351\\
					\text{cy} &=& 261
					\end{array}\right]
					&:& Segment \\
				\end{array}\right],
			{}{} \left[\begin{array}{rcl}
				\text{cr}=e_6 &:& \text{above}(a_{0}, a_{1})
				\end{array}\right],
			... ]
			\end{array} \\
		\text{utt} &=& \left[\begin{array}{rcl}
			\text{x} &:& Ind\\
			\text{y} &:& Ind\\
			\text{c}_\text{0} &:& \text{dog}(x)\\
			\text{c}_\text{1} &:& \text{bicycle}(y)\\
			\text{c}_\text{2} &:& \text{left}(x, y)\\
			\end{array}\right] \\
		\end{array}\right] \\
    \end{array}\right]
\end{equation}
\end{landscape}



\subsection{Python implementation}
\label{ssec:python}

This section presents the Python implementation of the model described above.
The full code, including visualization and more comments, is published as a Jupyter Notebook at \url{https://github.com/arildm/imagettr}.

\subsubsection{Utility functions}

These are PyTTR-related functions that are used in later code.

\begin{lstlisting}[label=lst:utility,caption=Utility functions]
from pyttr.ttrtypes import *
from pyttr.utils import *
import PIL.Image
from functools import reduce

# The Ind TTR type is used by these utility functions so it needs defining here already.
Ind = BType('Ind')
    
def copy_rectype(T):
    """Make another copy of a record type."""
    R = RecType()
    for k, v in T.comps.__dict__.items():
        R.addfield(k, v)
    return R

def rectype_relabels(T, rlbs):
    """Relabel multiple fields, given a dict of from-to pairs."""
    for k1, k2 in rlbs.items():
        T.Relabel(k1, k2)
    return T

def rectype_merges(Ts):
    """Merge a list of RecTypes."""
    return reduce((lambda T, U: T.merge(U)), Ts, RecType())

def is_basic_type(T):
    """Whether a type is a "basic field", i.e. a BType or a SingletonType of a BType."""
    tn = lambda T: type(T).__name__
    return (tn(T) == 'BType') if tn(T) != 'SingletonType' else is_basic_type(T.comps.base_type)

def basic_fields(T):
    """The labels of basic fields in a RecType."""
    return [k for k, v in T.comps.__dict__.items() if is_basic_type(v)]

def nonbasic_fields(T):
    """The labels of non-basic fields in a RecType."""
    return [k for k, v in T.comps.__dict__.items() if not is_basic_type(v)]

ptypes = dict()
def mkptype(sym, types=[Ind], vars=['v']):
    """Make preds and ptypes identifiable by their predicate names."""
    id = '/'.join([sym, ','.join(show(type) for type in types), ','.join(vars)])
    if id not in ptypes:
        ptypes[id] = PType(Pred(sym, types), vars)
    return ptypes[id]

def create_fun(pred_name, vars=['a']):
    """Create a function of a given number of Inds (length of vars).
    
    Example: create_fun('give', 'abc') --> \a. \b. \c. give(a, b, c)
    """
    fun = mkptype(pred_name, types=[Ind]*len(vars), vars=vars)
    for v in reversed(vars):
        fun = Fun(v, Ind, fun)
    return fun
\end{lstlisting}

\subsubsection{Extensions to PyTTR}

\begin{lstlisting}[label={lst:mergeunconflict},caption={merge\_unconflict()}]
def unique_labels(T):
    """Relabel a RecType so each field label is unique over all RecTypes."""
    for l, v in T.comps.__dict__.items():
        if '_' not in l:
            T.Relabel(l, gensym(l))
    return T

def merge_unconflict(T1, T2):
    """Merge two RecTypes after making sure they do not share any field labels."""
    T1c = unique_labels(copy_rectype(T1))
    T2c = unique_labels(copy_rectype(T2))
    return T1c.merge(T2c)
\end{lstlisting}

For example, if $T_1 = T_2 = [x:Ind]$, then $\mathtt{merge\_unconflict}(T_1, T_2)$ evaluates to $\left[\begin{array}{rcl} x_0&:&Ind \\ x_1&:&Ind \end{array}\right]$ (or a similar record type with different subscript indices).

\begin{lstlisting}[label={lst:useindfieldlabels},caption={use\_ind\_field\_labels()}]
def use_ind_field_labels(T):
    """c:foo(a) becomes c:foo(x) if x=a:Ind is present."""
    T = copy_rectype(T)
    for l, v in T.comps.__dict__.items():
        if isinstance(v, SingletonType) and v.comps.base_type == Ind:
            a = v.comps.obj
            T.Relabel(a, l)
            # Undo the relabeling of the Ind field itself.
            T.comps.__dict__[l] = SingletonType(Ind, a)
    return T
\end{lstlisting}

\begin{lstlisting}[label={lst:unsingleton},caption={unsingleton()}]
def unsingleton(T):
    """Remove singleton specifications of a type: x=a:Ind becomes x:Ind."""
    T2 = RecType()
    for l, v in T.comps.__dict__.items():
        T2.addfield(l, v if not isinstance(v, SingletonType) else v.comps.base_type)
    return T2
\end{lstlisting}

The condition described in \autoref{ssec:languagevqa} necessitated the ability to find a relabeling $\eta$ that would fulfill a subtype relation $A \sqsubseteq Q_\eta$.
A simple approach to finding such a relabeling is to list every possible combination and one-by-one perform relabeling and check subtypeness.
However, that is computationally very expensive, and not very interesting even if speed is not a priority.

Another quicker approach is to not perform the relabeling in all steps.
Subtypeness can instead be checked field-wise:
For every field $\langle\ell_Q, T_Q\rangle$ in $Q$, if there is a field $\langle\ell_A, T_A\rangle$ in $A$ such that $T_A \sqsubseteq T_Q$, then let $\eta(\ell_Q) = \ell_A$.
If $\eta$ covers all fields in $Q$, then it follows that $A \sqsubseteq Q_\eta$.

However, we need to mind the types that are dependent on other fields.
For example, $\text{dog}(\text{x}) \cancel{\sqsubseteq} \text{dog}(\text{y})$ even if both $\text{x}:Ind$ and $\text{y}:Ind$ are fields in the respective record types.
To remedy this, the simple approach mentioned above is carried out as a first step, but for basic-type fields only.
Then, for every basic-field relabeling, the second approach is carried out.
In the example case, some of the basic-type relabelings will then have relabeled $\text{y}$ to $\text{x}$ so that the field-wise check becomes $\text{dog}(\text{x}) \sqsubseteq \text{dog}(\text{x})$.

\begin{lstlisting}[label=lst:subtyperlb, caption=Implementation of the relabel-subtype relation.]
from itertools import permutations, combinations

def find_subtype_relabeling(T, U):
    '''Could record type T be a sub type of record type U if relabeling in T is allowed?'''
    # Find possible relabelings for basic-type fields
    basic_label_permutations = set(ps[:len(basic_fields(U))] for ps in permutations(basic_fields(T)))
    
    for tks in basic_label_permutations:
        # Copy U and try a basic-fields relabeling
        U2 = copy_rectype(U)
        rlb = dict(zip(basic_fields(U), tks))
        rectype_relabels(U2, rlb)
        
        # For each U field, find a T field that is a subtype
        match = dict()
        for uk in nonbasic_fields(U2):
            for tk in nonbasic_fields(T):
                if T.comps.__dict__[tk].subtype_of(U2.comps.__dict__[uk]):
                    match[uk] = tk
                    break
            if uk not in match:
                break

        # Successful if all non-basic fields match.
        if len(match) == len(nonbasic_fields(U2)):
            return dict(**rlb, **match)
    return None
\end{lstlisting}



\subsubsection{YOLO usage}

\begin{lstlisting}[label=lst:yolo, caption=Invoking YOLO]
from darkflow.net.build import TFNet
import numpy as np

tfnet = TFNet({"model": "yolo/yolo.cfg", "load": "yolo/yolo.weights",
    'config': 'yolo', "threshold": 0.2})

yolo_out = dict()
def yolo(img):
    """Invokes YOLO on a PIL image, caches and returns the result."""
    if str(img) not in yolo_out:
        yolo_out[str(img)] = tfnet.return_predict(np.array(img))
    return yolo_out[str(img)]

def yolo_coords(o):
    """Extract the coordinates from a YOLO output item as ((x0,y0), (x1,y1))."""
    return (o['topleft']['x'], o['topleft']['y']), (o['bottomright']['x'], o['bottomright']['y'])

def xy1xy2_to_cwh(x1, y1, x2, y2):
    '''Transform to center, width and height.'''
    return {'cx': int(x1/2 + x2/2), 'cy': int(y1/2 + y2/2), 'w': x2 - x1, 'h': y2 - y1}
\end{lstlisting}



\subsubsection{Language parsing}

[...]
 Parsing to PyTTR cannot really be done directly. NLTK feature grammars support strings and FOPC. Variable substitution is only allowed in FOPC. We produce a FOPC conjunction of ptypes, for each of which we create a new field.

\begin{lstlisting}[label=lst:grammar, caption=Basic parsing of natural language into PyTTR object.]
import nltk

grammar = nltk.grammar.FeatureGrammar.fromstring(r'''
%start S
S[SEM=<?s(x) & ?vp(x, y)>] -> NP[SEM=?s] VP[SEM=?vp]
NP[SEM=<?det(?n)>] -> Det[SEM=?det] N[SEM=?n]
Det[SEM=<\P a.P(a)>] -> 'a' | 'an'
N[SEM=<dog>] -> 'dog'
N[SEM=<car>] -> 'car'
N[SEM=<person>] -> 'person'
N[SEM=<bicycle>] -> 'bicycle'
N[SEM=<backpack>] -> 'backpack'
VP[SEM=?pp] -> 'is' PP[SEM=?pp]
PP[SEM=<\a b.(?prep(a, b) & ?o(b))>] -> Prep[SEM=?prep] NP[SEM=?o]
Prep[SEM=<left>] -> 'to' 'the' 'left' 'of'
Prep[SEM=<right>] -> 'to' 'the' 'right' 'of'
Prep[SEM=<above>] -> 'above'
Prep[SEM=<under>] -> 'under'
''')
parser = nltk.FeatureChartParser(grammar)

def fopc_to_pyttr(expr, T=RecType()):
    """Turns a FOPC object into a RecType."""
    from nltk.sem.logic import ApplicationExpression, AndExpression
    if isinstance(expr, ApplicationExpression):
        pred, args = expr.uncurry()
        T.addfield(gensym('c'), mkptype(str(pred), vars=[str(a) for a in args]))
        for x in args:
            if str(x) not in T.comps.__dict__:
                T.addfield(str(x), Ind)
    if isinstance(expr, AndExpression):
        fopc_to_pyttr(expr.first, T)
        fopc_to_pyttr(expr.second, T)
    return T

def eng_to_pyttr(text):
    trees = parser.parse(text.lower().split())
    sem = nltk.sem.root_semrep(list(trees)[0])
    T = fopc_to_pyttr(sem)
    return T
\end{lstlisting}



\subsubsection{PyTTR implementation}

The basic type $Ind$ was defined along with the utility functions in \autoref{lst:utility}.

\begin{lstlisting}[label={lst:pyttrbasic},caption={individuate()}]
Int = BType('Int')
Int.learn_witness_condition(lambda x: isinstance(x, int))

Image = BType('Image')
Image.learn_witness_condition(lambda x: isinstance(x, PIL.Image.Image))

Segment = RecType({'cx': Int, 'cy': Int, 'w': Int, 'h': Int})
Ppty = FunType(Ind, Ty)
Obj = RecType({'seg': Segment, 'pfun': Ppty})

Objs = ListType(Obj)
ObjDetector = FunType(Image, Objs)
\end{lstlisting}

[something about the object detector]

\begin{lstlisting}[label=lst:pyttr_yolo, caption=Connecting YOLO output to PyTTR]
def yolo_detector(i):
    """Creates IndObj records for YOLO results."""
    return [Rec({
        'seg': Rec(xy1xy2_to_cwh(*yolo_coords(o)[0], *yolo_coords(o)[1])),
        'pfun': create_fun(o['label'].replace(' ', '_')),
    }) for o in yolo(i)] # @todo RBG/BGR?
ObjDetector.witness_cache.append(yolo_detector)

objs = yolo_detector(img)
\end{lstlisting}

PyTTR includes a class $Fun$ which models TTR functions.
It does not, however, support usage of the argument within the function body.
The individuation function was therefore implemented in Python.

\begin{lstlisting}[label={lst:individuate},caption={individuate()}]
PTy = Type('PTy')
PTy.learn_witness_condition(lambda p: isinstance(p, HypObj) \
    and forsome(p.types, lambda t: isinstance(t, PType)))

IndObj = RecType({
    'x' : Ind,
    'loc' : Segment,
    'cp' : PTy,
    'cl' : create_fun('location', 'ab').app('x').app('loc'),
})
IndFun = FunType(Obj, RecTy)

def individuate(r):
    cp = r.pfun.app('x')
    cl = create_fun('location', 'ab').app('x').app('loc')
    return RecType({
        'x': SingletonType(Ind, Ind.create()),
        'cp': SingletonType(cp, cp.create()),
        'loc': SingletonType(Segment, r.seg),
        'cl': SingletonType(cl, cl.create()),
    })
IndFun.witness_cache.append(individuate)

indobjs = [individuate(r) for r in objs]
\end{lstlisting}

[something about spatial relation classifiers]

\begin{lstlisting}[label=lst:relclf, caption=Spatial relation classifiers]
from itertools import product

LocTup = RecType({'lo': IndObj, 'refo': IndObj})
ClfRes = RecType({'cr': PTy})
RelClf = FunType(LocTup, ClfRes)

location_relation_classifiers = {
    'left': lambda a, b: a.cx < b.cx,
    'right': lambda a, b: a.cx > b.cx,
    'above': lambda a, b: a.cy < b.cy,
    'below': lambda a, b: a.cy > b.cy,
}

def get_relclfs():
    for pred, f in location_relation_classifiers.items():
        def relclf(r):
            if f(r.lo.loc, r.refo.loc):
                c = create_fun(pred, 'ab').app(r.lo.x).app(r.refo.x)
                return RecType({'cr': SingletonType(c, c.create())})
            return RecType()
        RelClf.witness_cache.append(relclf)
        yield relclf

def find_all_rels(indobjs):
    """Find all relations between IndObj records."""
    for relclf in get_relclfs():
        for loT, refoT in product(indobjs, indobjs):
            loctup = Rec({'lo': loT.create(), 'refo': refoT.create()})
            yield relclf(loctup)

rels = list(find_all_rels(indobjs))
\end{lstlisting}

\begin{lstlisting}[label=lst:bel, caption=Combining beliefs.]
def combine_beliefs(bel):
    """Combine a list of belief record types into one."""
    return unsingleton(use_ind_field_labels(reduce(merge_unconflict, bel, RecType())))

bel = indobjs + rels
bel_comb = combine_beliefs(bel)
\end{lstlisting}

[...]

\begin{lstlisting}
def validate_utt(utt, bel):
    return bool(find_subtype_relabeling(combine_beliefs(bel), utt))

def relabel_utt(utt, bel_comb):
    """Relabels an utterance record type to match the combined beliefs.
    
    The result will be a subtype of bel_comb.
    """
    rlb = find_subtype_relabeling(bel_comb, utt)
    return rectype_relabels(utt, rlb)
\end{lstlisting}

\subsection{Discussion}
\label{sec:discussion}

Contradiction of Logan \& Sadler's "evidence" for their "theory of apprehension" (which is different from mine)? (Already Regier \& Carlson did.)
[no difference -sd]

Not a full VQA solution.
It can only answer one question type, and only in the form "A P is R a Q", which is not even a question.
With only the extension of parsing, it could understand (= educe situation record types) more complex forms like "A R1 B1 and R2 B2", "A1 R1 B1 and A2 R2 B2".
"What is R B?"
"What color is the A?"
"How many A are there?" etc.

...

PyTTR extensions (here or Conclusions?)

Functional aspect (Coventry).
