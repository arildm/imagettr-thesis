\renewcommand{\sectionautorefname}{Section}
\let\subsectionautorefname\sectionautorefname
\let\subsubsectionautorefname\sectionautorefname
\section{Results}
\label{sec:results}

The results of this project consists primarily of a \gls{ttr} model, which connects language to visual perception in a basic \gls{vqa} setting and uses \gls{ttr} throughout (\autoref{sec:ttrmodel}).
The project also solves a few significant sub-problems, which are not entirely within the \gls{ttr} model but tightly connected to it.
These have been solved as algorithms implemented in Python.
They are: efficiently combining multiple belief record types into one (\autoref{sec:combine}), basic translation from first-order logic to \gls{ttr} (\autoref{sec:parsing}) and finally a subtype relation insensitive to labels, $\subtrlb$ (\autoref{sec:subtyperelabeling}).

The code is written in a Jupyter notebook file and released at \url{https://github.com/arildm/imagettr} under the open-source MIT license.
This section contains references to that code (specifically the version tagged 1.0) in the form of notebook cell numbers.



\subsection{\Gls{ttr} model}
\label{sec:ttrmodel}

The types in the \gls{ttr} model are largely based on \cite{lspc}, but the $\type{Segment}$ type is new, the individuation function is improved and the $\type{RelClf}$ mechanism is more concretely defined.
The $\type{Agent}$ type is also new.

In the code, the \gls{ttr} model is constructed in notebook cells 9–10, 14–19 and 23–26.

Four basic types exist in the model.

\begin{description}
\item [$\type{Ind}$] A single individual object, such as the reader or the Eiffel Tower.
\item [$\type{Int}$] An integer, such as 415.
\item [$\type{Image}$] A 2-dimensional digital image.
It serves as an identifier to a set of extracted information, and its file type and actual data is not important in this thesis.
\item [$\type{String}$] A piece of plain text of arbitrary length.
\end{description}

A $\type{Segment}$ is a record type describing a rectangular bounding box within an (implicit) image (\autoref{eq:seg}).
Its fields contain the center coordinates of the box (`cx' and `cy') and the width (`w') and height (`h') of the box.
$\type{Ppty}$ is the type of functions that can be applied to an individual and return a type (\autoref{eq:ppty}).
In our account the resulting type will be restricted to a ptype that is dependent on the individual, thus describing a property of it.

\begin{equation}\label{eq:seg}
\type{Segment} = \rec{
\text{cx} &:& \type{Int}\\
\text{cy} &:& \type{Int}\\
\text{w} &:& \type{Int}\\
\text{h} &:& \type{Int}
}\end{equation}

\begin{equation}\label{eq:ppty}
\type{Ppty} = (\type{Ind} \rightarrow \type{Type})\end{equation}

%[PTy?]



\subsubsection{Object detection}

A \textit{perceptual object} is a record of the record type $\type{Obj}$ (\autoref{eq:obj}).
It contains a bounding box (the `seg' field) and a property (`pfun').
An example record is given in \autoref{eq:objrec}.
%$Obj$ records are the result of performing \textit{object detection}.
%This fact is expressed in TTR as the function type $ObjDetector$ (\autoref{eq:objdetector}).
An object detector is a function from an image to a set of such perceptual objects, as captured by the $\type{ObjDetector}$ function type (\autoref{eq:objdetector}).
The YOLO object detector is typed as $\type{ObjDetector}$ in notebook cell 14.

%[differences/similarites LSPC and others]

\begin{equation}\label{eq:obj}
\type{Obj} = \rec{
\text{seg} &:& \type{Segment}\\
\text{pfun} &:& \type{Ppty} \\
}\end{equation}

\begin{equation}\label{eq:objrec}
obj =
\rec{
\text{seg} &=& \rec{
\text{cx} &=& 435\\
\text{w} &=& 422\\
\text{cy} &=& 355\\
\text{h} &=& 242
}\\
\text{pfun} &=& \lambda v:\type{Ind}\ .\ \text{bicycle}(v)\\
} : \type{Obj}\end{equation}

\begin{equation}\label{eq:objdetector}
\type{ObjDetector} = ( \type{Image} \rightarrow [\type{Obj}] )
\end{equation}



\subsubsection{Individuation}

The perceptual object couples a property with a location, but it does not explicitly say anything about any individual object.
In \cite{lspc}, the step from the perceptual to the \textit{conceptual} domain is made by generating a record type that corresponds to a situation, namely the situation that a certain individual has a certain property and is at a certain location.
This situation record type is known as an \textit{individuated object}, and is a subtype of $\type{IndObj}$ (\autoref{eq:indobj}).

\begin{equation}\label{eq:indobj}
\type{IndObj} = \rec{
\text{x} &:& \type{Ind} \\
\text{cp} &:& \type{PType} \\
\text{cl} &:& \text{location}(\text{x}, \text{loc}) \\
\text{loc} &:& \type{Segment} \\
}
\end{equation}

Here, `x' is an individual and `loc' is a bounding box.
The `cl' field specifies that `loc' is the location of `x', and the purpose of `cp' is to declare a property of `x'.
As all individuated objects are subtypes of $\type{IndObj}$, the `cp' field must have a type that will be a supertype of any ptype; we define $\type{PType}$ to be this.

\begin{definition}
For any ptype $T = \mathit{pred}(v_1, ..., v_n)$, $T \sqsubseteq \type{PType}$.
\end{definition}

A function for generating an $\type{IndObj}$ subtype from an $\type{Obj}$ record is known from \cite{lspc} as an \textit{individuation function}.
It is typed as $\type{IndFun}$ (\autoref{eq:indfun}).
Note that it generates a record type, in contrast to $\type{ObjDetector}$ which generates records.

\begin{equation}\label{eq:indfun}
\type{IndFun} = ( \type{Obj} \rightarrow \type{RecType} )
\end{equation}

The individuation function is defined as $f_\type{IndFun}$ in \autoref{eq:indfundef} (notebook cell 15).
The record type resulting from applying $f_\type{IndFun}$ is a subtype of $\type{IndObj}$, where the `x' and `loc' fields are specified using manifest fields.
The `x' field is specified as a newly instantiated $\type{Ind}$ object, $a_n$ (where $n$ is a number such that the new instatiation is unique).
The `loc' field is specified as the value of `seg' in the $\type{Obj}$ record.
Having these fields specified allows us to access the values (the individual and the location) at a later stage, when we are looking at the $\type{IndObj}$ record types and not the $\type{Obj}$ records.
For the types in the `cl' and `cp' fields, it is not important to know \textit{what} the proof is, as long as there is a proof.
Therefore, they do not need to be instantiated and specified.

The instantiation of new individual objects $a_n$ assumes that no two $\type{Obj}$ records describe the same individual.
If more than one object detection model were applied, perhaps in an attempt at wider coverage, then we might end up with generating multiple individual objects where a human observer would detect only one.
A merging step could then be added in connection with the individuation procedure, where objects of the same property and similar locations are merged as one.
Furthemore, the detection models may return different but similar labels, such as ``car'' and ``truck''.
Covering these cases would additionally require measuring the similarity of different semantic concepts.

An example application of $f_\type{IndFun}$ is shown in \autoref{eq:indfunrec}.
The output record type describes a situation where an individual identified as $a_0$ is classified as a bicycle and is occupying a $422 \times 242$-sized rectangle with its center at $(435, 355)$.

\begin{equation}\label{eq:indfundef}
f_\type{IndFun} = \lambda r : \type{Obj}\ . \rec{
    \text{x} = a_n &:& \type{Ind} \\
    \text{cp} &:& r.\text{pfun}(\text{x}) \\
    \text{cl} &:& \text{location}(\text{x}, \text{loc}) \\
    \text{loc} = r.\text{seg} &:& \type{Segment}\\
}
\end{equation}

\begin{equation}\label{eq:indfunrec}
f_\type{IndFun}(
\rec{
\text{seg} &=& \rec{
\text{cx} &=& 435\\
\text{w} &=& 422\\
\text{cy} &=& 355\\
\text{h} &=& 242
}\\
\text{pfun} &=& \lambda v:\type{Ind}\ .\ \text{bicycle}(v)\\
}
) =
\rec{
    \text{x} = a_0 &:& \type{Ind} \\
    \text{cp} &:& \text{bicycle}(\text{x}) \\
    \text{cl} &:& \text{location}(\text{x}, \text{loc}) \\
    \text{loc} = \rec{
        \text{cx} &=& 435\\
        \text{w} &=& 422\\
        \text{cy} &=& 355\\
        \text{h} &=& 242
		} &:& \type{Segment}\\
}
\end{equation}



\subsubsection{Spatial relation classification}

Relations may hold between pairs of individuated objects.
How do we detect and model a certain relation between such a pair?

Since we are interested in the spatial relation between a \textit{reference object} and a \textit{located object}, we will be constructing tuple-like records of the type $\type{LocTup}$ defined in \autoref{eq:loctup}.
Records of this type contain instantiations (records) of two $\type{IndObj}$ record types.
In \autoref{eq:clf}, a classifier is modeled as a function from such a record to a new record type which should describe the relation.

\begin{equation}\label{eq:loctup}
\type{LocTup} = \rec{
    \text{lo} &:& \type{IndObj} \\
    \text{refo} &:& \type{IndObj} \\
    }
\end{equation}

\begin{equation}\label{eq:clf}
\type{RelClf} = ( \type{LocTup} \rightarrow \type{RecType} )
\end{equation}

For instance, a classifier for ``left'' might look like in \autoref{eq:leftclfdef}, where $\kappa_\text{left}$ is a non-\gls{ttr}, boolean function.
Of course, the requirement that the individual $r.\text{lo}.\text{x}$ is actually located at $r.\text{lo}.\text{loc}$ (and same for $r.\text{refo}$) is implicit from the typing as $\type{IndObj}$, where a field typed as $\text{location}(\text{x}, \text{loc})$ is necessarily present.

\begin{equation}\label{eq:leftclfdef}
\lambda r : \type{LocTup} \ .\ 
\begin{cases}
\rec{
    \text{x} &:& r.\text{lo}.\text{x} \\
    \text{y} &:& r.\text{refo}.\text{x} \\
    \text{cr} &:& \text{left}(\text{x}, \text{y}) \\
},
& \text{if } \kappa_\text{left}(r.\text{lo}.\text{loc}, r.\text{refo}.\text{loc}) \\
[\:], & \text{otherwise}
\end{cases}
\end{equation}

This is implemented in notebook cell 16, where the function \texttt{relclf} creates functions like the one in \autoref{eq:leftclfdef}.
The function \texttt{get\_relclfs} creates such a function for each of the four predicate-classifier pairs, and \texttt{find\_all\_rels} applies each classifier to each $\type{IndObj}$ pair.
(The latter step is later re-implemented in the agent algorithm.)



%%%%%%%%
\begin{comment}
\subsubsection{Combining beliefs}

The hitherto generated types are considered our beliefs.
As described in \autoref{sec:languagevqa}, we can answer to a polar question if we \textit{combine} the beliefs to a scene type and check whether it is a subtype of the question type, $S \sqsubseteq Q$.
How is this combining carried out?
A direct application of the \textit{merge} operation is not suitable for this, as we have labels reocurring in multiple record types.
Instead, all record types are relabeled with new, unique labels, before being merged.

\label{def:cfmerge}
If $T_1$ and $T_2$ are record types, then the \textbf{conflict-free merge} $T_1 \underset{u}{\wedge} T_2$ is a merge of the record types relabeled such that they do not share any labels.

If the belief types are $T_1, T_2, ..., T_n$, they are combined to $T_1 \underset{u}{\wedge} T_2 \underset{u}{\wedge} ... \underset{u}{\wedge} T_n$.
\end{comment}
%%%%%%%%



\subsubsection{Beliefs}

The set of individuated objects, added to the set of relation classification results, forms a set of beliefs.
Each of these types is a situation held to be true, by virtue of resulting from perception mechanisms.
They can be \textit{combined} into one \textit{scene} record type which describes the full scene.
The method of such combination is not trivial, and is discussed in \autoref{sec:combine}.



\subsubsection{Language}
\label{sec:ttrlanguage}

%The connection between visual perception and language happens by means of using the same representation (TTR) for both modes.
%The representation of the former mode has been discussed above.
%Digitally encoded visual data is input to the model, which uses an external object detector to extract information which forms the base of further acts of perception.
%
%For the language side, this model does not concern itself with parsing.
%Instead, the parsing of natural language is expected to occur outside the model.
%The resulting TTR representation 

% How do we go from language to TTR?
In order to add the  connection to language, any natural-language utterance must be parsed into \gls{ttr}.
As discussed in \autoref{sec:languagevqa}, \gls{ttr}-based natural-language parsing has not yet been implemented as a ready-to-use library.
Therefore, parsing must be done externally to the \gls{ttr} model.
This is described in \autoref{sec:parsing}.
%Any utterance is input to the model only as a TTR record type.
% What will the parsing result look like in TTR?
Equation~\ref{eq:question} models the question ``Is there a lamp above a table?'' (equivalent to the statement ``There is a lamp above a table'').

\begin{equation}\label{eq:question}
\rec{
    \text{x} &:& \type{Ind} \\
    \text{y} &:& \type{Ind} \\
    \text{c}_\text{x} &:& \text{lamp}(\text{x}) \\
    \text{c}_\text{y} &:& \text{table}(\text{y}) \\
    \text{c}_\text{r} &:& \text{above}(\text{x}, \text{y}) \\
    }
\end{equation}

% How do we use the question TTR type?
% TODO In terms of DIALOGUE ACTS?
As mentioned in \autoref{sec:languagevqa}, answering the question corresponds to checking whether $S \sqsubseteq Q$.
An important problem, however, stems from the fact that \gls{ttr} record types are labeled.
In general, fields in the scene type and question type will not share labels in a way that enables simple subtype checking to be useful.
The remedy to this is an alternative subtype relation $\subtrlb$ which is insensitive to label names.
This new relation is discussed in \autoref{sec:subtyperelabeling}.



\subsubsection{Agent}
\label{sec:agent}

The perceptual-conceptual pieces described above are now connected in an \textit{agent} record type (\autoref{eq:agent} and \autoref{eq:state}) with associated manipulation algorithms.
Upon receiving an image, it will carry out object detection, individuation and spatial relation classification, in order to form its beliefs.
It may also receive a parsed natural-language utterance, which will then be verified against the beliefs.
%The information is in \gls{ttr} form, which finally allows the agent to connect the two modes.
A construction like this provides a means to answer to natural-language questions about the image.

\begin{equation}\label{eq:agent}
\type{Agent} = \rec{
    \text{objdetector} &:& \type{ObjDetector} \\
    \text{indfun} &:& \type{IndFun} \\
    \text{relclfs} &:& [\type{RelClf}] \\
    \text{state} &:& \type{AgentState} \\
    }
\end{equation}

\begin{equation}\label{eq:state}
\type{AgentState} = \rec{
    \text{img} &:& \type{Image} \\
    \text{perc} &:& [\type{Obj}] \\
    \text{bel} &:& [\type{RecType}] \\
    \text{utt} &:& \type{String} \\
    \text{que} &:& \type{RecType} \\
    }
\end{equation}

The fields `objdetector', `indfun' and `relclfs' of $\type{Agent}$ are to be statically defined for a specific agent.
While running, the agent will modify the $\type{AgentState}$ record in `state'.
The `perc' field will contain a list of perceptual objects.
The `bel' field will be a list of beliefs modelled as record types:
individuated objects and spatial relations between individuals.

For an agent record $ag : \type{Agent}$, the perception and question-answering procedure is carried out as follows.

\paragraph{Visual perception}
\renewcommand{\itemautorefname}{Step}

\begin{enumerate}
\item Visual input in the form of an image is received and assigned to $ag.\text{state}.\text{img}$.
\item $ag.\text{objdetector}$ is invoked on $ag.\text{state.img}$ and creates a collection of perceptual object records that are assigned to $ag.\text{state}.\text{perc}$.
\item $ag.\text{indfun}$ is, in turn, invoked on each record in $ag.\text{state.perc}$ and resulting individuated object record types are added to $ag.\text{state.bel}$.
\item \label{item:relclfsbel} Now, each function in $ag.\text{relclfs}$ is applied to each pair of record types in $ag.\text{state.bel}$:
	\begin{enumerate}
	%\item The fields of the domain record type of the function is considered its arguments.
	%\item Each combination of $ag.\text{state.bel}$ record types that matches the argument types is considered for input.
	%\item The input record types are combined to match the domain record type of the function, and the type is instantiated.
		\item For each pair $T_1$ and $T_2$ in $ag.\text{state.bel}$, a $\type{LocTup}$ record type is constructed as $\rec{\text{lo} &:& T_1 \\ \text{refo} &:& T_2}$.
			Note that this will be specified to certain individuals and segments, and is thus more informative than the plain $\type{LocTup}$ type.
		\item The specified $\type{LocTup}$ type is instantiated to a record.
	\item Each function in $ag.\text{relclfs}$ is applied to the created record, and the record type resulting from each application is added to $ag.\text{state.bel}$ unless it is empty ($[\:]$).
	\end{enumerate}
		For example, the ``left'' classifier in \autoref{eq:leftclfdef} is applied to each pair of $\type{IndObj}$ after combining them into a $\type{LocTup}$ and instantiating it.
		Note that the $\type{IndObj}$ have manifest fields which carry on to the $\type{LocTup}$ type, so it is more specific than just instantiating $\type{LocTup}$ itself.
\end{enumerate}

The individuated objects and the spatial relations are contained in the same list, $ag.\text{state.bel}$, which models beliefs of the agent.
(Remember that an individuated object is a belief that a certain individual has a certain property and location.)
In extension, this list may contain record types of many other shapes, perhaps describing situations where an idividual has a certain color or two individuals are involved in an event (as suggested in \autoref{sec:futurework}).
\autoref{item:relclfsbel} works here because $ag.\text{state.bel}$ is sure to contain only $\type{IndObj}$ record types at this point, and because $ag.\text{relclfs}$ only contains $\type{RelClf}$ functions.
The general case would necessitate a different formulation (and a new name for the `relclfs' field), perhaps utilising subtype checking to qualify possible argument combinations.

\paragraph{Language}

\begin{enumerate}
\item Any language input utterance is assigned to $ag.\text{state.utt}$.
\item The utterance is parsed and the resulting record type ($Q$) assigned to $ag.\text{state.que}$.
\item The record types in $ag.\text{state.bel}$ are combined to one ($S$).
If the resulting record type is a relabel-subtype of $ag.\text{state.que}$, $S \subtrlb Q$ the answer ``Yes'' is emitted; otherwise ``No''.
\end{enumerate}

The $\type{Agent}$ type is implemented in notebook cell 23 and instatiated as a record in cell 24.
Its algorithms are implemented in cell 25 as \texttt{agent\_see} for the \textit{visual perception} part and \texttt{agent\_hear} for \textit{language}.

The state of an agent is a record of the type $\type{Agent}$.
An example state $ag$ is shown in \autoref{eq:ag}.

\begin{landscape}
\begin{equation}\label{eq:ag}
%\arraycolsep=1pt
\def\arraystretch{1.2}
ag =
\rec{
    \text{objdetector} &=& \mathtt{yolo\_detector} \\
    \text{indfun} &=& \mathtt{indfun} \\
    \text{relclfs} &=& [\type{Clf}_\text{left}, \type{Clf}_\text{right}, \type{Clf}_\text{above}, \type{Clf}_\text{below}] \\
    \text{state} &=& \rec{
		\text{img} &=& \text{\tt <Image "dogride.jpg">} \\
		\text{perc} &=& [
			\rec{
				\text{seg} &=& \rec{
					\text{cx} &=& 452\\
					\text{w} &=& 197\\
					\text{cy} &=& 261 \\
					\text{h} &=& 351\\
					}\\
				\text{pfun} &=& \lambda a:\type{Ind}\ .\ \text{person}(a)
				},
			\rec{
				\text{seg} &=& \rec{
					\text{cx} &=& 435\\
					\text{w} &=& 422\\
					\text{cy} &=& 355 \\
					\text{h} &=& 242\\
					}\\
				\text{pfun} &=& \lambda a:\type{Ind}\ .\ \text{bicycle}(a)
				},
			... ] \\
		\text{bel} &=& [
			\rec{
				\text{x} = a_0 &:& \type{Ind}\\
				\text{cp} &:& \text{person}(x)\\
				\text{cl} &:& \text{location}(x, loc)\\
				\text{loc} = \rec{
					\text{cx} &=& 452\\
					\text{w} &=& 197\\
					\text{cy} &=& 261 \\
					\text{h} &=& 351\\
					}
					&:& \type{Segment} \\
				},
			{}{} \rec{
				\text{x} = a_0 &:& \type{Ind} \\
				\text{y} = a_1 &:& \type{Ind} \\
				\text{cr} &:& \text{above}(\text{x}, \text{y})
				},
			... ] \\
        \text{utt} &=& \text{``Is there a dog to the left of a bicycle?''} \\
		\text{que} &=& \rec{
			\text{x} &:& \type{Ind}\\
			\text{y} &:& \type{Ind}\\
			\text{c}_\text{0} &:& \text{dog}(x)\\
			\text{c}_\text{1} &:& \text{bicycle}(y)\\
			\text{c}_\text{2} &:& \text{left}(x, y)\\
			} \\
		} \\
    }
\end{equation}
\end{landscape}



\subsection{Combining situation types}
\label{sec:combine}

The beliefs of the agent are formed by a collection of record types.
These are \textit{combined} into one, in order to build the scene type $S$.

Consider the spatial relation classifiers, which create record types with the fields `x', `y', and `cr'.
One of these record types may be specified so that it declares that an individual $a_1$ is above another individual $a_2$ (\autoref{eq:combineterm1}).
Another record type may declare that $a_2$ is to the right of $a_1$ (\autoref{eq:combineterm2}).
The \textit{combination} of these beliefs, which declares both these relations, is described by \autoref{eq:combination}.
To avoid conflict, some fields have been relabeled, prompting the expectation that combination results have no informative or predictable labels.

\begin{equation} \label{eq:combineterm1}
T_1 = \rec{
    \text{x}=a_1 &:& \type{Ind} \\
    \text{y}=a_2 &:& \type{Ind} \\
    \text{cr} &:& \text{above}(\text{x}, \text{y})
    }
\end{equation}

\begin{equation} \label{eq:combineterm2}
T_2 = \rec{
    \text{x}=a_2 &:& \type{Ind} \\
    \text{y}=a_1 &:& \type{Ind} \\
    \text{cr} &:& \text{right}(\text{x}, \text{y})
    }
\end{equation}

\begin{equation} \label{eq:combination}
\rec{
    \text{x}=a_1 &:& \type{Ind} \\
    \text{y}=a_2 &:& \type{Ind} \\
    \text{cr}_1 &:& \text{above}(\text{x}, \text{y}) \\
    \text{cr}_2 &:& \text{right}(\text{y}, \text{x})
    }
\end{equation}

\gls{ttr} features an \textit{merge} operation ($\ttrmerge$), but a merge will not have the result desired here.
Since the same labels occur in both belief types, a merge would result in \textit{meet types}, as seen in \autoref{eq:merge}, in a way which is not useful for this purpose.
The meet type of two different singleton types, $\type{Ind}_{a_1} \wedge \type{Ind}_{a_2}$, can only be true if the two individuals are the same, $a_1 = a_2$.
The constraint in the `cr' field then says that some individual is above and to the right of itself, which is meaningless and certainly not what we are trying to obtain.

\begin{equation} \label{eq:merge}
T_1  \ttrmerge T_2 =
\rec{
    \text{x} &:& \type{Ind}_{a_1} \wedge \type{Ind}_{a_2} \\
    \text{y} &:& \type{Ind}_{a_2} \wedge \type{Ind}_{a_1} \\
    \text{cr} &:& \text{above}(\text{x}, \text{y}) \wedge \text{right}(\text{x}, \text{y})
    }
\end{equation}

\cite{CooperTypetheorylanguage2016} solves this by a method of nesting and flattening (notebook cell 17).
Each belief is added as the type of a new field `prev' in the next belief: $[\text{prev} : T_1] \ttrmerge T_2$ (\autoref{eq:combineprevnest}).
The result is then flattened to avoid the nesting (\autoref{eq:combineprev}).
The field labeled `x' in $T_1$ is now labeled `prev.x' and does not conflict with the field labeled `x' from $T_2$.
% Duplicates?

\begin{equation} \label{eq:combineprevnest}
\rec{
    \text{prev} &:& \rec{
        \text{x}=a_1 &:& \type{Ind} \\
	\text{y}=a_2 &:& \type{Ind} \\
        \text{cr} &:& \text{above}(\text{x}, \text{y}) \\
        } \\
    \text{x}=a_2 &:& \type{Ind} \\
    \text{y}=a_1 &:& \type{Ind} \\
    \text{cr} &:& \text{right}(\text{x}, \text{y})
    }
\end{equation}

\begin{equation} \label{eq:combineprev}
\rec{
    \text{prev.x}=a_1 &:& \type{Ind} \\
    \text{prev.y}=a_2 &:& \type{Ind} \\
    \text{prev.cr} &:& \text{above}(\text{prev.x}, \text{prev.y}) \\
    \text{x}=a_2 &:& \type{Ind} \\
    \text{y}=a_1 &:& \type{Ind} \\
    \text{cr} &:& \text{right}(\text{x}, \text{y})
    }
\end{equation}

Another method is used in this project for the purpose of computational speed (notebook cell 18).
In this method, each belief record type is relabeled to only have unique labels, and then merged.
An example result is shown in \autoref{eq:combineunconflict}.
Generating unique labels is an operation outside \gls{ttr}, making this method less purely \gls{ttr}-powered.

\begin{equation} \label{eq:combineunconflict}
\rec{
    \text{x}_1=a_1 &:& \type{Ind} \\
    \text{y}_1=a_2 &:& \type{Ind} \\
    \text{cr}_1 &:& \text{above}(\text{x}_1, \text{y}_1) \\
    \text{x}_2=a_2 &:& \type{Ind} \\
    \text{y}_2=a_1 &:& \type{Ind} \\
    \text{cr}_2 &:& \text{right}(\text{x}_2, \text{y}_2)
    }
\end{equation}

Both methods result in duplicate fields: there is no meaningful difference between the fields labeled `$\text{x}_1$' and `$\text{y}_2$' above, as both have the same singleton type.
Removing these duplicates (also \textit{deduplication}, or \textit{dedupe}) is necessary for the subtype check that will follow.
This process first involves finding which fields have the same type as another field.
Subsequently, simply removing duplicates is not an option, as there may be other fields that depend on the duplicate field.
These dependent fields must also be updated to use the remaining field.

The \texttt{combine} and \texttt{dedupe} functions are defined in \autoref{lst:combine} (notebook cells 7 and 18).

In \texttt{combine}, a list of record types are reduced to one type by unique relabeling and merging.
The \texttt{unique\_labels} function makes use of \texttt{gensym} in the PyTTR library, which generates new, consecutively numbered labels such as \texttt{loc\_4} (typeset here as $\text{loc}_4$).
A label containing an underscore (`\_') is assumed to already be uniquely numbered.
Thus, labels without undescores are relabeled to new, numbered labels.

Finally, the \texttt{dedupe} function removes any duplicated singleton and complex field types by relabeling all occurrences of each such field type with one of their labels.
For example, in $\rec{\text{x}=a_1 &:& \type{Ind} \\ \text{y}=a_1 &:& \type{Ind}}$, `y' is relabeled to `x'.
(Or possibly vice versa; the order of record type fields is unspecified.)
When all duplicates of some field type have been removed, recursion is used to avoid usage of old labels in the outer for-loop.

\begin{listing}
\begin{lstlisting}
from functools import reduce

def unique_labels(T):
    """Relabel a RecType so each field label is unique over all RecTypes."""
    rlb = ((l, gensym(l)) for l in T.labels() if '_' not in l)
    return rectype_relabels(T, dict(rlb))

def dedupe(T):
    """Make a copy of a record type without duplicated field values."""
    for l,v in T.fields():
        # Are there more fields with the same value?
        l2s = [l2 for l2,v2 in T.fields() if l2 != l
               # Dedupe singleton types and complex types.
               and (isinstance(v, SingletonType) or not is_basic_type(v))
               # Using show is error-prone, pyttr should have an equals method.
               and show(v) == show(v2)]
        if len(l2s):
            # Relabel all these fields to the same label,
			# overwriting until one remains.
            for l2 in l2s:
                T.Relabel(l2, l)
            # Dependent fields have changed, so start over.
            return dedupe(T)
    # No more duplicates.
    return T

def combine(Ts):
    """Combine a list of belief record types into one."""
    f = lambda a, b: a.merge(unique_labels(b))
    return dedupe(reduce(f, Ts, RecType()))
\end{lstlisting}
\caption{The \texttt{combine} and \texttt{dedupe} functions.}
\label{lst:combine}
\end{listing}



\subsection{Parsing language to \gls{ttr}}
\label{sec:parsing}
\glsreset{fol}

As mentioned in \autoref{sec:ttnlp}, pure \gls{ttr} solutions to natural language parsing have been developed but not implemented.
Such an implementation is sufficiently complex and outside the scope of this thesis.
Furthermore, the language domain is limited for the purpose of this thesis, and a wide-coverage parsing solution is more than what is necessary.
Therefore, instead of implementing natural language parsing in \gls{ttr}, this project uses
another standard method to parse natural language to \gls{fol}.
The \gls{fol} expression is subsequently \textit{translated} to \gls{ttr} in a new algorithm.

\subsubsection{Parsing to \gls{fol}}

Parsing is done using the NLTK library \citep{nltk}, which contains a semantically augmented \gls{cfg} framework just like the method introduced in \autoref{sec:compsem}.
It uses feature structures to associate each constituent with a \gls{fol} term possibly using lambda calculus.
A snippet of the grammar is given in \autoref{lst:grammar} (the full grammar is given in notebook cell 20).
The grammar can be used to generate the sample parse tree in \autoref{fig:tree}.
Above the word-tokenized sentence, every node in the tree represents a constituent.
Underneath the abbreviation, each constituent features first the expression given in the grammar specification (with some typographical modification), and second, the \gls{fol} term resulting from substitution and $\beta$-reduction.

\begin{listing}
\begin{lstlisting}
QS[SEM=<?np(?pp)>] -> 'is' 'there' NP[SEM=?np] PP[SEM=?pp]
QS[SEM=<?np(\P.true)>] -> 'is' 'there' NP[SEM=?np]

NP[SEM=<?det(?n)>] -> Det[SEM=?det] N[SEM=?n]
Det[SEM=<\P Q.exists x.(P(x) & Q(x))>] -> 'a' | 'an'

VP[SEM=?pp] -> 'is' PP[SEM=?pp]
PP[SEM=<\x.(?np(\y.?prep(x, y)))>] -> Prep[SEM=?prep] NP[SEM=?np]

Prep[SEM=<left>] -> 'to' 'the' 'left' 'of'

N[SEM=<dog>] -> 'dog'
N[SEM=<person>] -> 'person'
\end{lstlisting}
\caption{A snippet of the FCFG grammar.}
\label{lst:grammar}
\end{listing}

\begin{figure}[h]
\includegraphics[width=\textwidth]{tree}
\centering
\caption{Example syntactic-semantic parsing of an utterance into first-order logic.}
\label{fig:tree}
\end{figure}



\subsubsection{Translating \gls{fol} to \gls{ttr}}

The result of the \gls{cfg} parsing is a Python object that encodes the \gls{fol} expression.
A custom Python function \texttt{fol\_to\_pyttr}, given in \autoref{lst:foltopyttr} (notebook cell 20), traverses this object recursively and builds a PyTTR type.

\begin{itemize}
\item For an ``Exists'' expression, an $\type{Ind}$ field is added to the type.
\item For an ``Application'' expression, a ptype field is added, copying the predicate and variable names.
\item An ``And'' expression simply triggers recursion into each of the two terms.
\item The constant `true' is added to allow simple existential questions like ``Is there an aeroplane?''
\end{itemize}

A wrapper function \texttt{eng\_to\_pyttr} combines simple word tokenization, \gls{cfg} parsing and \gls{fol}-to-\gls{ttr} translation.

\begin{listing}
\begin{lstlisting}
import nltk
from nltk.sem.logic import ApplicationExpression, AndExpression, ExistsExpression, ConstantExpression

def fol_to_pyttr(expr, T=RecType()):
    """Turns a FOL object into a RecType."""
    # Existential quantifier -> Ind field.
    if isinstance(expr, ExistsExpression):
        T.addfield(str(expr.variable), Ind)
        return fol_to_pyttr(expr.term, T)
    
    # Application -> ptype, e.g. left(x, y)
    if isinstance(expr, ApplicationExpression):
        pred, args = expr.uncurry()
        # Create a PType function, e.g. lambda x:Ind . dog(x)
        fun = create_fun(str(pred), 'abcd'[:len(args)])
        T.addfield(gensym('c'), (fun, [str(a) for a in args]))
        return T
    
    # For and-expressions, interpret each term.
    if isinstance(expr, AndExpression):
        fol_to_pyttr(expr.first, T)
        fol_to_pyttr(expr.second, T)
        return T
    
    # A constant function in the "is there an X" rule trivially gives "true".
    if isinstance(expr, ConstantExpression) and str(expr.variable) == 'true':
        return T
    
    raise ValueError('Unknown expression: ' + str(type(expr)) + ' ' + str(expr))

def eng_to_pyttr(text):
    # Tokenize.
    sent = text.lower().strip('.?!').split()
    # NLTK-parse to syntax tree.
    trees = parser.parse(sent)
    # Extract semantic representation for the tree.
    sem = nltk.sem.root_semrep(list(trees)[0])
    # Interpret to TTR record type.
    T = fol_to_pyttr(sem, RecType())
    return T
\end{lstlisting}
\caption{Translation from \gls{fol} to \gls{ttr}.}
\label{lst:foltopyttr}
\end{listing}



\subsection{The relabel-subtype relation}
\label{sec:subtyperelabeling}

Perceptual mechanisms and the combination of belief types have produced a scene type $S$.
Separately, natural language parsing of a speaker utterance has provided a question type $Q$.
Now, in order to answer the question, we are interested in whether $S \sqsubseteq Q$.

However, the fact that \gls{ttr} record types are labeled prevents direct usage of the subtype relation.
Field labels in the scene type will generally not agree with those in the question type.
This prompts for a more advanced variant of subtype checking, allowing \textit{relabeling}.

% TODO Why relabel supertype Q and not subtype S?

\begin{definition}
A record type $S$ is a \textbf{relabel-subtype} of the record type $Q$, $S \subtrlb Q$, if there is a relabeling $\eta$ of $Q$ such that $S \sqsubseteq Q_\eta$.

%Such a relabeling $\eta$ is known as a \textbf{subtype relabeling} of $Q$.
% or rather supertype relabeling?
\end{definition}

The number of relabelings in one record type, to the labels of another, can be quite large:
If $S$ has 20 fields and $Q$ has five, then there are $\dfrac{20!}{(20-5)!} = 1\,860\,480$ relabelings of Q (the number of 5-permutations of 20).
It is practically impossible to perform all relabelings and check whether subtypeness holds.
An alternative algorithm is presented below for the purpose of this project, where fast computation is enabled by making a few assumptions about the input record types.



\subsubsection{Subtype relabeling algorithm}

This algorithm handles non-dependent (``basic'') and dependent fields separately.

First, when considering relabelings of $Q$, only the basic fields are included.
(In this project, those fields are associated with singleton types of either $\type{Ind}$ or $\type{Segment}$.)
This drastically limits the number of relabelings to try:
If $S$ has eight basic fields and $Q$ has two, there are only $\dfrac{8!}{(8-2)!} = 56$ relabelings.

Then, for each relabeling being tried, the remaining (dependent) fields are subtype-checked individually, in order to avoid more relabeling.
This means checking
$\text{dog}(\text{x}) \sqsubseteq \text{dog}(\text{x})$ (true) instead of
$\rec{\text{c}_1 &:& \text{dog}(\text{x})} \sqsubseteq \rec{\text{c}_2 &:& \text{dog}(\text{x})}$ (false).
If there is some field in $Q_\eta$ that does not have a subtype field in $S$, then subtypeness cannot hold, and the rest of the complex fields are skipped in favor of trying the next basic-field relabeling.

% TODO what is this in terms of big-O?

For an illustration, consider the following simple example.
A relabel-subtype check is being performed on the record types $S$ (\autoref{eq:strlbs}) and $Q$ (\autoref{eq:strlbq}).

\begin{equation}\label{eq:strlbs}
S = \rec{
    \text{x} &:& \type{Ind} \\
    \text{y} &:& \type{Ind} \\
    \text{z} &:& \type{Ind} \\
    \text{c} &:& \text{right}(\text{x}, \text{y}) \\
    \text{d} &:& \text{left}(\text{x}, \text{z})
    }
\end{equation}

\begin{equation}\label{eq:strlbq}
Q = \rec{
    \text{p} &:& \type{Ind} \\
    \text{q} &:& \type{Ind} \\
    \text{e} &:& \text{left}(\text{p}, \text{q})
    }
\end{equation}

\begin{enumerate}
\item The first basic-field relabeling to try is $\eta_1 = \{\langle \text{p}, \text{x}\rangle, \langle \text{q}, \text{y}\rangle\}$, yielding $Q_{\eta_1} = \rec{ \text{x} &:& \type{Ind} \\ \text{y} &:& \type{Ind} \\ \text{e} &:& \text{left}(\text{x}, \text{y}) }$.
%Now $Q_{\eta_1}.\text{x} \sqsubseteq S.\text{x}$ and $Q_{\eta_1}.\text{y} \sqsubseteq S.\text{y}$
\item However, neither $\text{right}(\text{x}, \text{y})$ or $\text{left}(\text{x}, \text{z})$, the dependent fields in $S$, is a subtype of $\text{left}(\text{x}, \text{y})$
\item The next relabeling to try is $\eta_2 = \{\langle \text{p}, \text{x}\rangle, \langle \text{q}, \text{z}\rangle\}$, yielding $Q_{\eta_2} = \rec{ \text{x} &:& \type{Ind} \\ \text{z} &:& \type{Ind} \\ \text{e} &:& \text{left}(\text{x}, \text{z}) }$.
Similar to before, $Q_{\eta_2}.\text{x} \sqsubseteq S.\text{x}$ and $Q_{\eta_2}.\text{z} \sqsubseteq S.\text{z}$
\item Now, $\text{left}(\text{x}, \text{z}) \sqsubseteq \text{left}(\text{x}, \text{z})$
\item Conclusively, $S \sqsubseteq Q_{\eta_2}$ and thus $S \subtrlb Q$
\end{enumerate}



\subsubsection{Restrictions of the algorithm}

As a prerequisite, any dependent fields must depend only on basic (non-dependent) fields.
For example, the algorithm will not correctly handle $\rec{
\text{x} &:& \type{Ind} \\
\text{c}_1 &:& \text{great}(\text{x}) \\
\text{c}_2 &:& \text{believe}(\text{x}, \text{c}_1)
}$.

The algorithm does not recurse into nested record types.
This restraint could be eliminated by using flattening, but it is not needed in this scope.

%The implementation assumes that there is only one basic type ($Ind$) in the record types (at the top level):
%when listing basic-field relabelings, it does not distinguish between different basic types.
%Should there be more than one basic field in the top level, the results are the same but the performance suffers because 



\subsubsection{Implementation}

A Python implementation is given in \autoref{lst:find_subtype_relabeling} (notebook cell 21).

%As a caveat, the implementation does not take into account the types of basic fields.
%It will attempt relabelings where, for instance, an $Ind$-typed field in $Q$ is relabeled to the label of a $Segment$-typed field in $S$.
%This will not lead to any false results in this project, because $Ind$ is the only basic type that will occur in $Q$.
%It does however affect performance negatively, as more relabelings are tried than is necessary.

\begin{listing}
\begin{lstlisting}
from itertools import permutations, combinations

def my_subtype_of(sub, sup):
    """Is T a subtype of U? Accept dependent rectype fields (= (fun, args) tuples) with simplistic equality test."""
    try:
        return sub.subtype_of(sup)
    except AttributeError:
        return isinstance(sub, tuple) and isinstance(sup, tuple) and show(sub) == show(sup)

def find_subtype_relabeling(S, Q):
    '''Could record type S be a sub type of record type Q if relabeling in Q is allowed?'''
    # For each relabeling of basic-type fields
    for sls in permutations(basic_fields(S), len(basic_fields(Q))):
        # Try the basic-fields relabeling of Q
        rlb_basic = dict(zip(basic_fields(Q), sls))
        Q2 = rectype_relabels(Q, rlb_basic)
        
        # For each Q field, find a S field that is a subtype
        rlb_dep = dict()
        for ql in nonbasic_fields(Q2):
            for sl in nonbasic_fields(S):
                # The new labels must be unique.
                if sl in rlb_dep.values(): continue
                if my_subtype_of(S.field(sl), Q2.field(ql)):
                    rlb_dep[ql] = sl
                    break
            if ql not in rlb_dep:
                break

        # Successful if all non-basic fields match.
        if len(rlb_dep) == len(nonbasic_fields(Q2)):
            return dict(**rlb_basic, **rlb_dep)
    return None
\end{lstlisting}
\caption{The \texttt{find\_subtype\_relabeling} function.}
\label{lst:find_subtype_relabeling}
\end{listing}



\subsection{Additions to PyTTR}

Some extensions to PyTTR, listed below, were necessary for the implementation to be possible.
%In order to utilize PyTTR in the application, a few TTR operations had to be added.
%Additionally, a few functions which were TTR-related, but not obviously operations, were added.
Of these, some were added directly to the PyTTR library, because simpler version of the operations of functions were already there.
Others were defined in the custom application; in these cases, a notebook cell reference is supplied in the list below.

\begin{description}
\item[Python-body functions] A \gls{ttr} function is modelled by the PyTTR \texttt{Fun} class, where the function body is made up by another PyTTR object.
Application of the function is implemented as substituting the argument in the body object.
Some operations here have required more advanced operations.
I created a \texttt{LambdaFun} subclass of \texttt{Fun} to allow any Python code as its body (notebook cell 8).
\item[Copying a record type] This facilitates the creation of new record types based on an existing one, without altering the original.
\item[Relabeling multiple fields] (notebook cell 4) PyTTR originally only contains a method for relabeling a single field.
\item[Relabel fix] When a relabeled field occurs in a sibling dependent field value, the dependent field value must be updated to use the new label.
	For instance, if `x' is relabeled to `y' in $\rec{\text{x} &:& \type{Ind} \\ \text{c} &:& \text{p}(\text{x})}$, then $\text{p}(\text{x})$ must be updated to $\text{p}(\text{y})$.
\item[A fix for LazyObject] LazyObject is a class in the PyTTR library used for making references between fields.
Prior to the fix, it could only be used for paths longer than one item, for instance $r.\text{x}$ but not $r$.
\item[Flatten for record types] The flatten operation was previously implemented for records but not for record types.
I added it to the record type class in order to implement \citeauthor{CooperTypetheorylanguage2016}'s merge-and-flatten method described in \autoref{sec:combine}.
%\item[Latex output fixes] These did not contribute to the implementation itself, but to the writing of this thesis.
\end{description}



\subsection{Demonstration}

With the purpose of testing the integrity of the model, and for the sake of illustration, the model has been run on a handful of images from the VQA dataset \citep{AgrawalVQAVisualQuestion2015} (notebook cell 26).
The results are presented in \autoref{tab:demo}.
%The purpose of these runs are not to assess accuracy or performance, but to confirm the integrity of the model or, in other words, see that it works.

Note that the accuracy of the answers returned by the model are not a priority in this project.
The performance is dependent on what external modules for classification are integrated.
This is discussed further in \autoref{sec:discussion}.

%Where the answer is incorrect, this is explained by different reasons.
%In 1.2, the car is classified as \textit{truck} and our model does not have any inference system for determining that if something is a truck then it is also a car.
%(The answer could alternatively be considered correct, as all persons seen are actually to the left of the car, from the perspective of the car itself.
%This would however be a pointless coincidence, as there is no support in this model for intrinsic spatial relations, as discussed in \autoref{sec:method-spatrel}.)
%In 2.1 and 4.1, some of the objects are not successfully detected by the object detection system.
%In 3.1, the simplistic account of spatial relations conflicts with that of our intuition.
%Sure enough, there is at least one snowboard whose center coordinates is higher on the $y$ axis than that of at least one person.

\begin{table}
\begin{tabular}{p{.5\textwidth}p{.5\textwidth}}
\def\arraystretch{1.5}

	\includegraphics[width=0.5\textwidth]{vqa1.jpg} &
	\includegraphics[width=0.5\textwidth]{vqa3.jpg} \\
	1.1 \ Is there an aeroplane?

	\qquad Yes (Correct)

	1.2 \ Is there a person to the right of a car?

	\qquad No (Incorrect?) &

	3.1 \ Is there a snowboard above a person?

	\qquad Yes (Incorrect)

	3.2 \ Is there a snowboard below a person?

	\qquad Yes (Correct) \\[1.5em]

	\includegraphics[width=0.5\textwidth]{vqa2.jpg} &
	\includegraphics[width=0.5\textwidth]{vqa4.jpg} \\

	2.1 \ Is there a tent?

	\qquad No (Incorrect)

	2.2 \ Is there a kite above a person?

	\qquad Yes (Correct) &

	4.1 \ Is there a giraffe below a tree?

	\qquad No (Incorrect)

\end{tabular}
\caption{Demonstration of model performance.}
\label{tab:demo}
\end{table}

