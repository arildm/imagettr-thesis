\glsresetall
\section{Introduction}
\label{sec:intro}

Having computers understand visual input is desirable in several areas.
A domestic assistant robot may use a camera to navigate and identify useful objects in a home.
Driver-less cars need to be able to read road signs and track other moving vehicles.
Web crawlers may extract information from images alongside text on the web.

This kind of understanding involves processing sensory (such as visual) input on a cognitive level.
Low-level image processing may include tasks such as prominent color extraction, edge detection and visual pattern recognition.
Higher-level processing, however, includes identifying objects, their properties and their relations to each other.
This information can then be used for language understanding, reasoning, prediction and other cognitive processes.
Making the connection between sensory input and cognitive categories is what concerns the field of \textit{perceptual semantics} \citep{PustejovskyPerceptualsemanticsconstruction1990}.

Humans use language to communicate information.
Thus it is useful to add linguistic capacities to a perceptual system.
With vision and language connected, a robot can talk about what it sees, and descriptions can be automatically generated for images found on the web.
Image caption generation is indeed a popular task for evaluating computer vision systems.
Another one is \textit{\gls{vqa}} \citep{AgrawalVQAVisualQuestion2015}, where the system is expected to generate answers to natural-language questions in the context of a given image.

The connection between different modes of information, such as vision and language, requires a model of semantic representation.
Formal models such as \gls{fol} have long been of choice, but recent developments have seen data-driven approaches excel in some cases.
Briefly put, the former kind tends to deliver deep structures of information in narrow domains, while the latter more easily covers wide domains, but with shallow information content \citep{Dobnik:2017ag}.
A recent contribution that combines several branches in formal systems is \textit{\gls{ttr}} \citep{CooperAustiniantruthattitudes2005,CooperTypetheorylanguage2016}.

\subsection{Contribution of this thesis}
\label{sec:contribution}

The main question explored in this thesis is the following: What are the advantages and problems faced when implementing a \gls{ttr} model of perception and language?

To qualify the question further, a number of requirements are taken into account.
The model shall build on past proposals for such models, mainly \cite{ttrspat} and \cite{lspc}.
It shall make extensive use of \gls{ttr}, and where it cannot, rely on either existing or new but simplistic models for self-contained subproblems.

Some limitations are also considered in order to narrow down the scope.
The setting for the model is a basic \gls{vqa} application, meaning it will be used to answer questions given with an image as context.
The language domain is restricted to polar (yes/no) questions.

%TODO Should I add a discussion on these requirements and limitations? Where?

In response to the requirements and limitations mentioned above, some subordinate questions emerge.

\begin{enumerate}
\item How well do employed tools do in this application, and where does the application require extending them?
\item In what extension can the model be covered by \gls{ttr} (and where does it need additional techniques)?
\item How well does the model perform in a \gls{vqa} application?
\item What advantages does such a model have against state of the art and other well-established approaches to:
    \begin{enumerate}
    \item \gls{vqa} solutions?
    \item other models of perception and language?
    \end{enumerate}
\end{enumerate}

In the thesis, a model is formulated and implemented, and the resulting implementation is evaluated in terms of the proposed questions.

%The purpose of this task is to use \gls{ttr} as a multi-modal knowledge representation system, providing formal transparency.

The theoretical background for this thesis is summarized in \autoref{sec:background}.
In \autoref{sec:method}, the strategies and techniques used for the implementation are described.
The implementation is then presented in \autoref{sec:results}.
In \autoref{sec:discussion}, the results are discussed in relation to the questions above.
Finally, some conclusions are made in \autoref{sec:conclusions}.
