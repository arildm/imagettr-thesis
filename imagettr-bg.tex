\glsresetall
\section{Background}
\label{sec:background}

This section will highlight some important pieces of the history of past research in relevant fields.

\subsection{Computational semantics}

Semantics is the study of meaning.
Computational semantics is concerned with how to represent meaning digitally, and then use it to perform semantic parsing, inference and other tasks \citep{BlackburnComputationalsemantics2003}.
A well-established and largely capable formalism for expressing and operating on propositions is \gls{fol}.

\cite{MontagueFormalPhilosophySelected1974}
[SD Computational Semantics]

[modern methodologies]
With recent advancements in computer science, ambitious computational-semantic theories are now in abundance.
As a competitor to formal systems, statistical methods have emerged which do well in various tasks within semantics.
They utilize the performance of modern computers and leverage the large amounts of data that are available as a product of our largely digitalized society.


[formal systems]
If statistical models of semantics do well in [empirical/data-driven/practical] tasks, formal theories of semantics [do what?]
\cite{BlackburnComputationalsemantics2003}:
FOPC for the win, but ``other approaches are both possible and interesting''.

\cite{Dobnik:2017ag}





\subsection{Perceptual semantics}
% ... in general, and spatial relations in particular

An artificial device perceiving its environment will make internal, symbolic representations of the real world outside \citep{PustejovskyPerceptualsemanticsconstruction1990}.
According to Frege, these symbols will have \textit{sense} as well as \textit{reference}.
A symbol with the sense ``the dog'' may have a certain dog in the environment as reference.
Later, the same symbol and sense may refer to another dog.

\cite{Garnhamunifiedtheorymeaning1989} explores terms of spatial relations (``left'', ``right'', ``above'', etc.).
They claim that there are three types of meanings for each term: basic, deictic and intrinsic.
The vertical (or gravitational) axis is special, so the terms ``above'' and ``below'' work differently than expected when the related object is, for example, upside down.
\cite{Leveltperceptuallimitationstalking1984} and \citeauthor{Garnhamunifiedtheorymeaning1989} present different explanations to this.

\cite{LoganComputationalAnalysisApprehension1996} account for the state of 
Basic–deictic(–intrinsic) relations.
Perceptual–conceptual representation.
"Computational theory of apprehension": spatial indexing -> reference frame -> ... Instead, we move into the conceptual level, both in perception and language, and evaluate validity from there.
(Drawbacks?)
They present "evidence" for their theory, does that evidence contradict the present approach?

Target/Landmark, Figure/Ground, Referent/Relatum, Located object (LO)/Reference object (REFO)

Terms of spatial relations (\textit{behind}, \textit{to the left of}, etc.) have three types of meanings \citep{Garnhamunifiedtheorymeaning1989}: basic, deictic and intrinsical.
The deictic and intrinsical meanings hold for relations between two objects.
The deictic meaning is relative to the coordinate frame of the speaker, while the intrinsical is relative to that of the reference object.
The basic meaning, introduced by \cite{Garnhamunifiedtheorymeaning1989}, is also relative to the speaker, but holds for a single object only.
[and? (it is basic in the way that... what?) example?]

\cite{RegierGroundingspatiallanguage2001a}:
Four models. AVS.
Many experiments.
Spatial term ratings influenced by: proximal \& center-of-mass orientations, grazing line, distance.

\cite{CoventryClassificationExtrageometricInfluences2004}:
Extra-geometric constraints on the meaning of spatial relational terms.
Especially functional.
Functional geometric framework.
[functional aspect, Coventry?]

\cite{HarnadSymbolGroundingProblem1990}:
Can a computer really ``understand'' concepts, that is, will it operate on grounded symbols or just the (arbitrary) symbols themselves?
Turing test.

"say something about recognitising objects as well and grounding in general. So I would add discussions of Roy" SD



\cite{SteelsSymbolGroundingProblem2007}:
Peirce: object, symbol, concept. Grounded with method.
Searle and other claim that the Symbol grounding problem is insolvable.
Steels concludes that it is solved.
Using experiments where a number of agents participate in a language game where they make up random words for preset concepts and manage to ``agree'' on which words to use for which concepts.

...



\subsection{Type theory in natural language processing}
\label{ssec:ttnlp}

Type theory is a logic system developed by \cite{WhiteheadPrincipiamathematica1910}, \cite{church40}, \cite{martinlof84} among others \citep{CoquandTypeTheory2015}.
%Several different type theories have been created, of which Church's \textit{simply typed \textlambda-calculus} \cite{church40} and Martin-Löf's \textit{intuitionistic type theory} \citep{martinlof84} are some prominent examples.
In \cite{RantaTypetheoreticalGrammar1995}, it is used as a method of syntactic parsing.
\cite{KohlhaseTypeTheoreticSemanticslDRT1996} combines type theory with discourse representation theory (DRT).

\cite{CooperRecordsRecordTypes2005} combines several theories from logic, semantics and linguistics in a single type-theoretic framework known as \acrfull{ttr}.
It has been employed to model natural language in the context of
syntax \citep{CooperRecordsRecordTypes2005,RobinCooperAustiniantruthattitudes2005, CooperTypetheorysemantics2012, CooperTypetheorylanguage2016},
dialogue \citep{Larssonformalviewcorrective2009, CooperTypetheorylanguage2016, LarssonDialoguesHaveContent2011},
situated agents \citep{DobnikModellinglanguageaction2012, ttrspat,lspc} and
spoken language \citep{CooperTypetheorylanguage2016}.



%\subsubsection{Overview of \gls{ttr} syntax}

%[brief summary of TTR syntax?]



\subsection{[Perceptual semantics in] \acrfull{ttr}}


\cite{DobnikModellinglanguageaction2012} advocates the use of \gls{ttr} for classification of spatial relations.

\cite{ttrspat} model a situated agent 
 focusing especially on spatial relations.

\cite{lspc} model the point space perception of a mobile robot equipped with a rangefinder.
 that would move around and use laser range scanner or similar to collect points in space, group them into objects and detect spatial relations between them.
\Gls{ttr} is mainly used to model the transition from the perceptual to the cognitive domain as well as 
 throughout the model, accounting for perception and cognition.


\cite{LarssonFormalsemanticsperceptual2015}



\subsection{Programming \acrshort{ttr} in Python: PyTTR}

\cite{pyttr} is a Python implementation of \gls{ttr}.
It supports modeling records, record types, ptypes, functions and other TTR objects.
Additionally, it allows operations such as judgement, type checking and subtype checking.
As a Python library it also enables other features and peripheral procedures to be written in Python.

[the advantage of implementing a theoretical model]
PyTTR, itself being an implementation of TTR, allows, in turn, the implementation of models and theories that build on TTR.
By implementing a theoretical model as a computer program, it can ``come alive'' and be tested on real problems and data.
Another motivation for implementation is to compete with existing, less theoretically strong techniques to solve a given task, but it is possibly secondary to the former reason.

%[What has been written in PyTTR so far? nu, animat]



\subsection{Image recognition and object detection}

In image recognition, objects are detected and classified in visual data.
A wide range of models have been developed to solve this task.
Some focus only on the detection of objects \citep{BlaschkoLearningLocalizeObjects2008}, some only on classification \citep[ResNet,][]{HeDeepResidualLearning2015}, and others attempt to solve the full problem in an integrated fashion \citep{RedmonYouOnlyLook2015,HeMaskRCNN2017}.

Some models include a feature extraction stage, where the image is converted to .
In SIFT, keypoints are extracted at significant locations of an image, so that a group of keys can be compared to a group of keys in a database for an object, in order to do classification.

Convolutional neural networks are a commonly applied technique \citep{HeDeepResidualLearning2015} [more citations?].
Color image data is highly dimensional: it is typically represented digitally as a 2D matrix of pixels, where each pixel itself specifies a quantity of each of three basic colors.
Convolutional layers reduces the dimensionality so that a single (one-dimensional) vector can encode an image.
The full image is often first divided into same-size overlapping segments, thus capturing locational aspects of the data.

%Among the most recent contributions to computer vision, Facebook's \textit{Detectron} \citep{Detectron2018} features outlining of identified objects and classification with impressive accuracy.




\subsection{\Acrfull{vqa}}

\cite{AgrawalVQAVisualQuestion2015} suggest \acrfull{vqa} as a [complete] challenge in AI-completeness.
``A VQA system takes as input an image and a free-form, open-ended, natural-language question about the image and produces a natural-language answer as the output''.
The initiative includes a dataset and a series of annual competitions since 2016.

\cite{AndreasLearningComposeNeural2016}

\cite{SchlangenResolvingReferencesObjects2015}

[example questions/answers]