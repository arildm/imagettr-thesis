\glsresetall
\section{Background}
\label{sec:background}

This section will highlight some important pieces of the history of past research in relevant fields.

\subsection{Computational semantics}

Semantics is the study of meaning.
Computational semantics is concerned with how to represent meaning digitally, and then use it to perform semantic parsing, inference and other tasks \citep{BlackburnComputationalsemantics2003}.
A well-established and largely capable formalism for expressing and operating on propositions is \gls{fol}.
\cite{MontagueFormalPhilosophySelected1974} used \gls{fol} with syntactic parsing for semantic parsing.
Thus, a natural-language utterance can be translated to a logical representation.

With recent advancements in computer science, ambitious computational-semantic theories are now in abundance.
As a competitor to formal systems, statistical methods have emerged which do well in various tasks within semantics.
They utilize the performance of modern computers and leverage the large amounts of data that are available as a product of our largely digitalized society.
Data-driven approaches are easily adapted for wide coverage (assuming enough data is available) but they often produce shallow knowledge.
Formal approaches, on the other hand, require more or less precisely crafted rules and formulations, which is time-consuming, but it typically enables the result to be more structured and comprehensive \citep{Dobnik:2017ag}.

\cite{BlackburnComputationalsemantics2003} claimed (at that time) that \gls{fol} is an adequate semantic representation in a majority of cases, but ``other approaches are both possible and interesting''.

\cite{SearleMindsbrainsprograms1980} disputes whether a computer really can \textit{understand} concepts, that is, whether it will be able operate on grounded symbols or just the (arbitrary) symbols themselves.
\cite{HarnadSymbolGroundingProblem1990} names this the \textit{symbol grounding problem}.
\cite{SteelsSymbolGroundingProblem2007} describes experiments where a number of agents participate in a language game, where they make up random words for preset concepts and manage to ``agree'' on which words to use for which concepts.
With the success in these experiments, \citeauthor{SteelsSymbolGroundingProblem2007} concludes that the symbol grounding problem is solved.



\subsection{Perceptual semantics}
% ... in general, and spatial relations in particular

An artificial device perceiving its environment will make internal, symbolic representations of the real world outside \citep{PustejovskyPerceptualsemanticsconstruction1990}.
According to \cite{FregeUberSinnUnd1892}, these symbols will have \textit{sense} as well as \textit{reference}.
A symbol with the sense ``the dog'' may have a certain dog in the environment as reference.
Later, the same symbol and sense may refer to another dog.

By using terms of spatial relations (``left'', ``right'', ``above'', etc.), the location of one object is specified in terms of the location and orientation of another.
Different terminology have been used to refer to the two roles, but we will use \textit{located object} and \textit{reference object} \citep{DobnikModellinglanguageaction2012}.

\cite{Garnhamunifiedtheorymeaning1989} explores terms of spatial relations and claims that there are three types of meanings for each term: basic, deictic and intrinsic.
The deictic and intrinsical meanings hold for relations between two objects.
The deictic meaning is relative to the coordinate frame of the speaker, while the intrinsical is relative to that of the reference object.
The basic meaning, introduced by \citeauthor{Garnhamunifiedtheorymeaning1989}, is also relative to the speaker, but holds for a single object only.

%The vertical (or gravitational) axis is special, so the terms ``above'' and ``below'' work differently than expected when the related object is, for example, upside down.
%\citeauthor{Garnhamunifiedtheorymeaning1989} uses a rule known as the \textit{framework vertical constraint} to explain this.
%It says that ``above'' and ``below'' must be understood in the 

\cite{LoganComputationalAnalysisApprehension1996} propose \textit{spatial templates} for the classification of spatial relations.
A spatial template is a field of acceptability ratings for a certain spatial relation term.
The center of the field is the location occupied by the reference object and each rating denotes the acceptability of using the term if the located object is at the location of that rating.
The ratings in spatial templates are collected through experiments.

\cite{RegierGroundingspatiallanguage2001a} instead propose a computational classification model known as \textit{attentional vector-sum (AVS)}.
The model considers distance between objects and the fact that they can have different shapes (especially elongated in some direction).
This model is compared to three simpler alternatives in seven experiments, and AVS is found to perform best.

\cite{CoventryInterplayGeometryFunction2001} explores extra-geometric constraints on the meaning of spatial relational terms, especially functional ones.
The functional relation between objects is significant for the acceptability of terms of spatial relations.
For example, an umbrella may be well said to be \textit{above} a man, but less clearly \textit{over} him, if it does not protect him from rain falling sideways in hard wind \citep{CoventryInterplayGeometryFunction2001}.

%"say something about recognitising objects as well and grounding in general. So I would add discussions of Roy" SD



\subsection{Type theory in natural language processing}
\label{ssec:ttnlp}

Type theory is a logic system developed by \cite{WhiteheadPrincipiamathematica1910}, \cite{church40}, \cite{martinlof84} among others \citep{CoquandTypeTheory2015}.
%Several different type theories have been created, of which Church's \textit{simply typed \textlambda-calculus} \cite{church40} and Martin-LÃ¶f's \textit{intuitionistic type theory} \citep{martinlof84} are some prominent examples.
In \cite{RantaTypetheoreticalGrammar1995}, it is used as a method of syntactic parsing.
\cite{KohlhaseTypeTheoreticSemanticslDRT1996} combines type theory with discourse representation theory (DRT).

%[a hint of what tt provides]

\cite{CooperRecordsRecordTypes2005} combines several theories from logic, semantics and linguistics in a single type-theoretic framework known as \acrfull{ttr}.
It has been employed to model natural language in the context of
syntax \citep{CooperAustiniantruthattitudes2005, CooperRecordsRecordTypes2005, CooperTypetheorysemantics2012, CooperTypetheorylanguage2016},
dialogue \citep{Larssonformalviewcorrective2009, LarssonDialoguesHaveContent2011, CooperTypetheorylanguage2016},
situated agents \citep{DobnikModellinglanguageaction2012, ttrspat,lspc} and
spoken language \citep{CooperTypetheorylanguage2016}.



%\subsubsection{Overview of \gls{ttr} syntax}

%[brief summary of TTR syntax?]



\subsection{Perceptual semantics in \acrfull{ttr}}


\cite{DobnikModellinglanguageaction2012} presents how \gls{ttr} can be used to model a situated conversational agent.
The agent moves around in a point-space world.
Objects, detected as sub point-spaces are recognized, as are (geometric and extra-geometric) spatial relations between them.
The work is followed up by \cite{ttrspat} and \cite{lspc}, which model similar situated agents.

%\cite{LarssonFormalsemanticsperceptual2015}



\subsection{Programming \acrshort{ttr} in Python: PyTTR}

\cite{pyttr} provides a Python implementation of \gls{ttr} known as PyTTR.
It supports the modeling of \gls{ttr} types and operations such as judgement and type checking.
As a Python library it also enables other features and peripheral procedures to be written in Python.

PyTTR allows, in turn, the implementation of \gls{ttr} models.
By implementing a theoretical model as a computer program, it can ``come alive'' and be tested on real problems and data.
When implemented, the model can be evaluated and compared in practical settings it to other models.

%[What has been written in PyTTR so far? nu, animat]



\subsection{Image recognition and object detection}

In image recognition, visual data is analyzed in order to detect and classify objects.
A wide range of models have been developed to solve this task.
Some focus only on the detection of objects \citep{BlaschkoLearningLocalizeObjects2008}, some only on classification \citep[ResNet,][]{HeDeepResidualLearning2015}, and others attempt to solve the full problem in an integrated fashion \citep{RedmonYouOnlyLook2015,HeMaskRCNN2017}.

There are different strategies for encoding the image into features.
For one, SIFT is a technique where significant locations of an image are used to extract \textit{keypoints} \citep{LoweObjectrecognitionlocal1999}.
Classification can then be performed by comparing the keypoints of a target image to those in a database.

With \textit{convolutional neural networks}, however, the need for prior feature extraction is generally eliminated \citep{HeDeepResidualLearning2015, HeMaskRCNN2017}.
Color image data is highly dimensional: it is typically represented digitally as a 2D matrix of pixels, where each pixel itself specifies a quantity of each of three basic colors.
Convolutional layers reduce the dimensionality so that an image can be encoded in a single (one-dimensional) vector.
The full image is often first divided into same-size overlapping segments, thus capturing locational aspects of the data.



\subsection{\Acrfull{vqa}}

\cite{AgrawalVQAVisualQuestion2015} suggest \gls{vqa} as a challenge for multi-modal semantic systems.
A \gls{vqa} system is presented an image and a natural-language question about the image, and is expected to produce a natural-language answer.
The initiative includes datasets and a series of annual competitions since 2016.

A neural-network approach to question answering tasks in general is proposed by \cite{AndreasLearningComposeNeural2016}, where multiple neural-network modules are assembled like constituents in a syntax tree.
For example, for the \gls{vqa} question \textit{What color is the bird?}, a network that detects objects of a given class is connected to one which classifies the color at the indicated location.
The method of assembly is trained jointly with the module networks.

%\cite{SchlangenResolvingReferencesObjects2015}

%[example questions/answers]
