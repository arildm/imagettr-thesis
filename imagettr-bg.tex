\glsresetall
\section{Background}
\label{sec:background}

This section will highlight some important pieces of the history of past research in relevant fields.

\subsection{Computational semantics}

Semantics is the study of meaning.
Computational semantics is concerned with how to represent meaning digitally, and then use it to perform semantic parsing, inference and other tasks \citep{BlackburnComputationalsemantics2003}.
A well-established and largely capable formalism for expressing and operating on propositions is \gls{fol}.

\cite{MontagueFormalPhilosophySelected1974}
[SD Computational Semantics]

[modern methodologies]
With recent advancements in computer science, ambitious computational-semantic theories are now in abundance.
As a competitor to formal systems, statistical methods have emerged which do well in various tasks within semantics.
They utilize the performance of modern computers and leverage the large amounts of data that are available as a product of our largely digitalized society.


[formal systems]
If statistical models of semantics do well in [empirical/data-driven/practical] tasks, formal theories of semantics [do what?]
\cite{BlackburnComputationalsemantics2003}:
FOPC for the win, but ``other approaches are both possible and interesting''.

\cite{Dobnik:2017ag}





\subsection{Perceptual semantics}
% ... in general, and spatial relations in particular

An artificial device perceiving its environment will make internal, symbolic representations of the real world outside \citep{PustejovskyPerceptualsemanticsconstruction1990}.
According to Frege, these symbols will have \textit{sense} as well as \textit{reference}.
A symbol with the sense ``the dog'' may have a certain dog in the environment as reference.
Later, the same symbol and sense may refer to another dog.

\cite{Garnhamunifiedtheorymeaning1989} explores terms of spatial relations (``left'', ``right'', ``above'', etc.).
They claim that there are three types of meanings for each term: basic, deictic and intrinsic.
The vertical (or gravitational) axis is special, so the terms ``above'' and ``below'' work differently than expected when the related object is, for example, upside down.
\cite{Leveltperceptuallimitationstalking1984} and \citeauthor{Garnhamunifiedtheorymeaning1989} present different explanations to this.

\cite{LoganComputationalAnalysisApprehension1996} account for the state of 
Basic–deictic(–intrinsic) relations.
Perceptual–conceptual representation.
"Computational theory of apprehension": spatial indexing -> reference frame -> ... Instead, we move into the conceptual level, both in perception and language, and evaluate validity from there.
(Drawbacks?)
They present "evidence" for their theory, does that evidence contradict the present approach?

Target/Landmark, Figure/Ground, Referent/Relatum, Located object (LO)/Reference object (REFO)

Terms of spatial relations (\textit{behind}, \textit{to the left of}, etc.) have three types of meanings \citep{Garnhamunifiedtheorymeaning1989}: basic, deictic and intrinsical.
The deictic and intrinsical meanings hold for relations between two objects.
The deictic meaning is relative to the coordinate frame of the speaker, while the intrinsical is relative to that of the reference object.
The basic meaning, introduced by \cite{Garnhamunifiedtheorymeaning1989}, is also relative to the speaker, but holds for a single object only.
[and? (it is basic in the way that... what?) example?]

\cite{RegierGroundingspatiallanguage2001a}:
Four models. AVS.
Many experiments.
Spatial term ratings influenced by: proximal \& center-of-mass orientations, grazing line, distance.

\cite{CoventryClassificationExtrageometricInfluences2004}:
Extra-geometric constraints on the meaning of spatial relational terms.
Especially functional.
Functional geometric framework.
[functional aspect, Coventry?]

\cite{HarnadSymbolGroundingProblem1990}:
Can a computer really ``understand'' concepts, that is, will it operate on grounded symbols or just the (arbitrary) symbols themselves?
Turing test.

"say something about recognitising objects as well and grounding in general. So I would add discussions of Roy" SD



\cite{SteelsSymbolGroundingProblem2007}:
Peirce: object, symbol, concept. Grounded with method.
Searle and other claim that the Symbol grounding problem is insolvable.
Steels concludes that it is solved.
Using experiments where a number of agents participate in a language game where they make up random words for preset concepts and manage to ``agree'' on which words to use for which concepts.

...



\subsection{Type theory in natural language processing}
\label{ssec:ttnlp}

Type theory is a logic system developed by \cite{WhiteheadPrincipiamathematica1910}, \cite{church40}, \cite{martinlof84} among others \citep{CoquandTypeTheory2015}.
%Several different type theories have been created, of which Church's \textit{simply typed \textlambda-calculus} \cite{church40} and Martin-Löf's \textit{intuitionistic type theory} \citep{martinlof84} are some prominent examples.
In \cite{RantaTypetheoreticalGrammar1995}, it is used as a method of syntactic parsing.
\cite{KohlhaseTypeTheoreticSemanticslDRT1996} combines type theory with discourse representation theory (DRT).

[a hint of what tt provides]

\cite{CooperRecordsRecordTypes2005} combines several theories from logic, semantics and linguistics in a single type-theoretic framework known as \acrfull{ttr}.
It has been employed to model natural language in the context of
syntax \citep{CooperRecordsRecordTypes2005,RobinCooperAustiniantruthattitudes2005, CooperTypetheorysemantics2012, CooperTypetheorylanguage2016},
dialogue \citep{Larssonformalviewcorrective2009, CooperTypetheorylanguage2016, LarssonDialoguesHaveContent2011},
situated agents \citep{DobnikModellinglanguageaction2012, ttrspat,lspc} and
spoken language \citep{CooperTypetheorylanguage2016}.



%\subsubsection{Overview of \gls{ttr} syntax}

%[brief summary of TTR syntax?]



\subsection{[Perceptual semantics in] \acrfull{ttr}}


\cite{DobnikModellinglanguageaction2012} advocates the use of \gls{ttr} for classification of spatial relations.

\cite{ttrspat} model a situated agent 
 focusing especially on spatial relations.

\cite{lspc} model the point space perception of a mobile robot equipped with a rangefinder.
 that would move around and use laser range scanner or similar to collect points in space, group them into objects and detect spatial relations between them.
\Gls{ttr} is mainly used to model the transition from the perceptual to the cognitive domain as well as 
 throughout the model, accounting for perception and cognition.

\cite{LarssonFormalsemanticsperceptual2015}



\subsection{Programming \acrshort{ttr} in Python: PyTTR}

\cite{pyttr} provides a Python implementation of \gls{ttr}, known as PyTTR.
It supports the modeling of \gls{ttr} types and operations such as judgement and type checking.
As a Python library it also enables other features and peripheral procedures to be written in Python.

PyTTR allows, in turn, the implementation of \gls{ttr} models.
By implementing a theoretical model as a computer program, it can ``come alive'' and be tested on real problems and data.
When implemented, the model can be evaluated and compared in practical settings it to other models.

%[What has been written in PyTTR so far? nu, animat]



\subsection{Image recognition and object detection}

In image recognition, visual data is analyzed in order to detect and classify objects.
A wide range of models have been developed to solve this task.
Some focus only on the detection of objects \citep{BlaschkoLearningLocalizeObjects2008}, some only on classification \citep[ResNet,][]{HeDeepResidualLearning2015}, and others attempt to solve the full problem in an integrated fashion \citep{RedmonYouOnlyLook2015,HeMaskRCNN2017}.

There are different strategies for encoding the image into features.
For one, SIFT is a technique where significant locations of an image are used to extract \textit{keypoints} \citep{LoweObjectrecognitionlocal1999}.
Classification can then be performed by comparing the keypoints of a target image to those in a database.

With \textit{convolutional neural networks}, however, the need for prior feature extraction is generally eliminated \citep{HeDeepResidualLearning2015, HeMaskRCNN2017}.
Color image data is highly dimensional: it is typically represented digitally as a 2D matrix of pixels, where each pixel itself specifies a quantity of each of three basic colors.
Convolutional layers reduce the dimensionality so that an image can be encoded in a single (one-dimensional) vector.
The full image is often first divided into same-size overlapping segments, thus capturing locational aspects of the data.



\subsection{\Acrfull{vqa}}

\cite{AgrawalVQAVisualQuestion2015} suggest \acrfull{vqa} as a challenge for multi-modal semantic systems.
A \gls{vqa} system is presented an image and a natural-language question about the image, and is expected to produce a natural-language answer.
The initiative includes datasets and a series of annual competitions since 2016.

A neural-network approach to question answering tasks in general is proposed by \cite{AndreasLearningComposeNeural2016}, where multiple neural-network modules are assembled like constituents in a syntax tree.
For example, for the \gls{vqa} question \textit{What color is the bird?}, a network that detects objects of a given class is connected to one which classifies the color at the indicated location.
The method of assembly is trained jointly with the module networks.

%\cite{SchlangenResolvingReferencesObjects2015}

%[example questions/answers]