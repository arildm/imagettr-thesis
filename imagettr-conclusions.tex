\renewcommand{\sectionautorefname}{Section}
\let\subsectionautorefname\sectionautorefname
\let\subsubsectionautorefname\sectionautorefname
\glsresetall
\section{Conclusions}
\label{sec:conclusions}

Within this project, the foundations of \gls{vqa} have been implemented in \gls{ttr}.
The result is an executable application powered by PyTTR.

The formal-semantic framework behind the application provides transparency and reversibility, and enables relatively simple implementation of operations (such as verifying a proposition).
\Gls{ttr} is the single framework that serves to operate all parts of the pipeline: perception, language and grounding.

The model is one of the few applications of the recently developed PyTTR library, which allows \gls{ttr} to be used in executable programs.
Extensions to PyTTR were made where needed.



\subsection{Future work}

Spatial classification and language parsing were achieved using minimal and simplistic implementations.
Substituting them with sophisticated systems would make for wider question coverage and higher question answering scores.
For instance, \cite{LoganComputationalAnalysisApprehension1996} proposes spatial templates, regions of acceptability and compound relations (like ``above to the right of'').

As discussed in \autoref{sec:method-spatrel}, the present treatment of spatial relations excludes the assignment of the frame of reference, as well as functional aspects, in favor of model simplicity and easy implementation.
Both features are treated in terms of \gls{ttr} by \cite{ttrspat}.
The former requires a notion of the orientation of reference objects.
Assuming an object classifier with this capability were available, implementing intrinsical spatial relations would not be a large step from the present model.
Such a classifier might detect that a car is facing left in the image;
an object to the right in the image could then be classified as being ``behind'' the car.
Support for the functional aspect of spatial relations requires two things.
Firstly, classifiers for functional relations (such as $\text{protects}(o_3\text{.a}, o_1\text{.a}, o_2\text{.a})$ in \cite{ttrspat}, for an umbrella protecting a man from rain).
% TODO Be more clear below?
Secondly, prediction from a set of functional relations to spatial classifiers that are sensitive to those functional relations.
The second is needed to activate the appropriate spatial relation term depending on which functional relations are true according to the classifiers in the first.
That is, if the relation between the umbrella and the man is classified as ``protects'', then the spatial classifier selected for ``over'' should be one that includes this condition.

Extending the language domain should be an interesting topic for further research.
Keeping within the problem domain of geometric spatial relations, allowing other question types than polar questions is one direction to explore.
\citet[p. 156]{DobnikTeachingmobilerobots2009} lists four basic question types:
``Where is the chair?'',
``Is the table to the left of the chair?'' (this is the focus of this project),
``What is to the left of the chair?'' and
``What is the chair to the left of?''
Another is to widen the problem domain and add more properties and relations than a primary object class (``car'') and spatial relations.
For instance, attribute classifiers could recognise color, size, facial expressions and positions, in order to authorise questions such as ``Is the girl sitting down?'' and ``Where is the red flower?''.
Action event classifiers could identify actions such as ``riding'' and ``talking to''.

The use of formal frameworks for question-answering tasks especially invites techniques for inference.
Consider an image of a person wearing glasses, and the question ``Does this person have 20/20 vision?''
It is reasonable to assume that a person is wearing glasses because they do not have perfect eyesight, to which ``20/20 vision'' is synonymous.
Inference could help to achieve the synonymity as well as the relationship between eyesight and wearing glasses.

%(b) left for future work in terms of (1) semantic representations of grounded language in TTR; (ii) their implementation in pyTTR; (iii) in the domain of visual question answering? 

%Classification after Q.
