\renewcommand{\sectionautorefname}{Section}
\let\subsectionautorefname\sectionautorefname
\let\subsubsectionautorefname\sectionautorefname
\glsresetall
\section{Conclusions}
\label{sec:conclusions}

Within this project, the foundations of \gls{vqa} have been implemented in \gls{ttr}.
The result is an executable application powered by PyTTR.



\subsection{Suitability}

This project has shown that \gls{ttr} can indeed be used to connect existing vision and language systems.
It enables a detailed model of multi-modal perception and semantics.
\Gls{ttr} is the single framework that serves to operate all parts of the pipeline: perception, language and grounding.

This is one of the few applications of the recently developed PyTTR library, which has enabled executing this model on actual data.
Extensions to PyTTR were made where needed.



\subsection{Benefits}

The formal-semantic framework behind the application provides transparency and reversibility.
This can be contrasted to neural-network-based models, where the path from input to results is encoded in impermable statistical data.
The framework also enables relatively simple implementation of operations (such as verifying a proposition).



\subsection{Can it tell us something about semantics?}

The problem of answering polar questions has been modeled as a subtype check between two situation types: a grounded scene type and a hypothetical question type.
This is different than the commonly established modeling of questions as sets of propositions \citep{HamblinQuestionsMontagueEnglish1973}.
The question could be cast into a set as $\{T \mathrel{|} T \subtrlb Q\}$, but it still relies on the subtype check.



\subsection{Future work}
\label{sec:futurework}

The agent structure is a rather simplistic model, tailored for the use case at hand.
It accepts as input an image followed by a number of questions.
There is no semantic connection between the current image and question, other than the sequence in which they are input.
There is also nothing like a dialogue system;
the background to any answer from the agent is the latest image and the latest question only.
Changing these things could be important for further some extensions.

Spatial classification and language parsing were achieved using minimal and simplistic implementations.
Substituting them with sophisticated systems would make for wider question coverage and higher question answering scores.
For instance, \cite{LoganComputationalAnalysisApprehension1996} proposes spatial templates, regions of acceptability and compound relations (like ``above to the right of'').

As discussed in \autoref{sec:method-spatrel}, the present treatment of spatial relations excludes the assignment of the frame of reference, as well as functional aspects, in favor of model simplicity and easy implementation.
Both features are treated in terms of \gls{ttr} by \cite{ttrspat}.
The former requires a notion of the orientation of reference objects.
Assuming an object classifier with this capability were available, implementing intrinsic spatial relations would not be a large step from the present model.
Such a classifier might detect that a car is facing left in the image;
an object to the right in the image could then be classified as being ``behind'' the car.
Support for the functional aspect of spatial relations requires two things.
Firstly, classifiers for functional relations (such as $\text{protects}(o_3\text{.a}, o_1\text{.a}, o_2\text{.a})$ in \cite{ttrspat}, for an umbrella protecting a man from rain).
% TODO Be more clear below?
Secondly, prediction from a set of functional relations to spatial classifiers that are sensitive to those functional relations.
The second is needed to activate the appropriate spatial relation term depending on which functional relations are true according to the classifiers in the first.
That is, if the relation between the umbrella and the man is classified as ``protects'', then the spatial classifier selected for ``over'' should be one that includes this condition.

Extending the language domain should be an interesting topic for further research.
Keeping within the problem domain of geometric spatial relations, allowing other question types than polar questions is one direction to explore.
\citet[p. 156]{DobnikTeachingmobilerobots2009} lists four basic question types:
``Where is the chair?'',
``Is the table to the left of the chair?'' (this is the focus of this project),
``What is to the left of the chair?'' and
``What is the chair to the left of?''
Another is to widen the problem domain and add more properties and relations than a primary object class (``car'') and spatial relations.
For instance, attribute classifiers could recognise color, size, facial expressions and positions, in order to authorise questions such as ``Is the girl sitting down?'' and ``Where is the red flower?''.
Action event classifiers could identify actions such as ``riding'' and ``talking to''.

The use of formal frameworks for question-answering tasks especially invites techniques for logical inference.
Consider an image of a person wearing glasses, and the question ``Does this person have 20/20 vision?''
It is reasonable to assume that a person is wearing glasses because they do not have perfect eyesight, to which ``20/20 vision'' is synonymous.
Logical inference could help to achieve the synonymity as well as the relationship between eyesight and wearing glasses.

The relabel-subtype implementation in the \texttt{find\_subtype\_relabeling} Python function makes some assumptions about the record types being checked (\autoref{sec:subtyperelabeling}).
More specifically, a field type may not be dependent on another dependent field, and record types may not be nested.
More complex applications could be achieved if the implementation were extended to handle these cases and eliminate the assumptions.

Furthermore, as discussed in \autoref{sec:discussion-subtype}, the implementation does not scale to handle some of the extensions mentioned here.
One measure to improve the performance is to introduce type-sensitivity when finding feasible basic-field relabelings.
For example, do not try to relabel a field with type $\type{Ind}$ to one with type $\type{Int}$, since $\type{Int} \mathrel{\cancel\sqsubseteq} \type{Ind}$.
In the general case, however, the relabel-subtype algorithm may need to be replaced with one that utilises theorem proving in order to find a subtype-compatible relabeling.

As mentioned in \autoref{sec:discussion-inferencefirst}, this algorithm does not scale well, as it performs classification of spatial relations (and, in extension, any other kind of inference) before parsing the question.
This problem could be overcome by first extracting only direct information from the image, namely the result of the $\type{ObjDetector}$;
then, when the question has been parsed, finding out what inference steps are necessary to perform.
The process of finding required inferences may need to be integrated with the amended subtype strategy just mentioned.
This is a necessary condition for most extensions of the language domain and inference.

From a software engineering perspective, the code implemented in this project could be better structured.
The code was implemented in a single Jupyter Notebook file, for the sake of easy experimenting.
It could be rewritten in standard Python files to make it easier to run on different systems.

The PyTTR codebase deserves some additional development.
Its documentation is currently in the form of Jupyter Notebook files, but it would be helpful to also add in-code comments that explain how the library can be used.
It would also help to package the code properly so it could be released and imported to projects like this one more easily.

%(b) left for future work in terms of (1) semantic representations of grounded language in TTR; (ii) their implementation in pyTTR; (iii) in the domain of visual question answering? 

%Classification after Q.
