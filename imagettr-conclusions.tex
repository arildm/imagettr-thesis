\renewcommand{\sectionautorefname}{Section}
\let\subsectionautorefname\sectionautorefname
\let\subsubsectionautorefname\sectionautorefname
\glsresetall
\section{Conclusions}
\label{sec:conclusions}

Within this project, the foundations of \gls{vqa} have been implemented in \gls{ttr}.
The result is an executable application powered by PyTTR.

The formal-semantic framework behind the application provides transparency and reversibility, and enables relatively simple implementation of operations (such as verifying a proposition).
\Gls{ttr} is the single framework that serves to operate all parts of the pipeline: perception, language and grounding.

The model is one of the few applications of the recently developed PyTTR library, which allows \gls{ttr} to be used in executable programs.
Extensions to PyTTR were made where needed.



\subsection{Future work}

The relabel-subtype implementation in the \texttt{find\_subtype\_relabeling} Python function makes some assumptions about the record types being checked (\autoref{sec:subtyperelabeling}).
More specifically, a field type may not be dependent on another dependent field, and record types may not be nested.
More complex applications could be achieved if the implementation were extended to handle these cases and eliminate the assumptions.
It is also possible that performance improvements of the operation can be made.

The agent structure is a rather simplistic model, tailored for the use case at hand.
It accepts as input an image followed by a number of questions.
There is no semantic connection between the current image and question, other than the sequence in which they are input.
There is also nothing like a dialogue system;
the background to any answer from the agent is the latest image and the latest question only.
Changing these things could be important for further some extensions.

Spatial classification and language parsing were achieved using minimal and simplistic implementations.
Substituting them with sophisticated systems would make for wider question coverage and higher question answering scores.
For instance, \cite{LoganComputationalAnalysisApprehension1996} proposes spatial templates, regions of acceptability and compound relations (like ``above to the right of'').

As discussed in \autoref{sec:method-spatrel}, the present treatment of spatial relations excludes the assignment of the frame of reference, as well as functional aspects, in favor of model simplicity and easy implementation.
Both features are treated in terms of \gls{ttr} by \cite{ttrspat}.
The former requires a notion of the orientation of reference objects.
Assuming an object classifier with this capability were available, implementing intrinsical spatial relations would not be a large step from the present model.
Such a classifier might detect that a car is facing left in the image;
an object to the right in the image could then be classified as being ``behind'' the car.
Support for the functional aspect of spatial relations requires two things.
Firstly, classifiers for functional relations (such as $\text{protects}(o_3\text{.a}, o_1\text{.a}, o_2\text{.a})$ in \cite{ttrspat}, for an umbrella protecting a man from rain).
% TODO Be more clear below?
Secondly, prediction from a set of functional relations to spatial classifiers that are sensitive to those functional relations.
The second is needed to activate the appropriate spatial relation term depending on which functional relations are true according to the classifiers in the first.
That is, if the relation between the umbrella and the man is classified as ``protects'', then the spatial classifier selected for ``over'' should be one that includes this condition.

Extending the language domain should be an interesting topic for further research.
Keeping within the problem domain of geometric spatial relations, allowing other question types than polar questions is one direction to explore.
\citet[p. 156]{DobnikTeachingmobilerobots2009} lists four basic question types:
``Where is the chair?'',
``Is the table to the left of the chair?'' (this is the focus of this project),
``What is to the left of the chair?'' and
``What is the chair to the left of?''
Another is to widen the problem domain and add more properties and relations than a primary object class (``car'') and spatial relations.
For instance, attribute classifiers could recognise color, size, facial expressions and positions, in order to authorise questions such as ``Is the girl sitting down?'' and ``Where is the red flower?''.
Action event classifiers could identify actions such as ``riding'' and ``talking to''.

The use of formal frameworks for question-answering tasks especially invites techniques for inference.
Consider an image of a person wearing glasses, and the question ``Does this person have 20/20 vision?''
It is reasonable to assume that a person is wearing glasses because they do not have perfect eyesight, to which ``20/20 vision'' is synonymous.
Inference could help to achieve the synonymity as well as the relationship between eyesight and wearing glasses.

From a software engineering perspective, the code implemented in this project could be better structured.
The code was implemented in a single Jupyter Notebook file, for the sake of easy experimenting.
It could be rewritten in standard Python files to make it easier to run on different systems.

The PyTTR codebase deserves some additional development.
Its documentation is currently in the form of Jupyter Notebook files, but it would be helpful to also add in-code comments that explain how the library can be used.
It would also help to package the code properly so it could be released and imported to projects like this one more easily.

%(b) left for future work in terms of (1) semantic representations of grounded language in TTR; (ii) their implementation in pyTTR; (iii) in the domain of visual question answering? 

%Classification after Q.
